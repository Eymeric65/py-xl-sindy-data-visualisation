[
  {
    "success": true,
    "returncode": 0,
    "stdout": "already aligned\n",
    "stderr": "",
    "execution_time": 2.9213104248046875,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2518a2afe4fcef2bdb23f230b6e3d9d1 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2518a2afe4fcef2bdb23f230b6e3d9d1",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "already aligned\n",
    "stderr": "",
    "execution_time": 3.263822555541992,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2518a2afe4fcef2bdb23f230b6e3d9d1 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2518a2afe4fcef2bdb23f230b6e3d9d1",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "already aligned\n",
    "stderr": "",
    "execution_time": 3.250051736831665,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2518a2afe4fcef2bdb23f230b6e3d9d1 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2518a2afe4fcef2bdb23f230b6e3d9d1",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "already aligned\n",
    "stderr": "",
    "execution_time": 3.2530226707458496,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2518a2afe4fcef2bdb23f230b6e3d9d1 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2518a2afe4fcef2bdb23f230b6e3d9d1",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "already aligned\n",
    "stderr": "",
    "execution_time": 2.6623053550720215,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2518a2afe4fcef2bdb23f230b6e3d9d1 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2518a2afe4fcef2bdb23f230b6e3d9d1",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "already aligned\n",
    "stderr": "",
    "execution_time": 2.852918863296509,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2518a2afe4fcef2bdb23f230b6e3d9d1 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2518a2afe4fcef2bdb23f230b6e3d9d1",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [16, 1]\n2025-09-30 14:44:43,462 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:44:43,463 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:44:43,463 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:44:44,521 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:44:44,521 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:44:44,521 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:44:44,521 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:44:44,521 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:44:44,522 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:44:45,164 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0015534935803281546\n2025-09-30 14:44:45,319 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:44:45,319 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:44:45,320 - __main__ - INFO - Regression completed in 1.86 seconds\nestimate variance between mujoco and model is :  0.8834378\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.03s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.03s/batch]\n",
    "execution_time": 14.00370454788208,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2518a2afe4fcef2bdb23f230b6e3d9d1 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2518a2afe4fcef2bdb23f230b6e3d9d1",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [16, 1]\n2025-09-30 14:44:57,350 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:44:57,350 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:44:57,350 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:44:58,376 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:44:58,376 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:44:58,376 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:44:58,376 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:44:58,377 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:44:58,377 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:44:58,892 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.001555585717680731\n2025-09-30 14:44:59,027 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:44:59,027 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:44:59,027 - __main__ - INFO - Regression completed in 1.68 seconds\nestimate variance between mujoco and model is :  0.14191984\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.93s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.93s/batch]\n",
    "execution_time": 13.988851070404053,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2518a2afe4fcef2bdb23f230b6e3d9d1 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2518a2afe4fcef2bdb23f230b6e3d9d1",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [34, 1]\n2025-09-30 14:45:11,192 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:45:11,193 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:45:15,238 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.033442365474310724\n2025-09-30 14:45:15,384 - __main__ - INFO - Regression completed in 4.19 seconds\nestimate variance between mujoco and model is :  0.2652422\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.8s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.80s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.80s/batch]\n",
    "execution_time": 15.58192777633667,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae24d0108aa8cbe951ad4577639d0c2a --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae24d0108aa8cbe951ad4577639d0c2a",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [34, 1]\n2025-09-30 14:45:27,007 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:45:27,007 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:45:31,280 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03277532200846003\n2025-09-30 14:45:31,450 - __main__ - INFO - Regression completed in 4.44 seconds\nestimate variance between mujoco and model is :  0.27748886\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.0s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.97s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.97s/batch]\n",
    "execution_time": 16.73515796661377,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae24d0108aa8cbe951ad4577639d0c2a --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae24d0108aa8cbe951ad4577639d0c2a",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [34, 1]\n2025-09-30 14:45:44,119 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:45:44,120 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:45:45,883 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 1.3064136372487956\n2025-09-30 14:45:45,893 - __main__ - INFO - Regression completed in 1.77 seconds\nestimate variance between mujoco and model is :  7.9151196\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.73s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.73s/batch]\n",
    "execution_time": 13.044434309005737,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae24d0108aa8cbe951ad4577639d0c2a --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae24d0108aa8cbe951ad4577639d0c2a",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [34, 1]\n2025-09-30 14:45:56,569 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:45:56,569 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:46:00,758 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03337849072924467\n2025-09-30 14:46:00,920 - __main__ - INFO - Regression completed in 4.35 seconds\nestimate variance between mujoco and model is :  0.26484492\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.0s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.99s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.99s/batch]\n",
    "execution_time": 16.651172161102295,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae24d0108aa8cbe951ad4577639d0c2a --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae24d0108aa8cbe951ad4577639d0c2a",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [34, 1]\n2025-09-30 14:46:13,205 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:46:13,205 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:46:13,205 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:46:14,221 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:46:14,221 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:46:14,221 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:46:14,221 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:46:14,221 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:46:14,221 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:46:16,804 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03344236547431073\n2025-09-30 14:46:16,958 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:46:16,958 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:46:16,958 - __main__ - INFO - Regression completed in 3.75 seconds\nestimate variance between mujoco and model is :  0.2652422\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.4s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.81s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.81s/batch]\n",
    "execution_time": 15.342310905456543,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae24d0108aa8cbe951ad4577639d0c2a --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae24d0108aa8cbe951ad4577639d0c2a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [34, 1]\n2025-09-30 14:46:28,567 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:46:28,567 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:46:28,567 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:46:29,652 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:46:29,652 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:46:29,653 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:46:29,653 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:46:29,653 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:46:29,653 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:46:32,439 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03277532200846003\n2025-09-30 14:46:32,606 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:46:32,607 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:46:32,607 - __main__ - INFO - Regression completed in 4.04 seconds\nestimate variance between mujoco and model is :  0.27748886\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.6s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.81s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.81s/batch]\n",
    "execution_time": 15.415189981460571,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae24d0108aa8cbe951ad4577639d0c2a --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae24d0108aa8cbe951ad4577639d0c2a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [34, 1]\n2025-09-30 14:46:43,974 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:46:43,975 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:46:43,975 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:46:45,021 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:46:45,021 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:46:45,021 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:46:45,021 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:46:45,022 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:46:45,022 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:46:45,608 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 1.3064136372487956\n2025-09-30 14:46:45,619 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:46:45,619 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:46:45,619 - __main__ - INFO - Regression completed in 1.64 seconds\nestimate variance between mujoco and model is :  7.9151196\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.77s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.77s/batch]\n",
    "execution_time": 12.720504999160767,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae24d0108aa8cbe951ad4577639d0c2a --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae24d0108aa8cbe951ad4577639d0c2a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [34, 1]\n2025-09-30 14:46:56,829 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:46:56,829 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:46:56,829 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:46:57,873 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:46:57,874 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:46:57,874 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:46:57,874 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:46:57,874 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:46:57,874 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:47:00,587 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03337849072924466\n2025-09-30 14:47:00,753 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:47:00,753 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:47:00,754 - __main__ - INFO - Regression completed in 3.92 seconds\nestimate variance between mujoco and model is :  0.26484492\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.6s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+01, tolerance: 1.014e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\n",
    "execution_time": 16.64230728149414,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae24d0108aa8cbe951ad4577639d0c2a --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae24d0108aa8cbe951ad4577639d0c2a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [36, 1]\n2025-09-30 14:47:13,393 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:47:13,393 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:47:14,724 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0073652270335017945\n2025-09-30 14:47:14,770 - __main__ - INFO - Regression completed in 1.38 seconds\nestimate variance between mujoco and model is :  4.631501\n2025-09-30 14:47:20,755 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.88batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.87batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.077208280563354,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5933392144b2eec2518f5804a80a1b1b --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5933392144b2eec2518f5804a80a1b1b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [36, 1]\n2025-09-30 14:47:24,491 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:47:24,491 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:47:25,886 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.007353785933011981\n2025-09-30 14:47:25,939 - __main__ - INFO - Regression completed in 1.45 seconds\nestimate variance between mujoco and model is :  4.2934275\n2025-09-30 14:47:32,393 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.27batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.27batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.64839768409729,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5933392144b2eec2518f5804a80a1b1b --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5933392144b2eec2518f5804a80a1b1b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [36, 1]\n2025-09-30 14:47:36,114 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:47:36,114 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:47:37,441 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.007244675778986284\n2025-09-30 14:47:37,485 - __main__ - INFO - Regression completed in 1.37 seconds\nestimate variance between mujoco and model is :  5.2701616\n2025-09-30 14:47:43,990 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.40batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.39batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.685691595077515,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5933392144b2eec2518f5804a80a1b1b --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5933392144b2eec2518f5804a80a1b1b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [36, 1]\n2025-09-30 14:47:47,912 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:47:47,912 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:47:49,404 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.007364089071986067\n2025-09-30 14:47:49,449 - __main__ - INFO - Regression completed in 1.54 seconds\nestimate variance between mujoco and model is :  4.7501197\n2025-09-30 14:47:55,798 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.58batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.57batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.690258741378784,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5933392144b2eec2518f5804a80a1b1b --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5933392144b2eec2518f5804a80a1b1b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [36, 1]\n2025-09-30 14:47:59,539 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:47:59,539 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:47:59,539 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:48:00,584 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:48:00,584 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:48:00,584 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:48:00,584 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:48:00,584 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:48:00,584 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:48:00,859 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.007365227033501796\n2025-09-30 14:48:00,909 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:48:00,909 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:48:00,909 - __main__ - INFO - Regression completed in 1.37 seconds\nestimate variance between mujoco and model is :  4.631501\n2025-09-30 14:48:07,307 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.22batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.21batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.528308391571045,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5933392144b2eec2518f5804a80a1b1b --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5933392144b2eec2518f5804a80a1b1b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [36, 1]\n2025-09-30 14:48:11,205 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:48:11,206 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:48:11,206 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:48:12,265 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:48:12,265 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:48:12,265 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:48:12,265 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:48:12,266 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:48:12,266 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:48:12,537 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.007353785933011981\n2025-09-30 14:48:12,589 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:48:12,589 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:48:12,589 - __main__ - INFO - Regression completed in 1.38 seconds\nestimate variance between mujoco and model is :  4.2934275\n2025-09-30 14:48:18,832 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.25batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.24batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.505354642868042,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5933392144b2eec2518f5804a80a1b1b --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5933392144b2eec2518f5804a80a1b1b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [36, 1]\n2025-09-30 14:48:22,508 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:48:22,508 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:48:22,508 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:48:23,530 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:48:23,530 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:48:23,530 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:48:23,530 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:48:23,530 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:48:23,530 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:48:23,799 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.007244675778986283\n2025-09-30 14:48:23,849 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:48:23,850 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:48:23,850 - __main__ - INFO - Regression completed in 1.34 seconds\nestimate variance between mujoco and model is :  5.2701616\n2025-09-30 14:48:30,108 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.39batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.38batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.304988384246826,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5933392144b2eec2518f5804a80a1b1b --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5933392144b2eec2518f5804a80a1b1b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [36, 1]\n2025-09-30 14:48:34,724 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:48:34,725 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:48:34,725 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:48:36,015 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:48:36,016 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:48:36,016 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:48:36,016 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:48:36,016 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:48:36,016 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:48:36,300 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0073640890719860646\n2025-09-30 14:48:36,343 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:48:36,343 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:48:36,343 - __main__ - INFO - Regression completed in 1.62 seconds\nestimate variance between mujoco and model is :  4.7501197\n2025-09-30 14:48:42,110 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.66batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.65batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.91835355758667,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5933392144b2eec2518f5804a80a1b1b --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5933392144b2eec2518f5804a80a1b1b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [13, 1]\n2025-09-30 14:48:45,667 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:48:45,667 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:48:47,117 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0081227976727177\n2025-09-30 14:48:47,146 - __main__ - INFO - Regression completed in 1.48 seconds\nestimate variance between mujoco and model is :  2.2655554\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.67s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.67s/batch]\n",
    "execution_time": 12.739480018615723,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8db46d3c5f742027b963792ac0709dd3 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8db46d3c5f742027b963792ac0709dd3",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [13, 1]\n2025-09-30 14:48:58,624 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:48:58,625 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:49:00,177 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.008112001055065115\n2025-09-30 14:49:00,209 - __main__ - INFO - Regression completed in 1.58 seconds\nestimate variance between mujoco and model is :  2.3536031\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.72s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.73s/batch]\n",
    "execution_time": 13.590678453445435,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8db46d3c5f742027b963792ac0709dd3 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8db46d3c5f742027b963792ac0709dd3",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [13, 1]\n2025-09-30 14:49:12,194 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:49:12,194 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:49:13,888 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.007922817325411526\n2025-09-30 14:49:13,936 - __main__ - INFO - Regression completed in 1.74 seconds\nestimate variance between mujoco and model is :  4.713888\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.77s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.77s/batch]\n",
    "execution_time": 13.187081813812256,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8db46d3c5f742027b963792ac0709dd3 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8db46d3c5f742027b963792ac0709dd3",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56869 column 2 (char 2098768)\n",
    "execution_time": 3.042402744293213,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8db46d3c5f742027b963792ac0709dd3 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8db46d3c5f742027b963792ac0709dd3",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56869 column 2 (char 2098768)\n",
    "execution_time": 3.9152286052703857,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8db46d3c5f742027b963792ac0709dd3 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8db46d3c5f742027b963792ac0709dd3",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56869 column 2 (char 2098768)\n",
    "execution_time": 2.834832191467285,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8db46d3c5f742027b963792ac0709dd3 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8db46d3c5f742027b963792ac0709dd3",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56869 column 2 (char 2098768)\n",
    "execution_time": 2.755002021789551,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8db46d3c5f742027b963792ac0709dd3 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8db46d3c5f742027b963792ac0709dd3",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56869 column 2 (char 2098768)\n",
    "execution_time": 2.8928475379943848,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8db46d3c5f742027b963792ac0709dd3 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8db46d3c5f742027b963792ac0709dd3",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [9, 1]\n2025-09-30 14:49:41,031 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:49:41,031 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.777594566345215,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae206a5b11664fef512583f5bd00ce4c --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae206a5b11664fef512583f5bd00ce4c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [9, 1]\n2025-09-30 14:49:46,909 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:49:46,909 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.897421360015869,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae206a5b11664fef512583f5bd00ce4c --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae206a5b11664fef512583f5bd00ce4c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [9, 1]\n2025-09-30 14:49:53,216 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:49:53,216 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.374210357666016,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae206a5b11664fef512583f5bd00ce4c --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae206a5b11664fef512583f5bd00ce4c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [9, 1]\n2025-09-30 14:49:59,126 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:49:59,126 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.907730340957642,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae206a5b11664fef512583f5bd00ce4c --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae206a5b11664fef512583f5bd00ce4c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [9, 1]\n2025-09-30 14:50:05,008 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:50:05,008 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:50:05,008 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.832264184951782,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae206a5b11664fef512583f5bd00ce4c --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae206a5b11664fef512583f5bd00ce4c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [9, 1]\n2025-09-30 14:50:10,834 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:50:10,834 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:50:10,834 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.081270217895508,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae206a5b11664fef512583f5bd00ce4c --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae206a5b11664fef512583f5bd00ce4c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [9, 1]\n2025-09-30 14:50:17,285 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:50:17,285 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:50:17,285 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.357233762741089,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae206a5b11664fef512583f5bd00ce4c --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae206a5b11664fef512583f5bd00ce4c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [9, 1]\n2025-09-30 14:50:23,183 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:50:23,183 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:50:23,183 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.710134506225586,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/ae206a5b11664fef512583f5bd00ce4c --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "ae206a5b11664fef512583f5bd00ce4c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [2, 1]\n2025-09-30 14:50:28,608 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:50:28,608 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:50:37,305 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.32006709732727046\n2025-09-30 14:50:37,410 - __main__ - INFO - Regression completed in 8.80 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.667e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.127e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.018e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.777e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.705e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.578e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.773e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.142e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.051e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.480e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.003e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.558e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.117e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.712e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.272e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.891e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.306e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.347e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.057e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.307e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.234e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.893e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.334e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.597e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.715e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.717e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.123e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.478e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.712e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.977e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.032e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.023e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.707e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.779e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.642e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.929e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.342e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.474e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.260e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.586e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.044e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.784e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.316e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.904e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.481e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.135e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.789e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.465e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.194e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.287e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.894e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.101e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.995e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.631e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.056e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.309e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.423e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.424e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.183e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.412e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+00, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+00, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+00, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+00, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.329e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.880e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.115e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.351e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.826e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.334e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.888e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.466e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.990e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.659e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.289e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.875e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.474e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.102e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.727e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.727e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.424e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.133e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.862e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.372e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.380e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.061e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.752e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.857e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e+01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e+01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.032e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.856e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.858e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.468e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.418e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.479e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.715e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.494e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.678e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.745e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.577e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.460e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.273e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.917e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.751e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.077e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.686e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.348e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.912e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.666e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.285e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.552e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.129e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.881e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.563e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.247e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.567e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.456e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.232e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.962e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.468e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.066e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.533e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+00, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.5s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e+02, tolerance: 4.143e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e+02, tolerance: 4.143e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 12.431053876876831,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f5643924d3e5a80f345cddc235a5c658 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f5643924d3e5a80f345cddc235a5c658",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [2, 1]\n2025-09-30 14:50:41,265 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:50:41,266 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:50:45,645 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 674.6880327019137\n2025-09-30 14:50:45,647 - __main__ - INFO - Regression completed in 4.38 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.3s finished\n",
    "execution_time": 8.345165014266968,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f5643924d3e5a80f345cddc235a5c658 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f5643924d3e5a80f345cddc235a5c658",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [2, 1]\n2025-09-30 14:50:49,536 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:50:49,536 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:50:51,027 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 577.6356112970483\n2025-09-30 14:50:51,028 - __main__ - INFO - Regression completed in 1.49 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
    "execution_time": 5.41714072227478,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f5643924d3e5a80f345cddc235a5c658 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f5643924d3e5a80f345cddc235a5c658",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [2, 1]\n2025-09-30 14:50:55,052 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:50:55,052 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:51:03,626 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 5.516674911560178\n2025-09-30 14:51:03,739 - __main__ - INFO - Regression completed in 8.69 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.680e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.902e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.909e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.819e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.697e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.583e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.692e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.518e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.343e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.057e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.120e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.626e+01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.503e+01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e+02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.569e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.530e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.746e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.664e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.506e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.311e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.146e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.366e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.565e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.432e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.565e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.467e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.139e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.390e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.947e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.284e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.312e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.607e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.499e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.096e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.166e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.379e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.111e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.795e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.634e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.478e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.310e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.138e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.498e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.376e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.710e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.161e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.334e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.030e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.579e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.130e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.702e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.296e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.196e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.577e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.827e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.634e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e+00, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+00, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.5s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.877e+01, tolerance: 4.143e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.877e+01, tolerance: 4.143e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 12.98734974861145,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f5643924d3e5a80f345cddc235a5c658 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f5643924d3e5a80f345cddc235a5c658",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [2, 1]\n2025-09-30 14:51:07,913 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:51:07,914 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:51:07,914 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:51:08,986 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:51:08,987 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:51:08,987 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:51:08,987 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:51:08,987 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:51:08,987 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:51:16,071 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.3200670973272705\n2025-09-30 14:51:16,182 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:51:16,182 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:51:16,182 - __main__ - INFO - Regression completed in 8.27 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.667e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.127e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.018e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.777e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.705e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.578e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.773e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.142e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.051e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.480e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.003e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.558e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.117e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.712e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.272e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.891e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.306e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.347e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.057e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.307e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.234e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.893e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.334e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.597e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.715e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.717e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.123e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.478e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.712e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.977e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.032e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.023e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.707e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.779e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.642e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.929e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.342e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.474e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.260e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.586e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.044e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.784e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.316e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.904e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.481e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.135e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.789e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.465e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.194e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.287e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.894e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.101e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.995e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.631e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.056e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.309e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.423e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.424e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.183e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.412e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+00, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+00, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+00, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+00, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.329e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.880e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.115e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.351e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.826e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.334e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.888e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.466e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.990e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.659e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.289e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.875e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.474e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.102e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.727e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.727e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.424e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.133e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.862e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.372e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.380e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.061e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.752e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.857e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e+01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e+01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.032e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.856e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.858e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.468e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.418e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.479e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.715e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.494e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.678e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.745e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.577e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.460e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.273e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.917e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.751e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.077e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.686e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.348e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.912e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.666e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.285e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.552e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.129e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.881e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.563e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.247e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.567e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.456e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.232e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.962e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.468e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.066e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.533e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+00, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.0s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e+02, tolerance: 4.143e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e+02, tolerance: 4.143e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 12.006019830703735,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f5643924d3e5a80f345cddc235a5c658 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f5643924d3e5a80f345cddc235a5c658",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [2, 1]\n2025-09-30 14:51:20,073 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:51:20,073 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:51:20,073 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:51:21,112 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:51:21,113 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:51:21,113 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:51:21,113 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:51:21,113 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:51:21,113 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:51:23,897 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 674.6880327019139\n2025-09-30 14:51:23,898 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:51:23,898 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:51:23,898 - __main__ - INFO - Regression completed in 3.82 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.8s finished\n",
    "execution_time": 7.734374284744263,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f5643924d3e5a80f345cddc235a5c658 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f5643924d3e5a80f345cddc235a5c658",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [2, 1]\n2025-09-30 14:51:27,729 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:51:27,729 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:51:27,729 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:51:29,185 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:51:29,185 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:51:29,185 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:51:29,185 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:51:29,186 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:51:29,186 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:51:29,369 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 577.6356112970486\n2025-09-30 14:51:29,369 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:51:29,369 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:51:29,370 - __main__ - INFO - Regression completed in 1.64 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
    "execution_time": 5.520123243331909,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f5643924d3e5a80f345cddc235a5c658 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f5643924d3e5a80f345cddc235a5c658",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [2, 1]\n2025-09-30 14:51:33,347 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:51:33,348 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:51:33,348 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:51:34,371 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:51:34,371 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:51:34,371 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:51:34,371 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:51:34,372 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:51:34,372 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:51:41,097 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 5.516674911560171\n2025-09-30 14:51:41,199 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:51:41,199 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:51:41,200 - __main__ - INFO - Regression completed in 7.85 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.680e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.902e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.909e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.819e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.697e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.583e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.692e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.518e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.343e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.057e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.120e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.626e+01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.503e+01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e+02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.569e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.530e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.746e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.664e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.506e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.311e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.146e-02, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.366e-01, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.565e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e+00, tolerance: 4.141e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.432e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.565e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.467e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.139e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.390e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.947e-01, tolerance: 3.480e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.284e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.312e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.607e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.499e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.096e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.166e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.379e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.111e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.795e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.634e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.478e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.310e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.138e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.498e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.376e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e-01, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.710e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.161e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.334e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.030e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.579e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.130e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.702e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.296e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e-02, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.196e+00, tolerance: 2.345e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.577e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.827e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.634e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e-02, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e+00, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+00, tolerance: 2.398e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.6s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.877e+01, tolerance: 4.143e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.877e+01, tolerance: 4.143e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 11.848281145095825,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f5643924d3e5a80f345cddc235a5c658 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f5643924d3e5a80f345cddc235a5c658",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [38, 1]\n2025-09-30 14:51:45,467 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:51:45,467 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.206661701202393,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/42ddde4ac4a7c090172166af8203a335 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "42ddde4ac4a7c090172166af8203a335",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [38, 1]\n2025-09-30 14:51:51,686 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:51:51,686 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.077694416046143,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/42ddde4ac4a7c090172166af8203a335 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "42ddde4ac4a7c090172166af8203a335",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [38, 1]\n2025-09-30 14:51:57,690 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:51:57,690 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.033262729644775,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/42ddde4ac4a7c090172166af8203a335 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "42ddde4ac4a7c090172166af8203a335",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [38, 1]\n2025-09-30 14:52:03,905 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:03,906 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.365561246871948,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/42ddde4ac4a7c090172166af8203a335 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "42ddde4ac4a7c090172166af8203a335",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [38, 1]\n2025-09-30 14:52:10,089 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:10,090 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:52:10,090 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.9665985107421875,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/42ddde4ac4a7c090172166af8203a335 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "42ddde4ac4a7c090172166af8203a335",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [38, 1]\n2025-09-30 14:52:16,034 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:16,035 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:52:16,035 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.131340503692627,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/42ddde4ac4a7c090172166af8203a335 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "42ddde4ac4a7c090172166af8203a335",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [38, 1]\n2025-09-30 14:52:22,344 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:22,345 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:52:22,345 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.370717763900757,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/42ddde4ac4a7c090172166af8203a335 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "42ddde4ac4a7c090172166af8203a335",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [38, 1]\n2025-09-30 14:52:28,537 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:28,538 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:52:28,538 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.976599931716919,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/42ddde4ac4a7c090172166af8203a335 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "42ddde4ac4a7c090172166af8203a335",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [21, 1]\n2025-09-30 14:52:34,967 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:34,968 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.566370725631714,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e00a3cfbaf325101e2adc7d4b75938d2 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e00a3cfbaf325101e2adc7d4b75938d2",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [21, 1]\n2025-09-30 14:52:40,975 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:40,975 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.985085725784302,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e00a3cfbaf325101e2adc7d4b75938d2 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e00a3cfbaf325101e2adc7d4b75938d2",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [21, 1]\n2025-09-30 14:52:47,211 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:47,211 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.117785692214966,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e00a3cfbaf325101e2adc7d4b75938d2 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e00a3cfbaf325101e2adc7d4b75938d2",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [21, 1]\n2025-09-30 14:52:53,112 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:53,113 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.910316705703735,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e00a3cfbaf325101e2adc7d4b75938d2 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e00a3cfbaf325101e2adc7d4b75938d2",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [21, 1]\n2025-09-30 14:52:59,374 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:52:59,374 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:52:59,374 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.283745765686035,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e00a3cfbaf325101e2adc7d4b75938d2 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e00a3cfbaf325101e2adc7d4b75938d2",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [21, 1]\n2025-09-30 14:53:05,242 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:53:05,242 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:53:05,242 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.762526988983154,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e00a3cfbaf325101e2adc7d4b75938d2 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e00a3cfbaf325101e2adc7d4b75938d2",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [21, 1]\n2025-09-30 14:53:11,154 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:53:11,154 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:53:11,154 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.077084302902222,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e00a3cfbaf325101e2adc7d4b75938d2 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e00a3cfbaf325101e2adc7d4b75938d2",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [21, 1]\n2025-09-30 14:53:17,241 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 14:53:17,242 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:53:17,242 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.981953144073486,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e00a3cfbaf325101e2adc7d4b75938d2 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e00a3cfbaf325101e2adc7d4b75938d2",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [32, 1]\n2025-09-30 14:53:22,699 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:53:22,699 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:53:24,208 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.011554064874117437\n2025-09-30 14:53:24,333 - __main__ - INFO - Regression completed in 1.63 seconds\nestimate variance between mujoco and model is :  0.094159156\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.017e+00, tolerance: 9.849e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.017e+00, tolerance: 9.849e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.83s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.83s/batch]\n",
    "execution_time": 13.338870525360107,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/df1fa0ac624a0946a00c62d2a904590e --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "df1fa0ac624a0946a00c62d2a904590e",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [32, 1]\n2025-09-30 14:53:36,124 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:53:36,124 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:53:37,574 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.011636695616492339\n2025-09-30 14:53:37,732 - __main__ - INFO - Regression completed in 1.61 seconds\nestimate variance between mujoco and model is :  0.123945914\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+00, tolerance: 9.850e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+00, tolerance: 9.850e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.94s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.94s/batch]\n",
    "execution_time": 13.547119140625,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/df1fa0ac624a0946a00c62d2a904590e --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "df1fa0ac624a0946a00c62d2a904590e",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [32, 1]\n2025-09-30 14:53:49,566 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:53:49,566 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:53:50,996 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.030977120610339515\n2025-09-30 14:53:51,123 - __main__ - INFO - Regression completed in 1.56 seconds\nestimate variance between mujoco and model is :  0.98226935\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.54s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.54s/batch]\n",
    "execution_time": 12.744784355163574,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/df1fa0ac624a0946a00c62d2a904590e --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "df1fa0ac624a0946a00c62d2a904590e",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [32, 1]\n2025-09-30 14:54:02,518 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:54:02,519 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:54:03,978 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.011562375227556617\n2025-09-30 14:54:04,113 - __main__ - INFO - Regression completed in 1.59 seconds\nestimate variance between mujoco and model is :  0.09367799\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+00, tolerance: 9.849e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+00, tolerance: 9.849e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.91s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.91s/batch]\n",
    "execution_time": 12.93690037727356,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/df1fa0ac624a0946a00c62d2a904590e --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "df1fa0ac624a0946a00c62d2a904590e",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [32, 1]\n2025-09-30 14:54:15,586 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:54:15,586 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:54:15,586 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:54:16,614 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:54:16,614 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:54:16,614 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:54:16,614 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:54:16,615 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:54:16,615 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:54:16,977 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.011554064874117437\n2025-09-30 14:54:17,094 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:54:17,094 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:54:17,095 - __main__ - INFO - Regression completed in 1.51 seconds\nestimate variance between mujoco and model is :  0.094159156\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.017e+00, tolerance: 9.849e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.017e+00, tolerance: 9.849e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.80s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.80s/batch]\n",
    "execution_time": 13.77361273765564,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/df1fa0ac624a0946a00c62d2a904590e --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "df1fa0ac624a0946a00c62d2a904590e",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [32, 1]\n2025-09-30 14:54:29,332 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:54:29,332 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:54:29,332 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:54:30,359 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:54:30,359 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:54:30,359 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:54:30,359 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:54:30,359 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:54:30,359 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:54:30,780 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.01163669561649233\n2025-09-30 14:54:30,931 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:54:30,931 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:54:30,931 - __main__ - INFO - Regression completed in 1.60 seconds\nestimate variance between mujoco and model is :  0.123945914\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+00, tolerance: 9.850e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+00, tolerance: 9.850e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.86s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.86s/batch]\n",
    "execution_time": 13.918628692626953,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/df1fa0ac624a0946a00c62d2a904590e --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "df1fa0ac624a0946a00c62d2a904590e",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [32, 1]\n2025-09-30 14:54:43,015 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:54:43,015 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:54:43,015 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:54:44,033 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:54:44,033 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:54:44,033 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:54:44,033 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:54:44,034 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:54:44,034 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:54:44,411 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.030977120610339515\n2025-09-30 14:54:44,504 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:54:44,504 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:54:44,504 - __main__ - INFO - Regression completed in 1.49 seconds\nestimate variance between mujoco and model is :  0.98226935\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.50s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.50s/batch]\n",
    "execution_time": 12.610168695449829,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/df1fa0ac624a0946a00c62d2a904590e --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "df1fa0ac624a0946a00c62d2a904590e",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [32, 1]\n2025-09-30 14:54:55,695 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:54:55,695 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:54:55,695 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:54:56,711 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:54:56,711 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:54:56,711 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:54:56,711 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:54:56,711 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:54:56,711 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:54:57,093 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.011562375227556614\n2025-09-30 14:54:57,231 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:54:57,231 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:54:57,231 - __main__ - INFO - Regression completed in 1.54 seconds\nestimate variance between mujoco and model is :  0.09367799\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+00, tolerance: 9.849e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+00, tolerance: 9.849e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.85s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.85s/batch]\n",
    "execution_time": 14.05110216140747,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/df1fa0ac624a0946a00c62d2a904590e --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "df1fa0ac624a0946a00c62d2a904590e",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [28, 1]\n2025-09-30 14:55:09,836 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 14:55:09,837 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\nTypeError: regression_implicite() got an unexpected keyword argument 'regression_function'\n",
    "execution_time": 3.2546210289001465,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8d539ca77bd47116d467171851f2576c --algorithm mixed --regression-type implicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8d539ca77bd47116d467171851f2576c",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [28, 1]\n2025-09-30 14:55:13,040 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 14:55:13,041 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\nTypeError: regression_implicite() got an unexpected keyword argument 'regression_function'\n",
    "execution_time": 3.0120022296905518,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8d539ca77bd47116d467171851f2576c --algorithm mixed --regression-type implicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8d539ca77bd47116d467171851f2576c",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [28, 1]\n2025-09-30 14:55:15,912 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 14:55:15,912 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\nTypeError: regression_implicite() got an unexpected keyword argument 'regression_function'\n",
    "execution_time": 2.9583051204681396,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8d539ca77bd47116d467171851f2576c --algorithm mixed --regression-type implicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8d539ca77bd47116d467171851f2576c",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [28, 1]\n2025-09-30 14:55:18,924 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 14:55:18,925 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\nTypeError: regression_implicite() got an unexpected keyword argument 'regression_function'\n",
    "execution_time": 2.9676904678344727,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8d539ca77bd47116d467171851f2576c --algorithm mixed --regression-type implicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8d539ca77bd47116d467171851f2576c",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [28, 1]\n2025-09-30 14:55:21,980 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 14:55:21,980 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:55:21,980 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:55:23,033 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:55:23,034 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:55:23,034 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:55:23,034 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:55:23,034 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 14:55:23,034 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.20e+00  1.00e+00  1.64e+01   ------   \n  1  +1.9657e-01  +1.9554e-01  1.02e-03  6.49e-03  1.50e-03  9.98e-03  1.81e-01  9.89e-01  \n  2  +1.5249e-01  +1.5263e-01  1.44e-04  1.77e-04  4.08e-05  4.45e-04  4.96e-03  9.73e-01  \n  3  +1.1555e-01  +1.1740e-01  1.85e-03  6.24e-05  1.44e-05  2.10e-03  1.74e-03  7.66e-01  \n  4  +9.2645e-02  +9.3340e-02  6.94e-04  3.73e-05  8.58e-06  7.73e-04  1.04e-03  5.33e-01  \n  5  +8.4885e-02  +8.5373e-02  4.88e-04  2.66e-05  6.12e-06  5.39e-04  7.44e-04  4.29e-01  \n  6  +7.4302e-02  +7.4357e-02  5.42e-05  1.05e-05  2.42e-06  6.11e-05  2.96e-04  8.81e-01  \n  7  +7.3711e-02  +7.3773e-02  6.20e-05  9.92e-06  2.28e-06  6.91e-05  2.80e-04  1.96e-01  \n  8  +7.0051e-02  +7.0061e-02  1.05e-05  6.09e-06  1.39e-06  1.23e-05  1.78e-04  5.97e-01  \n  9  +6.8835e-02  +6.8840e-02  4.44e-06  4.22e-06  9.60e-07  5.25e-06  1.37e-04  4.48e-01  \n 10  +6.8065e-02  +6.8066e-02  9.97e-07  1.75e-06  3.95e-07  1.23e-06  8.17e-05  5.70e-01  \n 11  +6.7760e-02  +6.7760e-02  3.71e-07  6.93e-07  1.56e-07  4.53e-07  5.23e-05  4.57e-01  \n 12  +6.7744e-02  +6.7744e-02  3.39e-07  6.40e-07  1.44e-07  4.15e-07  5.01e-05  1.52e-01  \n 13  +6.7707e-02  +6.7707e-02  2.59e-07  5.01e-07  1.13e-07  3.18e-07  4.34e-05  3.00e-01  \n 14  +6.7705e-02  +6.7705e-02  2.39e-07  4.91e-07  1.11e-07  2.97e-07  4.27e-05  1.62e-01  \n 15  +6.7660e-02  +6.7660e-02  1.51e-07  3.17e-07  7.14e-08  1.88e-07  3.16e-05  3.45e-01  \n 16  +6.7627e-02  +6.7627e-02  6.41e-08  1.79e-07  4.03e-08  8.51e-08  2.01e-05  6.63e-01  \n 17  +6.7618e-02  +6.7618e-02  4.05e-08  1.39e-07  3.13e-08  5.69e-08  1.61e-05  3.89e-01  \n 18  +6.7590e-02  +6.7590e-02  2.60e-09  3.49e-08  7.89e-09  6.79e-09  4.74e-06  9.90e-01  \n 19  +6.7587e-02  +6.7587e-02  9.81e-10  2.52e-08  5.71e-09  4.05e-09  3.26e-06  4.94e-01  \n 20  +6.7584e-02  +6.7584e-02  6.05e-10  1.52e-08  3.47e-09  1.29e-09  1.73e-06  8.37e-01  \n 21  +6.7583e-02  +6.7583e-02  6.79e-10  1.44e-08  3.26e-09  1.07e-09  1.74e-06  3.36e-02  \n 22  +6.7584e-02  +6.7584e-02  1.07e-09  1.36e-08  3.09e-09  6.30e-10  1.39e-06  8.56e-01  \n 23  +6.7582e-02  +6.7582e-02  8.21e-10  1.04e-08  2.38e-09  5.15e-10  9.19e-07  4.20e-01  \n 24  +6.7581e-02  +6.7581e-02  8.00e-10  9.60e-09  2.18e-09  3.95e-10  9.05e-07  1.26e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 8.45212001s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 14:55:33,084 - xlsindy.simulation - INFO - Group 2, weight 0.21: [np.int64(2), np.int64(6), np.int64(19), np.int64(59)]\n2025-09-30 14:55:33,084 - xlsindy.simulation - INFO - Group 4, weight 0.19: [np.int64(4), np.int64(12), np.int64(24)]\n2025-09-30 14:55:33,084 - xlsindy.simulation - INFO - Group 5, weight 0.20: [np.int64(5), np.int64(20), np.int64(25)]\n2025-09-30 14:55:33,084 - xlsindy.simulation - INFO - Group 7, weight 0.19: [np.int64(8), np.int64(9), np.int64(10)]\n2025-09-30 14:55:33,084 - xlsindy.simulation - INFO - Group 10, weight 0.16: [np.int64(14), np.int64(15), np.int64(40)]\n2025-09-30 14:55:33,084 - xlsindy.simulation - INFO - Group 29, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 14:55:33,134 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:55:33,157 - __main__ - INFO - Regression completed in 11.18 seconds\nestimate variance between mujoco and model is :  0.29332873\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 02:55:23 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 02:55:23 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 02:55:23 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 02:55:23 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 02:55:23 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 02:55:23 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 02:55:23 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 02:55:23 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 02:55:23 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 02:55:23 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 02:55:23 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 02:55:24 PM: Finished problem compilation (took 1.162e+00 seconds).\n(CVXPY) Sep 30 02:55:24 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 02:55:33 PM: Problem status: optimal\n(CVXPY) Sep 30 02:55:33 PM: Optimal value: 6.758e-02\n(CVXPY) Sep 30 02:55:33 PM: Compilation took 1.162e+00 seconds\n(CVXPY) Sep 30 02:55:33 PM: Solver (including time spent in interface) took 8.826e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\n",
    "execution_time": 22.927369832992554,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8d539ca77bd47116d467171851f2576c --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8d539ca77bd47116d467171851f2576c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [28, 1]\n2025-09-30 14:55:45,049 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 14:55:45,049 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:55:45,049 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:55:46,080 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:55:46,080 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:55:46,080 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:55:46,080 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:55:46,080 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 14:55:46,080 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.20e+00  1.00e+00  1.64e+01   ------   \n  1  +1.9648e-01  +1.9546e-01  1.02e-03  6.49e-03  1.50e-03  9.98e-03  1.80e-01  9.89e-01  \n  2  +1.5239e-01  +1.5253e-01  1.44e-04  1.77e-04  4.08e-05  4.45e-04  4.95e-03  9.73e-01  \n  3  +1.1550e-01  +1.1735e-01  1.85e-03  6.25e-05  1.44e-05  2.10e-03  1.75e-03  7.65e-01  \n  4  +9.2640e-02  +9.3333e-02  6.93e-04  3.74e-05  8.60e-06  7.72e-04  1.04e-03  5.32e-01  \n  5  +8.4873e-02  +8.5359e-02  4.86e-04  2.66e-05  6.13e-06  5.36e-04  7.45e-04  4.29e-01  \n  6  +7.4295e-02  +7.4348e-02  5.36e-05  1.05e-05  2.40e-06  6.04e-05  2.93e-04  8.87e-01  \n  7  +7.3718e-02  +7.3780e-02  6.15e-05  9.86e-06  2.27e-06  6.85e-05  2.78e-04  1.94e-01  \n  8  +6.9991e-02  +7.0000e-02  9.25e-06  5.85e-06  1.34e-06  1.09e-05  1.71e-04  6.29e-01  \n  9  +6.8695e-02  +6.8698e-02  3.18e-06  3.65e-06  8.29e-07  3.80e-06  1.23e-04  5.18e-01  \n 10  +6.8110e-02  +6.8111e-02  1.04e-06  1.81e-06  4.09e-07  1.27e-06  8.38e-05  4.17e-01  \n 11  +6.7933e-02  +6.7933e-02  6.91e-07  1.23e-06  2.77e-07  8.38e-07  7.14e-05  2.98e-01  \n 12  +6.7757e-02  +6.7757e-02  2.68e-07  5.09e-07  1.15e-07  3.26e-07  4.29e-05  5.36e-01  \n 13  +6.7681e-02  +6.7681e-02  9.55e-08  1.96e-07  4.43e-08  1.18e-07  2.12e-05  6.11e-01  \n 14  +6.7648e-02  +6.7648e-02  2.34e-08  6.03e-08  1.36e-08  3.03e-08  7.43e-06  7.48e-01  \n 15  +6.7635e-02  +6.7635e-02  4.09e-09  1.10e-08  2.49e-09  5.37e-09  1.45e-06  8.16e-01  \n 16  +6.7632e-02  +6.7632e-02  5.30e-10  1.81e-09  4.08e-10  7.38e-10  2.40e-07  8.64e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.66653711s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 14:55:54,365 - xlsindy.simulation - INFO - Group 2, weight 0.21: [np.int64(2), np.int64(6), np.int64(19), np.int64(59)]\n2025-09-30 14:55:54,365 - xlsindy.simulation - INFO - Group 4, weight 0.19: [np.int64(4), np.int64(12), np.int64(24)]\n2025-09-30 14:55:54,365 - xlsindy.simulation - INFO - Group 5, weight 0.20: [np.int64(5), np.int64(20), np.int64(25)]\n2025-09-30 14:55:54,365 - xlsindy.simulation - INFO - Group 30, weight 0.62: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 14:55:54,400 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:55:54,421 - __main__ - INFO - Regression completed in 9.37 seconds\nestimate variance between mujoco and model is :  1.2654142\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 02:55:46 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 02:55:46 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 02:55:46 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 02:55:46 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 02:55:46 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 02:55:46 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 02:55:46 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 02:55:46 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 02:55:46 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 02:55:46 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 02:55:46 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 02:55:47 PM: Finished problem compilation (took 1.150e+00 seconds).\n(CVXPY) Sep 30 02:55:47 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 02:55:54 PM: Problem status: optimal\n(CVXPY) Sep 30 02:55:54 PM: Optimal value: 6.763e-02\n(CVXPY) Sep 30 02:55:54 PM: Compilation took 1.150e+00 seconds\n(CVXPY) Sep 30 02:55:54 PM: Solver (including time spent in interface) took 7.064e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.91s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.91s/batch]\n",
    "execution_time": 21.18669319152832,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8d539ca77bd47116d467171851f2576c --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8d539ca77bd47116d467171851f2576c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [28, 1]\n2025-09-30 14:56:06,015 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 14:56:06,016 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:56:06,016 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:56:07,057 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:56:07,057 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:56:07,057 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:56:07,057 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:56:07,057 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 14:56:07,057 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.20e+00  1.00e+00  1.64e+01   ------   \n  1  +1.9600e-01  +1.9498e-01  1.02e-03  6.49e-03  1.50e-03  9.98e-03  1.80e-01  9.89e-01  \n  2  +1.5204e-01  +1.5218e-01  1.41e-04  1.75e-04  4.03e-05  4.39e-04  4.89e-03  9.73e-01  \n  3  +1.1740e-01  +1.1932e-01  1.92e-03  6.75e-05  1.56e-05  2.19e-03  1.89e-03  7.45e-01  \n  4  +9.5292e-02  +9.6016e-02  7.24e-04  4.07e-05  9.38e-06  8.11e-04  1.14e-03  5.19e-01  \n  5  +8.7051e-02  +8.7527e-02  4.76e-04  2.91e-05  6.70e-06  5.30e-04  8.12e-04  4.20e-01  \n  6  +7.6175e-02  +7.6232e-02  5.77e-05  1.03e-05  2.35e-06  6.39e-05  2.88e-04  9.90e-01  \n  7  +7.4047e-02  +7.4086e-02  3.95e-05  8.71e-06  2.00e-06  4.38e-05  2.46e-04  3.47e-01  \n  8  +7.1370e-02  +7.1371e-02  1.86e-06  2.95e-06  6.72e-07  2.41e-06  9.01e-05  8.01e-01  \n  9  +7.0233e-02  +7.0234e-02  1.04e-06  8.43e-07  1.89e-07  1.12e-06  5.63e-05  6.70e-01  \n 10  +7.0109e-02  +7.0110e-02  1.27e-07  1.51e-07  3.40e-08  1.41e-07  1.46e-05  8.34e-01  \n 11  +7.0086e-02  +7.0086e-02  2.63e-08  3.60e-08  8.08e-09  2.96e-08  3.85e-06  7.82e-01  \n 12  +7.0080e-02  +7.0080e-02  3.79e-09  5.91e-09  1.33e-09  4.32e-09  6.50e-07  8.52e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 4.431396608s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 14:56:13,078 - xlsindy.simulation - INFO - Group 2, weight 0.17: [np.int64(2), np.int64(6), np.int64(19)]\n2025-09-30 14:56:13,078 - xlsindy.simulation - INFO - Group 3, weight 0.20: [np.int64(3), np.int64(4), np.int64(23)]\n2025-09-30 14:56:13,078 - xlsindy.simulation - INFO - Group 4, weight 0.20: [np.int64(5), np.int64(20), np.int64(25)]\n2025-09-30 14:56:13,078 - xlsindy.simulation - INFO - Group 6, weight 0.20: [np.int64(8), np.int64(9), np.int64(10)]\n2025-09-30 14:56:13,078 - xlsindy.simulation - INFO - Group 8, weight 0.20: [np.int64(12), np.int64(24), np.int64(59)]\n2025-09-30 14:56:13,078 - xlsindy.simulation - INFO - Group 10, weight 0.17: [np.int64(14), np.int64(15), np.int64(40)]\n2025-09-30 14:56:13,078 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:56:13,097 - __main__ - INFO - Regression completed in 7.08 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 02:56:07 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 02:56:07 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 02:56:07 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 02:56:07 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 02:56:07 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 02:56:07 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 02:56:07 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 02:56:07 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 02:56:07 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 02:56:07 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 02:56:07 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 02:56:08 PM: Finished problem compilation (took 1.141e+00 seconds).\n(CVXPY) Sep 30 02:56:08 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 02:56:13 PM: Problem status: optimal\n(CVXPY) Sep 30 02:56:13 PM: Optimal value: 7.008e-02\n(CVXPY) Sep 30 02:56:13 PM: Compilation took 1.141e+00 seconds\n(CVXPY) Sep 30 02:56:13 PM: Solver (including time spent in interface) took 4.814e+00 seconds\n",
    "execution_time": 10.779810428619385,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8d539ca77bd47116d467171851f2576c --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8d539ca77bd47116d467171851f2576c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [28, 1]\n2025-09-30 14:56:17,272 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 14:56:17,272 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:56:17,272 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:56:18,316 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:56:18,316 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:56:18,317 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:56:18,317 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:56:18,317 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 14:56:18,317 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.20e+00  1.00e+00  1.64e+01   ------   \n  1  +1.9656e-01  +1.9553e-01  1.02e-03  6.49e-03  1.50e-03  9.98e-03  1.81e-01  9.89e-01  \n  2  +1.5248e-01  +1.5262e-01  1.44e-04  1.77e-04  4.08e-05  4.45e-04  4.96e-03  9.73e-01  \n  3  +1.1555e-01  +1.1739e-01  1.85e-03  6.24e-05  1.44e-05  2.10e-03  1.74e-03  7.66e-01  \n  4  +9.2641e-02  +9.3336e-02  6.94e-04  3.73e-05  8.58e-06  7.73e-04  1.04e-03  5.33e-01  \n  5  +8.4881e-02  +8.5368e-02  4.88e-04  2.66e-05  6.12e-06  5.38e-04  7.44e-04  4.29e-01  \n  6  +7.4300e-02  +7.4354e-02  5.42e-05  1.05e-05  2.42e-06  6.11e-05  2.96e-04  8.81e-01  \n  7  +7.3709e-02  +7.3771e-02  6.20e-05  9.93e-06  2.28e-06  6.91e-05  2.80e-04  1.96e-01  \n  8  +7.0049e-02  +7.0059e-02  1.05e-05  6.09e-06  1.39e-06  1.23e-05  1.78e-04  5.97e-01  \n  9  +6.8834e-02  +6.8839e-02  4.45e-06  4.22e-06  9.60e-07  5.25e-06  1.37e-04  4.48e-01  \n 10  +6.8065e-02  +6.8066e-02  9.97e-07  1.75e-06  3.96e-07  1.23e-06  8.17e-05  5.70e-01  \n 11  +6.7766e-02  +6.7767e-02  3.95e-07  7.31e-07  1.65e-07  4.82e-07  5.41e-05  4.48e-01  \n 12  +6.7738e-02  +6.7738e-02  3.35e-07  6.33e-07  1.43e-07  4.10e-07  5.02e-05  2.55e-01  \n 13  +6.7703e-02  +6.7704e-02  2.53e-07  5.01e-07  1.13e-07  3.12e-07  4.36e-05  3.77e-01  \n 14  +6.7637e-02  +6.7637e-02  9.00e-08  2.32e-07  5.23e-08  1.17e-07  2.49e-05  8.44e-01  \n 15  +6.7615e-02  +6.7615e-02  2.60e-08  1.28e-07  2.89e-08  4.11e-08  1.50e-05  8.29e-01  \n 16  +6.7594e-02  +6.7594e-02  7.65e-09  5.44e-08  1.23e-08  1.42e-08  6.91e-06  7.11e-01  \n 17  +6.7583e-02  +6.7583e-02  5.32e-10  1.81e-08  4.12e-09  1.68e-09  2.34e-06  9.90e-01  \n 18  +6.7582e-02  +6.7582e-02  6.03e-10  1.36e-08  3.10e-09  1.09e-09  1.56e-06  5.24e-01  \n 19  +6.7581e-02  +6.7581e-02  7.44e-10  1.11e-08  2.52e-09  6.37e-10  1.11e-06  6.11e-01  \n 20  +6.7579e-02  +6.7579e-02  5.62e-10  7.26e-09  1.65e-09  3.43e-10  7.17e-07  6.58e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 7.024276621s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 14:56:26,935 - xlsindy.simulation - INFO - Group 2, weight 0.21: [np.int64(2), np.int64(6), np.int64(19), np.int64(59)]\n2025-09-30 14:56:26,935 - xlsindy.simulation - INFO - Group 4, weight 0.19: [np.int64(4), np.int64(12), np.int64(24)]\n2025-09-30 14:56:26,935 - xlsindy.simulation - INFO - Group 7, weight 0.19: [np.int64(8), np.int64(9), np.int64(10)]\n2025-09-30 14:56:26,935 - xlsindy.simulation - INFO - Group 10, weight 0.16: [np.int64(14), np.int64(15), np.int64(40)]\n2025-09-30 14:56:26,935 - xlsindy.simulation - INFO - Group 29, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 14:56:26,963 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:56:26,983 - __main__ - INFO - Regression completed in 9.71 seconds\nestimate variance between mujoco and model is :  0.23818716\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 02:56:18 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 02:56:18 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 02:56:18 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 02:56:18 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 02:56:18 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 02:56:18 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 02:56:18 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 02:56:18 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 02:56:18 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 02:56:18 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 02:56:19 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 02:56:19 PM: Finished problem compilation (took 1.132e+00 seconds).\n(CVXPY) Sep 30 02:56:19 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 02:56:26 PM: Problem status: optimal\n(CVXPY) Sep 30 02:56:26 PM: Optimal value: 6.758e-02\n(CVXPY) Sep 30 02:56:26 PM: Compilation took 1.132e+00 seconds\n(CVXPY) Sep 30 02:56:26 PM: Solver (including time spent in interface) took 7.403e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.90s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.90s/batch]\n",
    "execution_time": 21.874053955078125,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8d539ca77bd47116d467171851f2576c --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8d539ca77bd47116d467171851f2576c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [1, 1]\n2025-09-30 14:56:39,150 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:56:39,150 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:56:41,904 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.004964110200993067\n2025-09-30 14:56:42,064 - __main__ - INFO - Regression completed in 2.91 seconds\nestimate variance between mujoco and model is :  1.2614521\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.779e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.036e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.678e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.302e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.755e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.200e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.667e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.162e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.237e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.815e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.418e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.347e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.958e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.323e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.721e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.151e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.612e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.104e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.626e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.177e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.755e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.771e-02, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.375e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.930e-01, tolerance: 3.015e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.148e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.148e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.80s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.80s/batch]\n",
    "execution_time": 15.521862506866455,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fdfeccb82dc4438e8c4c72a80ff7e27b --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fdfeccb82dc4438e8c4c72a80ff7e27b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [1, 1]\n2025-09-30 14:56:54,207 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:56:54,207 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:56:56,857 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.004964163318936408\n2025-09-30 14:56:57,027 - __main__ - INFO - Regression completed in 2.82 seconds\nestimate variance between mujoco and model is :  1.0405065\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.981e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.834e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.477e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.015e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.515e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.026e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.566e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.129e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.718e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.330e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.992e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.535e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.939e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.349e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.657e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.053e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.547e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.346e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.574e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.695e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.055e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.081e-01, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.750e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.750e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.74s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.74s/batch]\n",
    "execution_time": 13.857890129089355,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fdfeccb82dc4438e8c4c72a80ff7e27b --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fdfeccb82dc4438e8c4c72a80ff7e27b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [1, 1]\n2025-09-30 14:57:08,287 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:57:08,288 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:57:10,078 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.033843971646032055\n2025-09-30 14:57:10,088 - __main__ - INFO - Regression completed in 1.80 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
    "execution_time": 5.857226133346558,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fdfeccb82dc4438e8c4c72a80ff7e27b --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fdfeccb82dc4438e8c4c72a80ff7e27b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [1, 1]\n2025-09-30 14:57:13,885 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:57:13,885 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:57:16,579 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.004964115512713453\n2025-09-30 14:57:16,725 - __main__ - INFO - Regression completed in 2.84 seconds\nestimate variance between mujoco and model is :  1.2470809\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.969e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.735e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.183e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.655e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.155e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.248e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.844e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.460e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.614e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.510e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.321e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.773e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.256e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.769e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.310e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.879e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.469e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.461e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.911e-01, tolerance: 3.015e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.137e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.137e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.77s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.77s/batch]\n",
    "execution_time": 14.100790977478027,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fdfeccb82dc4438e8c4c72a80ff7e27b --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fdfeccb82dc4438e8c4c72a80ff7e27b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [1, 1]\n2025-09-30 14:57:28,407 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:57:28,407 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:57:28,408 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:57:29,431 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:57:29,431 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:57:29,431 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:57:29,431 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:57:29,431 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:57:29,431 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:57:30,989 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.004964110200993066\n2025-09-30 14:57:31,137 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:57:31,137 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:57:31,138 - __main__ - INFO - Regression completed in 2.73 seconds\nestimate variance between mujoco and model is :  1.2614521\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.779e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.036e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.678e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.302e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.755e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.200e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.667e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.162e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.237e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.815e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.418e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.347e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.958e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.323e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.721e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.151e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.612e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.104e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.626e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.177e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.755e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.771e-02, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.375e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.930e-01, tolerance: 3.015e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.148e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.148e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.71s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.71s/batch]\n",
    "execution_time": 15.593299627304077,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fdfeccb82dc4438e8c4c72a80ff7e27b --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fdfeccb82dc4438e8c4c72a80ff7e27b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [1, 1]\n2025-09-30 14:57:43,585 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:57:43,585 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:57:43,585 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:57:44,614 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:57:44,614 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:57:44,615 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:57:44,615 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:57:44,615 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:57:44,615 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:57:46,035 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.00496416331893641\n2025-09-30 14:57:46,181 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:57:46,182 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:57:46,182 - __main__ - INFO - Regression completed in 2.60 seconds\nestimate variance between mujoco and model is :  1.0405065\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.981e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.834e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.477e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.015e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.515e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.026e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.566e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.129e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.718e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.330e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.992e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.535e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.939e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.349e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.657e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.053e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.547e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.346e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.574e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.695e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.055e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.081e-01, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.750e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.750e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.71s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.71s/batch]\n",
    "execution_time": 14.48116135597229,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fdfeccb82dc4438e8c4c72a80ff7e27b --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fdfeccb82dc4438e8c4c72a80ff7e27b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [1, 1]\n2025-09-30 14:57:58,282 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:57:58,282 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:57:58,282 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:57:59,360 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:57:59,361 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:57:59,361 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:57:59,361 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:57:59,361 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:57:59,361 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:58:00,057 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.033843971646032055\n2025-09-30 14:58:00,069 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:58:00,069 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:58:00,069 - __main__ - INFO - Regression completed in 1.79 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
    "execution_time": 5.7611308097839355,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fdfeccb82dc4438e8c4c72a80ff7e27b --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fdfeccb82dc4438e8c4c72a80ff7e27b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [1, 1]\n2025-09-30 14:58:03,907 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:58:03,907 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:58:03,907 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:58:04,967 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:58:04,967 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:58:04,967 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:58:04,967 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:58:04,968 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:58:04,968 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:58:06,361 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.004964115512713453\n2025-09-30 14:58:06,503 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:58:06,503 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:58:06,504 - __main__ - INFO - Regression completed in 2.60 seconds\nestimate variance between mujoco and model is :  1.2470809\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.969e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.735e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.183e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.655e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.155e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.248e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.844e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.460e-01, tolerance: 4.582e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.614e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e-01, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.510e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.321e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.773e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.256e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.769e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.310e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.879e-02, tolerance: 4.583e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.469e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+00, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.461e-01, tolerance: 3.573e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+00, tolerance: 2.659e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.911e-01, tolerance: 3.015e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.137e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.137e+00, tolerance: 4.609e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.76s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.76s/batch]\n",
    "execution_time": 14.375003814697266,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fdfeccb82dc4438e8c4c72a80ff7e27b --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fdfeccb82dc4438e8c4c72a80ff7e27b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [7, 1]\n2025-09-30 14:58:18,241 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:58:18,241 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:58:19,562 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.06358765232708323\n2025-09-30 14:58:19,566 - __main__ - INFO - Regression completed in 1.32 seconds\nestimate variance between mujoco and model is :  4.5709267\n2025-09-30 14:58:25,564 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 25.35batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.244969129562378,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f48d2d4654bd52bae94ad764c7a7dbea --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f48d2d4654bd52bae94ad764c7a7dbea",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [7, 1]\n2025-09-30 14:58:29,512 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:58:29,513 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:58:30,833 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0635909173454521\n2025-09-30 14:58:30,836 - __main__ - INFO - Regression completed in 1.32 seconds\nestimate variance between mujoco and model is :  4.3681097\n2025-09-30 14:58:36,522 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 23.95batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.031439065933228,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f48d2d4654bd52bae94ad764c7a7dbea --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f48d2d4654bd52bae94ad764c7a7dbea",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [7, 1]\n2025-09-30 14:58:40,522 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:58:40,522 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:58:41,827 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.06867153546532774\n2025-09-30 14:58:41,831 - __main__ - INFO - Regression completed in 1.31 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
    "execution_time": 4.918728351593018,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f48d2d4654bd52bae94ad764c7a7dbea --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f48d2d4654bd52bae94ad764c7a7dbea",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [7, 1]\n2025-09-30 14:58:45,920 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:58:45,921 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:58:47,242 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.06358800279390883\n2025-09-30 14:58:47,246 - __main__ - INFO - Regression completed in 1.33 seconds\nestimate variance between mujoco and model is :  4.5482903\n2025-09-30 14:58:53,013 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 26.59batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.29409909248352,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f48d2d4654bd52bae94ad764c7a7dbea --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f48d2d4654bd52bae94ad764c7a7dbea",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [7, 1]\n2025-09-30 14:58:56,789 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:58:56,789 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:58:56,789 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:58:57,809 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:58:57,809 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:58:57,809 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:58:57,809 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:58:57,809 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:58:57,809 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:58:57,998 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.06358765232708323\n2025-09-30 14:58:58,002 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:58:58,002 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:58:58,002 - __main__ - INFO - Regression completed in 1.21 seconds\nestimate variance between mujoco and model is :  4.5709267\n2025-09-30 14:59:04,110 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 25.50batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.031327724456787,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f48d2d4654bd52bae94ad764c7a7dbea --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f48d2d4654bd52bae94ad764c7a7dbea",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [7, 1]\n2025-09-30 14:59:07,796 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:59:07,796 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:59:07,796 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:59:08,826 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:59:08,826 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:59:08,826 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:59:08,826 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:59:08,826 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:59:08,826 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:59:09,012 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0635909173454521\n2025-09-30 14:59:09,015 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:59:09,015 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:59:09,016 - __main__ - INFO - Regression completed in 1.22 seconds\nestimate variance between mujoco and model is :  4.3681097\n2025-09-30 14:59:14,826 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 26.03batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 10.704951286315918,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f48d2d4654bd52bae94ad764c7a7dbea --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f48d2d4654bd52bae94ad764c7a7dbea",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [7, 1]\n2025-09-30 14:59:18,716 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:59:18,717 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:59:18,717 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:59:19,748 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:59:19,748 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:59:19,748 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:59:19,748 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:59:19,749 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:59:19,749 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:59:19,934 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.06867153546532774\n2025-09-30 14:59:19,938 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:59:19,938 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:59:19,938 - __main__ - INFO - Regression completed in 1.22 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
    "execution_time": 5.3002824783325195,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f48d2d4654bd52bae94ad764c7a7dbea --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f48d2d4654bd52bae94ad764c7a7dbea",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [7, 1]\n2025-09-30 14:59:23,827 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:59:23,827 - __main__ - INFO - Starting mixed regression\n2025-09-30 14:59:23,827 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 14:59:24,889 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 14:59:24,889 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 14:59:24,889 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 14:59:24,889 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 14:59:24,889 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 14:59:24,890 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:59:25,084 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.06358800279390883\n2025-09-30 14:59:25,088 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 14:59:25,088 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 14:59:25,088 - __main__ - INFO - Regression completed in 1.26 seconds\nestimate variance between mujoco and model is :  4.5482903\n2025-09-30 14:59:31,518 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 25.57batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.760037183761597,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/f48d2d4654bd52bae94ad764c7a7dbea --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "f48d2d4654bd52bae94ad764c7a7dbea",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [5, 1]\n2025-09-30 14:59:35,930 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:59:35,930 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:59:37,496 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.02630781940311274\n2025-09-30 14:59:37,501 - __main__ - INFO - Regression completed in 1.57 seconds\nestimate variance between mujoco and model is :  4.5385995\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% 2025-09-30 14:59:43,709 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.67batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.67batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 12.10042405128479,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/3629e5f3baf15ff2c6d8366b75ff67e9 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "3629e5f3baf15ff2c6d8366b75ff67e9",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [5, 1]\n2025-09-30 14:59:47,569 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:59:47,569 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 14:59:49,116 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.026307308758140063\n2025-09-30 14:59:49,121 - __main__ - INFO - Regression completed in 1.55 seconds\nestimate variance between mujoco and model is :  4.3763337\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% 2025-09-30 14:59:54,905 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.49batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.49batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.21770715713501,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/3629e5f3baf15ff2c6d8366b75ff67e9 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "3629e5f3baf15ff2c6d8366b75ff67e9",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [5, 1]\n2025-09-30 14:59:58,904 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 14:59:58,904 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:00:00,481 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.026302703724494007\n2025-09-30 15:00:00,485 - __main__ - INFO - Regression completed in 1.58 seconds\nestimate variance between mujoco and model is :  4.448919\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% 2025-09-30 15:00:07,166 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.71batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.71batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 12.01180100440979,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/3629e5f3baf15ff2c6d8366b75ff67e9 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "3629e5f3baf15ff2c6d8366b75ff67e9",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [5, 1]\n2025-09-30 15:00:11,361 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:00:11,361 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:00:13,034 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.02630776834784437\n2025-09-30 15:00:13,039 - __main__ - INFO - Regression completed in 1.68 seconds\nestimate variance between mujoco and model is :  4.520459\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% 2025-09-30 15:00:19,225 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.65batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.65batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 12.471790075302124,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/3629e5f3baf15ff2c6d8366b75ff67e9 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "3629e5f3baf15ff2c6d8366b75ff67e9",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [5, 1]\n2025-09-30 15:00:23,285 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:00:23,285 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:00:23,286 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:00:24,309 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:00:24,309 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:00:24,309 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:00:24,309 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:00:24,309 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:00:24,309 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:00:24,859 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.026307819403112755\n2025-09-30 15:00:24,864 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:00:24,864 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:00:24,864 - __main__ - INFO - Regression completed in 1.58 seconds\nestimate variance between mujoco and model is :  4.5385995\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% 2025-09-30 15:00:31,242 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.58batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.58batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.611603260040283,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/3629e5f3baf15ff2c6d8366b75ff67e9 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "3629e5f3baf15ff2c6d8366b75ff67e9",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [5, 1]\n2025-09-30 15:00:34,905 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:00:34,905 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:00:34,905 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:00:35,951 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:00:35,951 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:00:35,951 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:00:35,951 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:00:35,951 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:00:35,951 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:00:36,417 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.026307308758140063\n2025-09-30 15:00:36,422 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:00:36,422 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:00:36,422 - __main__ - INFO - Regression completed in 1.52 seconds\nestimate variance between mujoco and model is :  4.3763337\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% 2025-09-30 15:00:42,561 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.69batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.68batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.268101930618286,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/3629e5f3baf15ff2c6d8366b75ff67e9 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "3629e5f3baf15ff2c6d8366b75ff67e9",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [5, 1]\n2025-09-30 15:00:46,417 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:00:46,417 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:00:46,417 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:00:47,424 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:00:47,425 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:00:47,425 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:00:47,425 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:00:47,425 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:00:47,425 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:00:47,917 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.026302703724494007\n2025-09-30 15:00:47,921 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:00:47,921 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:00:47,921 - __main__ - INFO - Regression completed in 1.50 seconds\nestimate variance between mujoco and model is :  4.448919\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% 2025-09-30 15:00:54,441 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.69batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.69batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 12.164039850234985,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/3629e5f3baf15ff2c6d8366b75ff67e9 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "3629e5f3baf15ff2c6d8366b75ff67e9",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [5, 1]\n2025-09-30 15:00:58,341 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:00:58,342 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:00:58,342 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:00:59,354 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:00:59,355 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:00:59,355 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:00:59,355 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:00:59,355 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:00:59,355 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:00:59,803 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.02630776834784437\n2025-09-30 15:00:59,807 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:00:59,807 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:00:59,807 - __main__ - INFO - Regression completed in 1.47 seconds\nestimate variance between mujoco and model is :  4.520459\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% 2025-09-30 15:01:05,665 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.65batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.65batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 10.911523818969727,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/3629e5f3baf15ff2c6d8366b75ff67e9 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "3629e5f3baf15ff2c6d8366b75ff67e9",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [22, 1]\n2025-09-30 15:01:09,613 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:01:09,613 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.775782108306885,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/20d633e4d6355d27b8e9bb7a5c2f3065 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "20d633e4d6355d27b8e9bb7a5c2f3065",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [22, 1]\n2025-09-30 15:01:15,365 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:01:15,365 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.135396718978882,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/20d633e4d6355d27b8e9bb7a5c2f3065 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "20d633e4d6355d27b8e9bb7a5c2f3065",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [22, 1]\n2025-09-30 15:01:21,868 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:01:21,868 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.276287317276001,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/20d633e4d6355d27b8e9bb7a5c2f3065 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "20d633e4d6355d27b8e9bb7a5c2f3065",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [22, 1]\n2025-09-30 15:01:28,309 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:01:28,310 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.674817085266113,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/20d633e4d6355d27b8e9bb7a5c2f3065 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "20d633e4d6355d27b8e9bb7a5c2f3065",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [22, 1]\n2025-09-30 15:01:34,520 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:01:34,520 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:01:34,520 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.849002122879028,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/20d633e4d6355d27b8e9bb7a5c2f3065 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "20d633e4d6355d27b8e9bb7a5c2f3065",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [22, 1]\n2025-09-30 15:01:40,508 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:01:40,508 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:01:40,508 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.483421325683594,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/20d633e4d6355d27b8e9bb7a5c2f3065 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "20d633e4d6355d27b8e9bb7a5c2f3065",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [22, 1]\n2025-09-30 15:01:47,007 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:01:47,007 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:01:47,007 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.102942943572998,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/20d633e4d6355d27b8e9bb7a5c2f3065 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "20d633e4d6355d27b8e9bb7a5c2f3065",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [22, 1]\n2025-09-30 15:01:52,864 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:01:52,864 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:01:52,864 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.817564249038696,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/20d633e4d6355d27b8e9bb7a5c2f3065 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "20d633e4d6355d27b8e9bb7a5c2f3065",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [20, 1]\n2025-09-30 15:01:58,986 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:01:58,986 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.227698087692261,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5ae64c0ece9293a6e8ce48fa8bdd15db --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5ae64c0ece9293a6e8ce48fa8bdd15db",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [20, 1]\n2025-09-30 15:02:05,200 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:05,200 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.199288606643677,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5ae64c0ece9293a6e8ce48fa8bdd15db --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5ae64c0ece9293a6e8ce48fa8bdd15db",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [20, 1]\n2025-09-30 15:02:11,260 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:11,260 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.334021091461182,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5ae64c0ece9293a6e8ce48fa8bdd15db --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5ae64c0ece9293a6e8ce48fa8bdd15db",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [20, 1]\n2025-09-30 15:02:17,759 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:17,759 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.131108045578003,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5ae64c0ece9293a6e8ce48fa8bdd15db --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5ae64c0ece9293a6e8ce48fa8bdd15db",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [20, 1]\n2025-09-30 15:02:23,761 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:23,762 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:02:23,762 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.968118190765381,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5ae64c0ece9293a6e8ce48fa8bdd15db --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5ae64c0ece9293a6e8ce48fa8bdd15db",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [20, 1]\n2025-09-30 15:02:29,729 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:29,729 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:02:29,729 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.0981175899505615,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5ae64c0ece9293a6e8ce48fa8bdd15db --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5ae64c0ece9293a6e8ce48fa8bdd15db",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [20, 1]\n2025-09-30 15:02:36,094 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:36,094 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:02:36,095 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.499572515487671,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5ae64c0ece9293a6e8ce48fa8bdd15db --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5ae64c0ece9293a6e8ce48fa8bdd15db",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [20, 1]\n2025-09-30 15:02:42,267 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:42,267 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:02:42,267 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.931661605834961,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5ae64c0ece9293a6e8ce48fa8bdd15db --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5ae64c0ece9293a6e8ce48fa8bdd15db",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [10, 1]\n2025-09-30 15:02:48,086 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:48,086 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.766759157180786,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/385feebaf1d4cbe254a2ed3a5cbe0191 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "385feebaf1d4cbe254a2ed3a5cbe0191",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [10, 1]\n2025-09-30 15:02:53,850 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:53,850 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.8588786125183105,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/385feebaf1d4cbe254a2ed3a5cbe0191 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "385feebaf1d4cbe254a2ed3a5cbe0191",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [10, 1]\n2025-09-30 15:02:59,874 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:02:59,875 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.04875373840332,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/385feebaf1d4cbe254a2ed3a5cbe0191 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "385feebaf1d4cbe254a2ed3a5cbe0191",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [10, 1]\n2025-09-30 15:03:06,187 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:03:06,188 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.293288230895996,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/385feebaf1d4cbe254a2ed3a5cbe0191 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "385feebaf1d4cbe254a2ed3a5cbe0191",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [10, 1]\n2025-09-30 15:03:12,191 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:03:12,191 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:03:12,191 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.075850963592529,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/385feebaf1d4cbe254a2ed3a5cbe0191 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "385feebaf1d4cbe254a2ed3a5cbe0191",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [10, 1]\n2025-09-30 15:03:18,631 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:03:18,632 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:03:18,632 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.596121788024902,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/385feebaf1d4cbe254a2ed3a5cbe0191 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "385feebaf1d4cbe254a2ed3a5cbe0191",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [10, 1]\n2025-09-30 15:03:25,171 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:03:25,171 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:03:25,171 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.4099225997924805,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/385feebaf1d4cbe254a2ed3a5cbe0191 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "385feebaf1d4cbe254a2ed3a5cbe0191",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [10, 1]\n2025-09-30 15:03:31,138 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:03:31,139 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:03:31,139 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.739346742630005,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/385feebaf1d4cbe254a2ed3a5cbe0191 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "385feebaf1d4cbe254a2ed3a5cbe0191",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [18, 1]\n2025-09-30 15:03:37,110 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:03:37,110 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.055158853530884,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e9a8905515afa9524236ef6d30e1f4c5 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e9a8905515afa9524236ef6d30e1f4c5",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [18, 1]\n2025-09-30 15:03:42,989 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:03:42,989 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.8468897342681885,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e9a8905515afa9524236ef6d30e1f4c5 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e9a8905515afa9524236ef6d30e1f4c5",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [18, 1]\n2025-09-30 15:03:49,570 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:03:49,571 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.6411292552948,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e9a8905515afa9524236ef6d30e1f4c5 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e9a8905515afa9524236ef6d30e1f4c5",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [18, 1]\n2025-09-30 15:03:55,782 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:03:55,782 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.351466178894043,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e9a8905515afa9524236ef6d30e1f4c5 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e9a8905515afa9524236ef6d30e1f4c5",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [18, 1]\n2025-09-30 15:04:01,769 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:04:01,769 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:04:01,769 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.8316650390625,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e9a8905515afa9524236ef6d30e1f4c5 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e9a8905515afa9524236ef6d30e1f4c5",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [18, 1]\n2025-09-30 15:04:07,829 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:04:07,829 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:04:07,829 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.039437770843506,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e9a8905515afa9524236ef6d30e1f4c5 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e9a8905515afa9524236ef6d30e1f4c5",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [18, 1]\n2025-09-30 15:04:13,776 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:04:13,776 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:04:13,776 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.93189001083374,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e9a8905515afa9524236ef6d30e1f4c5 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e9a8905515afa9524236ef6d30e1f4c5",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [18, 1]\n2025-09-30 15:04:19,721 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:04:19,721 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:04:19,721 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.976124048233032,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/e9a8905515afa9524236ef6d30e1f4c5 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "e9a8905515afa9524236ef6d30e1f4c5",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [25, 1]\n2025-09-30 15:04:25,427 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:04:25,427 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:04:26,450 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:04:26,475 - xlsindy.simulation - INFO - Experimental matrix norm: 590.8822039464479\n2025-09-30 15:04:26,475 - xlsindy.simulation - INFO - Experimental matrix variance: 9.878329476529286\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.09e+00  1.00e+00  8.34e+01   ------   \n  1  +6.7934e-01  +6.7840e-01  9.33e-04  6.44e-03  3.27e-04  9.98e-03  9.12e-01  9.89e-01  \n  2  +6.6487e-01  +6.6467e-01  2.03e-04  5.81e-04  2.93e-05  6.61e-04  8.27e-02  9.10e-01  \n  3  +6.1417e-01  +6.2213e-01  7.96e-03  4.85e-04  2.45e-05  8.44e-03  6.91e-02  3.59e-01  \n  4  +5.9561e-01  +5.9648e-01  8.71e-04  1.85e-04  9.35e-06  9.71e-04  2.64e-02  6.65e-01  \n  5  +5.8391e-01  +5.8429e-01  3.87e-04  1.46e-04  7.37e-06  4.32e-04  2.08e-02  3.42e-01  \n  6  +5.7632e-01  +5.7653e-01  2.05e-04  9.09e-05  4.58e-06  2.20e-04  1.30e-02  6.78e-01  \n  7  +5.7487e-01  +5.7505e-01  1.84e-04  7.80e-05  3.93e-06  1.96e-04  1.11e-02  3.76e-01  \n  8  +5.7092e-01  +5.7092e-01  9.86e-07  2.59e-05  1.30e-06  2.68e-06  3.78e-03  9.12e-01  \n  9  +5.6924e-01  +5.6924e-01  9.07e-07  1.95e-05  9.71e-07  1.59e-06  3.28e-03  2.79e-01  \n 10  +5.6839e-01  +5.6839e-01  4.69e-07  7.81e-06  3.86e-07  6.48e-07  2.42e-03  6.72e-01  \n 11  +5.6837e-01  +5.6837e-01  4.61e-07  7.56e-06  3.74e-07  6.35e-07  2.40e-03  6.81e-02  \n 12  +5.6830e-01  +5.6830e-01  3.53e-07  5.54e-06  2.74e-07  4.83e-07  2.10e-03  2.43e-01  \n 13  +5.6824e-01  +5.6824e-01  2.66e-07  3.93e-06  1.95e-07  3.63e-07  1.77e-03  2.72e-01  \n 14  +5.6819e-01  +5.6819e-01  1.95e-07  2.74e-06  1.36e-07  2.68e-07  1.41e-03  3.44e-01  \n 15  +5.6819e-01  +5.6819e-01  1.85e-07  2.54e-06  1.26e-07  2.55e-07  1.33e-03  1.62e-01  \n 16  +5.6819e-01  +5.6819e-01  1.78e-07  2.45e-06  1.21e-07  2.46e-07  1.28e-03  7.77e-02  \n 17  +5.6819e-01  +5.6819e-01  1.37e-07  2.13e-06  1.06e-07  2.02e-07  1.10e-03  5.23e-01  \n 18  +5.6815e-01  +5.6815e-01  9.61e-08  1.36e-06  6.76e-08  1.42e-07  7.69e-04  4.32e-01  \n 19  +5.6813e-01  +5.6813e-01  6.60e-08  8.75e-07  4.37e-08  1.00e-07  5.05e-04  4.84e-01  \n 20  +5.6813e-01  +5.6813e-01  6.03e-08  8.59e-07  4.29e-08  9.44e-08  4.83e-04  1.13e-01  \n 21  +5.6813e-01  +5.6813e-01  5.32e-08  8.04e-07  4.02e-08  8.63e-08  4.36e-04  1.71e-01  \n 22  +5.6814e-01  +5.6814e-01  4.38e-08  8.11e-07  4.05e-08  7.73e-08  4.19e-04  1.67e-01  \n 23  +5.6813e-01  +5.6813e-01  3.93e-08  7.30e-07  3.65e-08  7.09e-08  3.71e-04  1.57e-01  \n 24  +5.6813e-01  +5.6813e-01  2.83e-08  6.70e-07  3.35e-08  5.89e-08  3.18e-04  3.06e-01  \n 25  +5.6813e-01  +5.6813e-01  2.42e-08  6.35e-07  3.18e-08  5.43e-08  2.90e-04  1.67e-01  \n 26  +5.6813e-01  +5.6813e-01  1.76e-08  6.42e-07  3.21e-08  4.81e-08  2.78e-04  1.79e-01  \n 27  +5.6812e-01  +5.6812e-01  1.67e-08  4.42e-07  2.22e-08  4.14e-08  1.86e-04  3.57e-01  \n 28  +5.6812e-01  +5.6812e-01  4.37e-09  4.19e-07  2.10e-08  3.01e-08  1.52e-04  5.19e-01  \n 29  +5.6812e-01  +5.6812e-01  2.68e-09  3.83e-07  1.92e-08  2.79e-08  1.31e-04  2.36e-01  \n 30  +5.6812e-01  +5.6812e-01  3.47e-10  3.70e-07  1.86e-08  2.58e-08  1.19e-04  2.23e-01  \n 31  +5.6812e-01  +5.6812e-01  7.19e-10  3.63e-07  1.82e-08  2.49e-08  1.13e-04  1.20e-01  \n 32  +5.6813e-01  +5.6813e-01  1.35e-08  3.56e-07  1.79e-08  1.53e-08  8.23e-05  9.90e-01  \n 33  +5.6811e-01  +5.6811e-01  6.68e-09  1.96e-07  9.85e-09  1.54e-08  4.28e-05  4.72e-01  \n 34  +5.6810e-01  +5.6810e-01  5.47e-09  1.65e-07  8.31e-09  1.60e-08  3.33e-05  3.52e-01  \n 35  +5.6809e-01  +5.6809e-01  5.07e-09  1.53e-07  7.68e-09  1.68e-08  2.87e-05  3.09e-01  \n 36  +5.6808e-01  +5.6808e-01  2.36e-09  1.12e-07  5.66e-09  1.91e-08  1.82e-05  6.38e-01  \n 37  +5.6806e-01  +5.6806e-01  5.48e-10  9.12e-08  4.60e-09  2.07e-08  1.33e-05  5.20e-01  \n 38  +5.6804e-01  +5.6804e-01  1.96e-09  7.04e-08  3.55e-09  2.30e-08  9.04e-06  6.60e-01  \n 39  +5.6801e-01  +5.6801e-01  3.50e-09  5.80e-08  2.92e-09  2.36e-08  6.95e-06  3.99e-01  \n 40  +5.6797e-01  +5.6797e-01  5.75e-09  4.30e-08  2.17e-09  2.38e-08  4.86e-06  3.82e-01  \n 41  +5.6782e-01  +5.6782e-01  1.00e-08  1.83e-08  9.23e-10  2.20e-08  1.75e-06  9.90e-01  \n 42  +5.6761e-01  +5.6761e-01  6.53e-09  5.18e-09  2.62e-10  1.12e-08  4.60e-07  9.17e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 13.170031672s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:04:41,316 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -1.55702633e-17 -1.55702633e-17 ... -1.55702633e-17\n  -1.55702633e-17 -1.55702633e-17]\n [-1.55702633e-17 -1.00000000e+00 -1.55702633e-17 ... -1.55702633e-17\n  -1.55702633e-17 -1.55702633e-17]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  4.51850693e-01\n  -2.31761786e-01  1.12512609e-03]\n ...\n [ 0.00000000e+00  0.00000000e+00  5.47294901e-01 ... -1.00000000e+00\n   4.87115228e-01 -8.84729516e-04]\n [ 0.00000000e+00  0.00000000e+00 -4.44778057e-01 ...  7.70792927e-01\n  -1.00000000e+00  6.40473927e-03]\n [ 0.00000000e+00  0.00000000e+00 -2.04694645e-02 ...  1.74882540e-02\n   1.64303613e-02 -1.00000000e+00]]\n2025-09-30 15:04:41,363 - xlsindy.simulation - INFO - Group 23, weight 0.52: [np.int64(29), np.int64(39), np.int64(48), np.int64(53), np.int64(61)]\n2025-09-30 15:04:41,363 - xlsindy.simulation - INFO - Group 32, weight 0.79: [np.int64(40), np.int64(41), np.int64(43), np.int64(44), np.int64(45), np.int64(47), np.int64(54), np.int64(57), np.int64(60), np.int64(68), np.int64(69), np.int64(78), np.int64(90), np.int64(93)]\n2025-09-30 15:04:41,412 - __main__ - INFO - Regression completed in 15.98 seconds\nestimate variance between mujoco and model is :  0.6567459\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:04:26 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:04:26 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:04:26 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:04:26 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:04:26 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:04:26 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:04:26 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:04:26 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:04:26 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:04:26 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:04:27 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:04:27 PM: Finished problem compilation (took 1.182e+00 seconds).\n(CVXPY) Sep 30 03:04:27 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:04:41 PM: Problem status: optimal\n(CVXPY) Sep 30 03:04:41 PM: Optimal value: 5.674e-01\n(CVXPY) Sep 30 03:04:41 PM: Compilation took 1.182e+00 seconds\n(CVXPY) Sep 30 03:04:41 PM: Solver (including time spent in interface) took 1.355e+01 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.55s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.55s/batch]\n",
    "execution_time": 27.552680730819702,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a21e193d88e5a12c10ae913b1292c6b2 --algorithm mixed --regression-type implicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a21e193d88e5a12c10ae913b1292c6b2",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [25, 1]\n2025-09-30 15:04:52,964 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:04:52,964 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:04:53,988 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:04:54,003 - xlsindy.simulation - INFO - Experimental matrix norm: 590.9499317955034\n2025-09-30 15:04:54,003 - xlsindy.simulation - INFO - Experimental matrix variance: 9.8805944355725\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.09e+00  1.00e+00  8.34e+01   ------   \n  1  +6.7927e-01  +6.7834e-01  9.33e-04  6.44e-03  3.27e-04  9.98e-03  9.12e-01  9.89e-01  \n  2  +6.6479e-01  +6.6459e-01  2.03e-04  5.81e-04  2.93e-05  6.62e-04  8.27e-02  9.10e-01  \n  3  +6.1409e-01  +6.2208e-01  7.99e-03  4.85e-04  2.45e-05  8.46e-03  6.91e-02  3.59e-01  \n  4  +5.9550e-01  +5.9638e-01  8.74e-04  1.85e-04  9.35e-06  9.76e-04  2.64e-02  6.64e-01  \n  5  +5.8378e-01  +5.8417e-01  3.89e-04  1.46e-04  7.36e-06  4.34e-04  2.08e-02  3.41e-01  \n  6  +5.7614e-01  +5.7634e-01  2.05e-04  9.06e-05  4.56e-06  2.20e-04  1.29e-02  6.80e-01  \n  7  +5.7470e-01  +5.7489e-01  1.85e-04  7.81e-05  3.93e-06  1.97e-04  1.12e-02  3.68e-01  \n  8  +5.7073e-01  +5.7073e-01  1.09e-06  2.59e-05  1.30e-06  2.78e-06  3.78e-03  9.18e-01  \n  9  +5.6928e-01  +5.6928e-01  1.03e-06  2.10e-05  1.05e-06  1.84e-06  3.38e-03  2.16e-01  \n 10  +5.6917e-01  +5.6917e-01  1.23e-06  1.98e-05  9.90e-07  2.03e-06  3.36e-03  7.08e-02  \n 11  +5.6861e-01  +5.6861e-01  9.27e-07  1.23e-05  6.14e-07  1.41e-06  2.83e-03  2.51e-01  \n 12  +5.6842e-01  +5.6842e-01  9.01e-07  9.38e-06  4.68e-07  1.31e-06  2.59e-03  2.01e-01  \n 13  +5.6801e-01  +5.6801e-01  4.88e-07  3.73e-06  1.86e-07  6.78e-07  1.67e-03  5.21e-01  \n 14  +5.6791e-01  +5.6791e-01  4.10e-07  2.73e-06  1.37e-07  5.67e-07  1.39e-03  4.17e-01  \n 15  +5.6775e-01  +5.6775e-01  2.51e-07  1.59e-06  7.97e-08  3.45e-07  1.05e-03  6.04e-01  \n 16  +5.6773e-01  +5.6773e-01  1.90e-07  1.20e-06  6.01e-08  2.72e-07  7.94e-04  4.76e-01  \n 17  +5.6758e-01  +5.6758e-01  4.68e-08  3.54e-07  1.78e-08  7.08e-08  2.80e-04  7.88e-01  \n 18  +5.6751e-01  +5.6751e-01  8.48e-09  1.22e-07  6.11e-09  1.73e-08  9.08e-05  8.40e-01  \n 19  +5.6747e-01  +5.6747e-01  1.23e-09  2.31e-08  1.16e-09  2.95e-09  1.77e-05  8.74e-01  \n 20  +5.6746e-01  +5.6746e-01  2.05e-10  4.21e-09  2.12e-10  5.22e-10  3.18e-06  8.31e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.476367748s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:05:02,149 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -3.80685186e-19 -3.80685186e-19 ... -3.80685186e-19\n  -3.80685186e-19 -3.80685186e-19]\n [-3.80685186e-19 -1.00000000e+00 -3.80685186e-19 ... -3.80685186e-19\n  -3.80685186e-19 -3.80685186e-19]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  4.59078620e-01\n  -2.21102340e-01  1.16037393e-02]\n ...\n [ 0.00000000e+00  0.00000000e+00  5.50364481e-01 ... -1.00000000e+00\n   4.91213695e-01 -3.24662044e-03]\n [ 0.00000000e+00  0.00000000e+00 -4.18041964e-01 ...  7.72090120e-01\n  -1.00000000e+00  1.29066113e-02]\n [ 0.00000000e+00  0.00000000e+00  4.78382325e-01 ...  1.77799821e-02\n   1.52361598e-01 -1.00000000e+00]]\n2025-09-30 15:05:02,179 - xlsindy.simulation - INFO - Group 27, weight 0.67: [np.int64(33), np.int64(45), np.int64(62), np.int64(90), np.int64(93)]\n2025-09-30 15:05:02,179 - xlsindy.simulation - INFO - Group 35, weight 0.75: [np.int64(43), np.int64(48), np.int64(58)]\n2025-09-30 15:05:02,179 - xlsindy.simulation - INFO - Group 41, weight 0.63: [np.int64(53), np.int64(61), np.int64(78)]\n2025-09-30 15:05:02,254 - __main__ - INFO - Regression completed in 9.29 seconds\nestimate variance between mujoco and model is :  3.035602\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:04:54 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:04:54 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:04:54 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:04:54 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:04:54 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:04:54 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:04:54 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:04:54 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:04:54 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:04:54 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:04:54 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:04:55 PM: Finished problem compilation (took 1.154e+00 seconds).\n(CVXPY) Sep 30 03:04:55 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:05:02 PM: Problem status: optimal\n(CVXPY) Sep 30 03:05:02 PM: Optimal value: 5.675e-01\n(CVXPY) Sep 30 03:05:02 PM: Compilation took 1.154e+00 seconds\n(CVXPY) Sep 30 03:05:02 PM: Solver (including time spent in interface) took 6.876e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.79s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.79s/batch]\n",
    "execution_time": 21.033804416656494,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a21e193d88e5a12c10ae913b1292c6b2 --algorithm mixed --regression-type implicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a21e193d88e5a12c10ae913b1292c6b2",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [25, 1]\n2025-09-30 15:05:13,856 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:05:13,856 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:05:14,871 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:05:14,893 - xlsindy.simulation - INFO - Experimental matrix norm: 591.5701924399399\n2025-09-30 15:05:14,893 - xlsindy.simulation - INFO - Experimental matrix variance: 9.901349188794477\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.09e+00  1.00e+00  8.35e+01   ------   \n  1  +6.7900e-01  +6.7806e-01  9.32e-04  6.44e-03  3.27e-04  9.99e-03  9.13e-01  9.89e-01  \n  2  +6.6443e-01  +6.6423e-01  1.97e-04  5.83e-04  2.94e-05  6.71e-04  8.30e-02  9.10e-01  \n  3  +6.1386e-01  +6.2197e-01  8.12e-03  4.89e-04  2.47e-05  8.60e-03  6.96e-02  3.55e-01  \n  4  +5.9507e-01  +5.9590e-01  8.33e-04  1.84e-04  9.30e-06  9.35e-04  2.63e-02  6.68e-01  \n  5  +5.8346e-01  +5.8380e-01  3.46e-04  1.52e-04  7.65e-06  3.91e-04  2.16e-02  2.98e-01  \n  6  +5.7505e-01  +5.7523e-01  1.89e-04  8.15e-05  4.10e-06  2.00e-04  1.16e-02  8.69e-01  \n  7  +5.7391e-01  +5.7407e-01  1.62e-04  7.41e-05  3.72e-06  1.71e-04  1.06e-02  2.79e-01  \n  8  +5.7073e-01  +5.7074e-01  5.88e-06  2.70e-05  1.35e-06  7.22e-06  4.00e-03  9.31e-01  \n  9  +5.6955e-01  +5.6955e-01  3.35e-06  2.03e-05  1.01e-06  3.94e-06  3.48e-03  2.94e-01  \n 10  +5.6886e-01  +5.6886e-01  5.74e-07  5.32e-06  2.62e-07  6.75e-07  1.75e-03  6.40e-01  \n 11  +5.6869e-01  +5.6869e-01  2.07e-07  1.20e-06  5.91e-08  2.29e-07  7.16e-04  7.72e-01  \n 12  +5.6866e-01  +5.6866e-01  3.03e-08  2.02e-07  9.94e-09  3.40e-08  1.41e-04  8.43e-01  \n 13  +5.6865e-01  +5.6865e-01  4.46e-09  3.48e-08  1.71e-09  5.09e-09  2.49e-05  8.48e-01  \n 14  +5.6865e-01  +5.6865e-01  5.33e-10  5.60e-09  2.75e-10  6.35e-10  4.03e-06  8.76e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 4.84859954s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:05:21,413 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00  2.20115130e-20  2.20115130e-20 ...  2.20115130e-20\n   2.20115130e-20  2.20115130e-20]\n [ 2.20115130e-20 -1.00000000e+00  2.20115130e-20 ...  2.20115130e-20\n   2.20115130e-20  2.20115130e-20]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  5.01206290e-01\n  -2.60050920e-01  4.94091498e-02]\n ...\n [ 0.00000000e+00  0.00000000e+00  5.41099310e-01 ... -1.00000000e+00\n   6.76126601e-01 -9.74986986e-03]\n [ 0.00000000e+00  0.00000000e+00 -3.52787292e-01 ...  8.52211398e-01\n  -1.00000000e+00  1.50362327e-01]\n [ 0.00000000e+00  0.00000000e+00  3.83952222e-02 ... -4.39440074e-03\n   9.02912946e-02 -1.00000000e+00]]\n2025-09-30 15:05:21,467 - __main__ - INFO - Regression completed in 7.61 seconds\n",
    "stderr": "(CVXPY) Sep 30 03:05:14 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:05:14 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:05:14 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:05:14 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:05:14 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:05:14 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:05:14 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:05:14 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:05:14 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:05:14 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:05:15 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:05:16 PM: Finished problem compilation (took 1.183e+00 seconds).\n(CVXPY) Sep 30 03:05:16 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:05:21 PM: Problem status: optimal\n(CVXPY) Sep 30 03:05:21 PM: Optimal value: 5.687e-01\n(CVXPY) Sep 30 03:05:21 PM: Compilation took 1.183e+00 seconds\n(CVXPY) Sep 30 03:05:21 PM: Solver (including time spent in interface) took 5.227e+00 seconds\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 243, in <module>\n    xlsindy.dynamics_modeling.generate_acceleration_function(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/dynamics_modeling.py\", line 67, in generate_acceleration_function\n    if str(symbol_matrix[3, i]) not in str(dynamic_equations[i]):\nIndexError: index 0 is out of bounds for axis 0 with size 0\n",
    "execution_time": 11.09454083442688,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a21e193d88e5a12c10ae913b1292c6b2 --algorithm mixed --regression-type implicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a21e193d88e5a12c10ae913b1292c6b2",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [25, 1]\n2025-09-30 15:05:25,219 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:05:25,219 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:05:26,319 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:05:26,335 - xlsindy.simulation - INFO - Experimental matrix norm: 590.888965342358\n2025-09-30 15:05:26,335 - xlsindy.simulation - INFO - Experimental matrix variance: 9.878555580018384\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.09e+00  1.00e+00  8.34e+01   ------   \n  1  +6.7933e-01  +6.7840e-01  9.33e-04  6.44e-03  3.27e-04  9.98e-03  9.12e-01  9.89e-01  \n  2  +6.6486e-01  +6.6466e-01  2.03e-04  5.81e-04  2.93e-05  6.61e-04  8.27e-02  9.10e-01  \n  3  +6.1416e-01  +6.2213e-01  7.97e-03  4.85e-04  2.45e-05  8.44e-03  6.91e-02  3.59e-01  \n  4  +5.9560e-01  +5.9647e-01  8.71e-04  1.85e-04  9.35e-06  9.72e-04  2.64e-02  6.65e-01  \n  5  +5.8389e-01  +5.8428e-01  3.87e-04  1.46e-04  7.37e-06  4.32e-04  2.08e-02  3.42e-01  \n  6  +5.7631e-01  +5.7651e-01  2.05e-04  9.09e-05  4.58e-06  2.20e-04  1.30e-02  6.78e-01  \n  7  +5.7485e-01  +5.7504e-01  1.84e-04  7.80e-05  3.93e-06  1.97e-04  1.12e-02  3.75e-01  \n  8  +5.7090e-01  +5.7090e-01  9.97e-07  2.59e-05  1.30e-06  2.69e-06  3.78e-03  9.13e-01  \n  9  +5.6921e-01  +5.6922e-01  9.13e-07  1.95e-05  9.71e-07  1.59e-06  3.28e-03  2.79e-01  \n 10  +5.6841e-01  +5.6841e-01  4.96e-07  8.81e-06  4.36e-07  7.02e-07  2.53e-03  5.83e-01  \n 11  +5.6839e-01  +5.6839e-01  4.94e-07  8.39e-06  4.15e-07  6.93e-07  2.50e-03  8.69e-02  \n 12  +5.6829e-01  +5.6829e-01  3.69e-07  5.56e-06  2.75e-07  5.10e-07  2.12e-03  2.82e-01  \n 13  +5.6824e-01  +5.6824e-01  3.11e-07  4.21e-06  2.09e-07  4.26e-07  1.84e-03  2.58e-01  \n 14  +5.6821e-01  +5.6821e-01  2.71e-07  3.44e-06  1.71e-07  3.71e-07  1.63e-03  1.84e-01  \n 15  +5.6818e-01  +5.6818e-01  2.20e-07  2.57e-06  1.28e-07  3.02e-07  1.32e-03  3.53e-01  \n 16  +5.6818e-01  +5.6818e-01  2.18e-07  2.51e-06  1.25e-07  3.01e-07  1.29e-03  7.58e-02  \n 17  +5.6818e-01  +5.6818e-01  2.12e-07  2.53e-06  1.26e-07  2.94e-07  1.29e-03  1.42e-02  \n 18  +5.6815e-01  +5.6815e-01  1.66e-07  1.80e-06  8.98e-08  2.33e-07  9.93e-04  3.62e-01  \n 19  +5.6815e-01  +5.6815e-01  1.46e-07  1.58e-06  7.91e-08  2.09e-07  8.58e-04  2.68e-01  \n 20  +5.6816e-01  +5.6816e-01  7.47e-08  1.30e-06  6.50e-08  1.37e-07  6.06e-04  7.92e-01  \n 21  +5.6814e-01  +5.6814e-01  5.27e-08  9.91e-07  4.96e-08  1.04e-07  4.36e-04  4.57e-01  \n 22  +5.6812e-01  +5.6812e-01  4.53e-08  7.33e-07  3.68e-08  9.08e-08  3.20e-04  3.61e-01  \n 23  +5.6813e-01  +5.6813e-01  4.12e-08  7.18e-07  3.60e-08  8.75e-08  3.05e-04  1.29e-01  \n 24  +5.6812e-01  +5.6812e-01  3.44e-08  6.53e-07  3.28e-08  7.97e-08  2.67e-04  2.31e-01  \n 25  +5.6813e-01  +5.6813e-01  2.82e-08  6.41e-07  3.22e-08  7.38e-08  2.51e-04  1.66e-01  \n 26  +5.6813e-01  +5.6813e-01  2.28e-08  6.26e-07  3.14e-08  6.85e-08  2.36e-04  1.62e-01  \n 27  +5.6814e-01  +5.6814e-01  8.14e-09  6.15e-07  3.09e-08  5.52e-08  2.05e-04  4.31e-01  \n 28  +5.6812e-01  +5.6812e-01  9.12e-09  5.21e-07  2.62e-08  5.31e-08  1.67e-04  2.18e-01  \n 29  +5.6812e-01  +5.6812e-01  7.41e-09  5.22e-07  2.62e-08  5.11e-08  1.66e-04  4.25e-02  \n 30  +5.6808e-01  +5.6808e-01  1.57e-08  2.60e-07  1.31e-08  4.70e-08  8.07e-05  5.43e-01  \n 31  +5.6807e-01  +5.6807e-01  1.50e-08  2.27e-07  1.14e-08  4.50e-08  6.74e-05  2.26e-01  \n 32  +5.6801e-01  +5.6801e-01  8.32e-09  1.11e-07  5.59e-09  3.10e-08  2.67e-05  9.76e-01  \n 33  +5.6797e-01  +5.6797e-01  8.89e-09  8.35e-08  4.21e-09  2.91e-08  1.91e-05  3.83e-01  \n 34  +5.6794e-01  +5.6794e-01  8.71e-09  6.88e-08  3.47e-09  2.76e-08  1.48e-05  3.92e-01  \n 35  +5.6786e-01  +5.6786e-01  8.89e-09  4.39e-08  2.21e-09  2.42e-08  8.51e-06  6.68e-01  \n 36  +5.6774e-01  +5.6774e-01  7.87e-09  2.48e-08  1.25e-09  1.88e-08  4.32e-06  7.41e-01  \n 37  +5.6773e-01  +5.6773e-01  7.55e-09  2.28e-08  1.15e-09  1.79e-08  3.90e-06  1.60e-01  \n 38  +5.6771e-01  +5.6771e-01  7.05e-09  2.13e-08  1.07e-09  1.70e-08  3.49e-06  4.05e-01  \n 39  +5.6762e-01  +5.6762e-01  5.43e-09  1.33e-08  6.69e-10  1.24e-08  2.06e-06  5.21e-01  \n 40  +5.6746e-01  +5.6746e-01  1.61e-09  2.02e-09  1.04e-10  2.87e-09  3.12e-07  8.92e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 12.141276313s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:05:40,225 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -4.82923174e-18 -4.82923174e-18 ... -4.82923174e-18\n  -4.82923174e-18 -4.82923174e-18]\n [-4.82923174e-18 -1.00000000e+00 -4.82923174e-18 ... -4.82923174e-18\n  -4.82923174e-18 -4.82923174e-18]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  4.52508622e-01\n  -2.30298015e-01  2.27604010e-03]\n ...\n [ 0.00000000e+00  0.00000000e+00  5.47519893e-01 ... -1.00000000e+00\n   4.87095791e-01 -1.25606246e-03]\n [ 0.00000000e+00  0.00000000e+00 -4.42533623e-01 ...  7.71029787e-01\n  -1.00000000e+00  6.79401325e-03]\n [ 0.00000000e+00  0.00000000e+00 -2.12494383e-02 ...  1.78798068e-02\n   1.04124699e-02 -1.00000000e+00]]\n2025-09-30 15:05:40,250 - xlsindy.simulation - INFO - Group 25, weight 0.74: [np.int64(31), np.int64(33), np.int64(39), np.int64(40), np.int64(43), np.int64(45), np.int64(48), np.int64(53), np.int64(57), np.int64(58), np.int64(60), np.int64(61), np.int64(69), np.int64(78), np.int64(90), np.int64(93)]\n2025-09-30 15:05:40,250 - xlsindy.simulation - INFO - Group 32, weight 0.66: [np.int64(44), np.int64(54), np.int64(62)]\n2025-09-30 15:05:40,325 - __main__ - INFO - Regression completed in 15.11 seconds\nestimate variance between mujoco and model is :  0.115643665\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:05:26 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:05:26 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:05:26 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:05:26 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:05:26 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:05:26 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:05:26 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:05:26 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:05:26 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:05:26 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:05:27 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:05:27 PM: Finished problem compilation (took 1.207e+00 seconds).\n(CVXPY) Sep 30 03:05:27 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:05:40 PM: Problem status: optimal\n(CVXPY) Sep 30 03:05:40 PM: Optimal value: 5.674e-01\n(CVXPY) Sep 30 03:05:40 PM: Compilation took 1.207e+00 seconds\n(CVXPY) Sep 30 03:05:40 PM: Solver (including time spent in interface) took 1.257e+01 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.50s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.50s/batch]\n",
    "execution_time": 26.86252474784851,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a21e193d88e5a12c10ae913b1292c6b2 --algorithm mixed --regression-type implicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a21e193d88e5a12c10ae913b1292c6b2",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [25, 1]\n2025-09-30 15:05:51,808 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:05:51,808 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:05:51,808 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:05:52,866 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:05:52,866 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:05:52,866 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:05:52,866 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:05:52,867 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:05:52,867 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.09e+00  1.00e+00  8.34e+01   ------   \n  1  +6.7934e-01  +6.7840e-01  9.33e-04  6.44e-03  3.27e-04  9.98e-03  9.12e-01  9.89e-01  \n  2  +6.6487e-01  +6.6467e-01  2.03e-04  5.81e-04  2.93e-05  6.61e-04  8.27e-02  9.10e-01  \n  3  +6.1417e-01  +6.2213e-01  7.96e-03  4.85e-04  2.45e-05  8.44e-03  6.91e-02  3.59e-01  \n  4  +5.9561e-01  +5.9648e-01  8.71e-04  1.85e-04  9.35e-06  9.71e-04  2.64e-02  6.65e-01  \n  5  +5.8391e-01  +5.8429e-01  3.87e-04  1.46e-04  7.37e-06  4.32e-04  2.08e-02  3.42e-01  \n  6  +5.7632e-01  +5.7653e-01  2.05e-04  9.09e-05  4.58e-06  2.20e-04  1.30e-02  6.78e-01  \n  7  +5.7487e-01  +5.7505e-01  1.84e-04  7.80e-05  3.93e-06  1.96e-04  1.11e-02  3.76e-01  \n  8  +5.7092e-01  +5.7092e-01  9.86e-07  2.59e-05  1.30e-06  2.68e-06  3.78e-03  9.12e-01  \n  9  +5.6924e-01  +5.6924e-01  9.07e-07  1.95e-05  9.71e-07  1.59e-06  3.28e-03  2.79e-01  \n 10  +5.6839e-01  +5.6839e-01  4.69e-07  7.81e-06  3.86e-07  6.48e-07  2.42e-03  6.72e-01  \n 11  +5.6837e-01  +5.6837e-01  4.61e-07  7.56e-06  3.74e-07  6.35e-07  2.40e-03  6.81e-02  \n 12  +5.6830e-01  +5.6830e-01  3.53e-07  5.54e-06  2.74e-07  4.83e-07  2.10e-03  2.43e-01  \n 13  +5.6824e-01  +5.6824e-01  2.66e-07  3.93e-06  1.95e-07  3.63e-07  1.77e-03  2.72e-01  \n 14  +5.6819e-01  +5.6819e-01  1.95e-07  2.74e-06  1.36e-07  2.68e-07  1.41e-03  3.44e-01  \n 15  +5.6819e-01  +5.6819e-01  1.85e-07  2.54e-06  1.26e-07  2.55e-07  1.33e-03  1.62e-01  \n 16  +5.6819e-01  +5.6819e-01  1.78e-07  2.45e-06  1.21e-07  2.46e-07  1.28e-03  7.77e-02  \n 17  +5.6819e-01  +5.6819e-01  1.37e-07  2.13e-06  1.06e-07  2.02e-07  1.10e-03  5.23e-01  \n 18  +5.6815e-01  +5.6815e-01  9.61e-08  1.36e-06  6.76e-08  1.42e-07  7.69e-04  4.32e-01  \n 19  +5.6813e-01  +5.6813e-01  6.60e-08  8.75e-07  4.37e-08  1.00e-07  5.05e-04  4.84e-01  \n 20  +5.6813e-01  +5.6813e-01  6.03e-08  8.59e-07  4.29e-08  9.44e-08  4.83e-04  1.13e-01  \n 21  +5.6813e-01  +5.6813e-01  5.32e-08  8.04e-07  4.02e-08  8.63e-08  4.36e-04  1.71e-01  \n 22  +5.6814e-01  +5.6814e-01  4.38e-08  8.11e-07  4.05e-08  7.73e-08  4.19e-04  1.67e-01  \n 23  +5.6813e-01  +5.6813e-01  3.93e-08  7.30e-07  3.65e-08  7.09e-08  3.71e-04  1.57e-01  \n 24  +5.6813e-01  +5.6813e-01  2.83e-08  6.70e-07  3.35e-08  5.89e-08  3.18e-04  3.06e-01  \n 25  +5.6813e-01  +5.6813e-01  2.42e-08  6.35e-07  3.18e-08  5.43e-08  2.90e-04  1.67e-01  \n 26  +5.6813e-01  +5.6813e-01  1.76e-08  6.42e-07  3.21e-08  4.81e-08  2.78e-04  1.79e-01  \n 27  +5.6812e-01  +5.6812e-01  1.67e-08  4.42e-07  2.22e-08  4.14e-08  1.86e-04  3.57e-01  \n 28  +5.6812e-01  +5.6812e-01  4.37e-09  4.19e-07  2.10e-08  3.01e-08  1.52e-04  5.19e-01  \n 29  +5.6812e-01  +5.6812e-01  2.68e-09  3.83e-07  1.92e-08  2.79e-08  1.31e-04  2.36e-01  \n 30  +5.6812e-01  +5.6812e-01  3.47e-10  3.70e-07  1.86e-08  2.58e-08  1.19e-04  2.23e-01  \n 31  +5.6812e-01  +5.6812e-01  7.19e-10  3.63e-07  1.82e-08  2.49e-08  1.13e-04  1.20e-01  \n 32  +5.6813e-01  +5.6813e-01  1.35e-08  3.56e-07  1.79e-08  1.53e-08  8.23e-05  9.90e-01  \n 33  +5.6811e-01  +5.6811e-01  6.68e-09  1.96e-07  9.85e-09  1.54e-08  4.28e-05  4.72e-01  \n 34  +5.6810e-01  +5.6810e-01  5.47e-09  1.65e-07  8.31e-09  1.60e-08  3.33e-05  3.52e-01  \n 35  +5.6809e-01  +5.6809e-01  5.07e-09  1.53e-07  7.68e-09  1.68e-08  2.87e-05  3.09e-01  \n 36  +5.6808e-01  +5.6808e-01  2.36e-09  1.12e-07  5.66e-09  1.91e-08  1.82e-05  6.38e-01  \n 37  +5.6806e-01  +5.6806e-01  5.48e-10  9.12e-08  4.60e-09  2.07e-08  1.33e-05  5.20e-01  \n 38  +5.6804e-01  +5.6804e-01  1.96e-09  7.04e-08  3.55e-09  2.30e-08  9.04e-06  6.60e-01  \n 39  +5.6801e-01  +5.6801e-01  3.50e-09  5.80e-08  2.92e-09  2.36e-08  6.95e-06  3.99e-01  \n 40  +5.6797e-01  +5.6797e-01  5.75e-09  4.30e-08  2.17e-09  2.38e-08  4.86e-06  3.82e-01  \n 41  +5.6782e-01  +5.6782e-01  1.00e-08  1.83e-08  9.23e-10  2.20e-08  1.75e-06  9.90e-01  \n 42  +5.6761e-01  +5.6761e-01  6.53e-09  5.18e-09  2.62e-10  1.12e-08  4.60e-07  9.17e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 13.013723581s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:06:07,460 - xlsindy.simulation - INFO - Group 23, weight 0.78: [np.int64(29), np.int64(39), np.int64(40), np.int64(41), np.int64(43), np.int64(44), np.int64(45), np.int64(47), np.int64(48), np.int64(53), np.int64(54), np.int64(57), np.int64(60), np.int64(61), np.int64(68), np.int64(69), np.int64(78), np.int64(90), np.int64(93)]\n2025-09-30 15:06:07,508 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:06:07,527 - __main__ - INFO - Regression completed in 15.72 seconds\nestimate variance between mujoco and model is :  0.10232363\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:05:52 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:05:52 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:05:52 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:05:52 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:05:52 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:05:52 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:05:52 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:05:52 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:05:52 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:05:52 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:05:53 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:05:54 PM: Finished problem compilation (took 1.127e+00 seconds).\n(CVXPY) Sep 30 03:05:54 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:06:07 PM: Problem status: optimal\n(CVXPY) Sep 30 03:06:07 PM: Optimal value: 5.674e-01\n(CVXPY) Sep 30 03:06:07 PM: Compilation took 1.127e+00 seconds\n(CVXPY) Sep 30 03:06:07 PM: Solver (including time spent in interface) took 1.340e+01 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.56s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.56s/batch]\n",
    "execution_time": 26.656025648117065,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a21e193d88e5a12c10ae913b1292c6b2 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a21e193d88e5a12c10ae913b1292c6b2",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [25, 1]\n2025-09-30 15:06:18,841 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:06:18,842 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:06:18,842 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:06:19,898 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:06:19,898 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:06:19,898 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:06:19,898 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:06:19,899 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:06:19,899 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.09e+00  1.00e+00  8.34e+01   ------   \n  1  +6.7927e-01  +6.7834e-01  9.33e-04  6.44e-03  3.27e-04  9.98e-03  9.12e-01  9.89e-01  \n  2  +6.6479e-01  +6.6459e-01  2.03e-04  5.81e-04  2.93e-05  6.62e-04  8.27e-02  9.10e-01  \n  3  +6.1409e-01  +6.2208e-01  7.99e-03  4.85e-04  2.45e-05  8.46e-03  6.91e-02  3.59e-01  \n  4  +5.9550e-01  +5.9638e-01  8.74e-04  1.85e-04  9.35e-06  9.76e-04  2.64e-02  6.64e-01  \n  5  +5.8378e-01  +5.8417e-01  3.89e-04  1.46e-04  7.36e-06  4.34e-04  2.08e-02  3.41e-01  \n  6  +5.7614e-01  +5.7634e-01  2.05e-04  9.06e-05  4.56e-06  2.20e-04  1.29e-02  6.80e-01  \n  7  +5.7470e-01  +5.7489e-01  1.85e-04  7.81e-05  3.93e-06  1.97e-04  1.12e-02  3.68e-01  \n  8  +5.7073e-01  +5.7073e-01  1.09e-06  2.59e-05  1.30e-06  2.78e-06  3.78e-03  9.18e-01  \n  9  +5.6928e-01  +5.6928e-01  1.03e-06  2.10e-05  1.05e-06  1.84e-06  3.38e-03  2.16e-01  \n 10  +5.6917e-01  +5.6917e-01  1.23e-06  1.98e-05  9.90e-07  2.03e-06  3.36e-03  7.08e-02  \n 11  +5.6861e-01  +5.6861e-01  9.27e-07  1.23e-05  6.14e-07  1.41e-06  2.83e-03  2.51e-01  \n 12  +5.6842e-01  +5.6842e-01  9.01e-07  9.38e-06  4.68e-07  1.31e-06  2.59e-03  2.01e-01  \n 13  +5.6801e-01  +5.6801e-01  4.88e-07  3.73e-06  1.86e-07  6.78e-07  1.67e-03  5.21e-01  \n 14  +5.6791e-01  +5.6791e-01  4.10e-07  2.73e-06  1.37e-07  5.67e-07  1.39e-03  4.17e-01  \n 15  +5.6775e-01  +5.6775e-01  2.51e-07  1.59e-06  7.97e-08  3.45e-07  1.05e-03  6.04e-01  \n 16  +5.6773e-01  +5.6773e-01  1.90e-07  1.20e-06  6.01e-08  2.72e-07  7.94e-04  4.76e-01  \n 17  +5.6758e-01  +5.6758e-01  4.68e-08  3.54e-07  1.78e-08  7.08e-08  2.80e-04  7.88e-01  \n 18  +5.6751e-01  +5.6751e-01  8.48e-09  1.22e-07  6.11e-09  1.73e-08  9.08e-05  8.40e-01  \n 19  +5.6747e-01  +5.6747e-01  1.23e-09  2.31e-08  1.16e-09  2.95e-09  1.77e-05  8.74e-01  \n 20  +5.6746e-01  +5.6746e-01  2.05e-10  4.21e-09  2.12e-10  5.22e-10  3.18e-06  8.31e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.423526083s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:06:27,890 - xlsindy.simulation - INFO - Group 2, weight 0.66: [np.int64(2), np.int64(33), np.int64(39), np.int64(45), np.int64(47), np.int64(57), np.int64(60), np.int64(61), np.int64(62), np.int64(69), np.int64(78), np.int64(80), np.int64(90), np.int64(93)]\n2025-09-30 15:06:27,890 - xlsindy.simulation - INFO - Group 31, weight 0.43: [np.int64(40), np.int64(43), np.int64(48), np.int64(53), np.int64(58), np.int64(64), np.int64(68)]\n2025-09-30 15:06:27,891 - xlsindy.simulation - INFO - Group 33, weight 0.45: [np.int64(44), np.int64(50), np.int64(55), np.int64(59)]\n2025-09-30 15:06:27,935 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:06:27,956 - __main__ - INFO - Regression completed in 9.11 seconds\nestimate variance between mujoco and model is :  1.8795991\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:06:19 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:06:19 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:06:19 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:06:19 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:06:19 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:06:19 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:06:19 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:06:19 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:06:19 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:06:19 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:06:20 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:06:21 PM: Finished problem compilation (took 1.133e+00 seconds).\n(CVXPY) Sep 30 03:06:21 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:06:27 PM: Problem status: optimal\n(CVXPY) Sep 30 03:06:27 PM: Optimal value: 5.675e-01\n(CVXPY) Sep 30 03:06:27 PM: Compilation took 1.133e+00 seconds\n(CVXPY) Sep 30 03:06:27 PM: Solver (including time spent in interface) took 6.807e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.89s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.89s/batch]\n",
    "execution_time": 21.210269689559937,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a21e193d88e5a12c10ae913b1292c6b2 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a21e193d88e5a12c10ae913b1292c6b2",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [25, 1]\n2025-09-30 15:06:39,947 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:06:39,948 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:06:39,948 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:06:40,977 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:06:40,978 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:06:40,978 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:06:40,978 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:06:40,978 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:06:40,978 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.09e+00  1.00e+00  8.35e+01   ------   \n  1  +6.7900e-01  +6.7806e-01  9.32e-04  6.44e-03  3.27e-04  9.99e-03  9.13e-01  9.89e-01  \n  2  +6.6443e-01  +6.6423e-01  1.97e-04  5.83e-04  2.94e-05  6.71e-04  8.30e-02  9.10e-01  \n  3  +6.1386e-01  +6.2197e-01  8.12e-03  4.89e-04  2.47e-05  8.60e-03  6.96e-02  3.55e-01  \n  4  +5.9507e-01  +5.9590e-01  8.33e-04  1.84e-04  9.30e-06  9.35e-04  2.63e-02  6.68e-01  \n  5  +5.8346e-01  +5.8380e-01  3.46e-04  1.52e-04  7.65e-06  3.91e-04  2.16e-02  2.98e-01  \n  6  +5.7505e-01  +5.7523e-01  1.89e-04  8.15e-05  4.10e-06  2.00e-04  1.16e-02  8.69e-01  \n  7  +5.7391e-01  +5.7407e-01  1.62e-04  7.41e-05  3.72e-06  1.71e-04  1.06e-02  2.79e-01  \n  8  +5.7073e-01  +5.7074e-01  5.88e-06  2.70e-05  1.35e-06  7.22e-06  4.00e-03  9.31e-01  \n  9  +5.6955e-01  +5.6955e-01  3.35e-06  2.03e-05  1.01e-06  3.94e-06  3.48e-03  2.94e-01  \n 10  +5.6886e-01  +5.6886e-01  5.74e-07  5.32e-06  2.62e-07  6.75e-07  1.75e-03  6.40e-01  \n 11  +5.6869e-01  +5.6869e-01  2.07e-07  1.20e-06  5.91e-08  2.29e-07  7.16e-04  7.72e-01  \n 12  +5.6866e-01  +5.6866e-01  3.03e-08  2.02e-07  9.94e-09  3.40e-08  1.41e-04  8.43e-01  \n 13  +5.6865e-01  +5.6865e-01  4.46e-09  3.48e-08  1.71e-09  5.09e-09  2.49e-05  8.48e-01  \n 14  +5.6865e-01  +5.6865e-01  5.33e-10  5.60e-09  2.75e-10  6.35e-10  4.03e-06  8.76e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 4.901887236s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:06:47,457 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:06:47,480 - __main__ - INFO - Regression completed in 7.53 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:06:40 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:06:40 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:06:40 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:06:40 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:06:40 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:06:40 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:06:40 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:06:40 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:06:40 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:06:40 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:06:41 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:06:42 PM: Finished problem compilation (took 1.120e+00 seconds).\n(CVXPY) Sep 30 03:06:42 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:06:47 PM: Problem status: optimal\n(CVXPY) Sep 30 03:06:47 PM: Optimal value: 5.687e-01\n(CVXPY) Sep 30 03:06:47 PM: Compilation took 1.120e+00 seconds\n(CVXPY) Sep 30 03:06:47 PM: Solver (including time spent in interface) took 5.293e+00 seconds\n",
    "execution_time": 11.757100105285645,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a21e193d88e5a12c10ae913b1292c6b2 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a21e193d88e5a12c10ae913b1292c6b2",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [25, 1]\n2025-09-30 15:06:51,478 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:06:51,478 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:06:51,478 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:06:52,618 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:06:52,618 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:06:52,618 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:06:52,618 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:06:52,618 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:06:52,618 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.09e+00  1.00e+00  8.34e+01   ------   \n  1  +6.7933e-01  +6.7840e-01  9.33e-04  6.44e-03  3.27e-04  9.98e-03  9.12e-01  9.89e-01  \n  2  +6.6486e-01  +6.6466e-01  2.03e-04  5.81e-04  2.93e-05  6.61e-04  8.27e-02  9.10e-01  \n  3  +6.1416e-01  +6.2213e-01  7.97e-03  4.85e-04  2.45e-05  8.44e-03  6.91e-02  3.59e-01  \n  4  +5.9560e-01  +5.9647e-01  8.71e-04  1.85e-04  9.35e-06  9.72e-04  2.64e-02  6.65e-01  \n  5  +5.8389e-01  +5.8428e-01  3.87e-04  1.46e-04  7.37e-06  4.32e-04  2.08e-02  3.42e-01  \n  6  +5.7631e-01  +5.7651e-01  2.05e-04  9.09e-05  4.58e-06  2.20e-04  1.30e-02  6.78e-01  \n  7  +5.7485e-01  +5.7504e-01  1.84e-04  7.80e-05  3.93e-06  1.97e-04  1.12e-02  3.75e-01  \n  8  +5.7090e-01  +5.7090e-01  9.97e-07  2.59e-05  1.30e-06  2.69e-06  3.78e-03  9.13e-01  \n  9  +5.6921e-01  +5.6922e-01  9.13e-07  1.95e-05  9.71e-07  1.59e-06  3.28e-03  2.79e-01  \n 10  +5.6841e-01  +5.6841e-01  4.96e-07  8.81e-06  4.36e-07  7.02e-07  2.53e-03  5.83e-01  \n 11  +5.6839e-01  +5.6839e-01  4.94e-07  8.39e-06  4.15e-07  6.93e-07  2.50e-03  8.69e-02  \n 12  +5.6829e-01  +5.6829e-01  3.69e-07  5.56e-06  2.75e-07  5.10e-07  2.12e-03  2.82e-01  \n 13  +5.6824e-01  +5.6824e-01  3.11e-07  4.21e-06  2.09e-07  4.26e-07  1.84e-03  2.58e-01  \n 14  +5.6821e-01  +5.6821e-01  2.71e-07  3.44e-06  1.71e-07  3.71e-07  1.63e-03  1.84e-01  \n 15  +5.6818e-01  +5.6818e-01  2.20e-07  2.57e-06  1.28e-07  3.02e-07  1.32e-03  3.53e-01  \n 16  +5.6818e-01  +5.6818e-01  2.18e-07  2.51e-06  1.25e-07  3.01e-07  1.29e-03  7.58e-02  \n 17  +5.6818e-01  +5.6818e-01  2.12e-07  2.53e-06  1.26e-07  2.94e-07  1.29e-03  1.42e-02  \n 18  +5.6815e-01  +5.6815e-01  1.66e-07  1.80e-06  8.98e-08  2.33e-07  9.93e-04  3.62e-01  \n 19  +5.6815e-01  +5.6815e-01  1.46e-07  1.58e-06  7.91e-08  2.09e-07  8.58e-04  2.68e-01  \n 20  +5.6816e-01  +5.6816e-01  7.47e-08  1.30e-06  6.50e-08  1.37e-07  6.06e-04  7.92e-01  \n 21  +5.6814e-01  +5.6814e-01  5.27e-08  9.91e-07  4.96e-08  1.04e-07  4.36e-04  4.57e-01  \n 22  +5.6812e-01  +5.6812e-01  4.53e-08  7.33e-07  3.68e-08  9.08e-08  3.20e-04  3.61e-01  \n 23  +5.6813e-01  +5.6813e-01  4.12e-08  7.18e-07  3.60e-08  8.75e-08  3.05e-04  1.29e-01  \n 24  +5.6812e-01  +5.6812e-01  3.44e-08  6.53e-07  3.28e-08  7.97e-08  2.67e-04  2.31e-01  \n 25  +5.6813e-01  +5.6813e-01  2.82e-08  6.41e-07  3.22e-08  7.38e-08  2.51e-04  1.66e-01  \n 26  +5.6813e-01  +5.6813e-01  2.28e-08  6.26e-07  3.14e-08  6.85e-08  2.36e-04  1.62e-01  \n 27  +5.6814e-01  +5.6814e-01  8.14e-09  6.15e-07  3.09e-08  5.52e-08  2.05e-04  4.31e-01  \n 28  +5.6812e-01  +5.6812e-01  9.12e-09  5.21e-07  2.62e-08  5.31e-08  1.67e-04  2.18e-01  \n 29  +5.6812e-01  +5.6812e-01  7.41e-09  5.22e-07  2.62e-08  5.11e-08  1.66e-04  4.25e-02  \n 30  +5.6808e-01  +5.6808e-01  1.57e-08  2.60e-07  1.31e-08  4.70e-08  8.07e-05  5.43e-01  \n 31  +5.6807e-01  +5.6807e-01  1.50e-08  2.27e-07  1.14e-08  4.50e-08  6.74e-05  2.26e-01  \n 32  +5.6801e-01  +5.6801e-01  8.32e-09  1.11e-07  5.59e-09  3.10e-08  2.67e-05  9.76e-01  \n 33  +5.6797e-01  +5.6797e-01  8.89e-09  8.35e-08  4.21e-09  2.91e-08  1.91e-05  3.83e-01  \n 34  +5.6794e-01  +5.6794e-01  8.71e-09  6.88e-08  3.47e-09  2.76e-08  1.48e-05  3.92e-01  \n 35  +5.6786e-01  +5.6786e-01  8.89e-09  4.39e-08  2.21e-09  2.42e-08  8.51e-06  6.68e-01  \n 36  +5.6774e-01  +5.6774e-01  7.87e-09  2.48e-08  1.25e-09  1.88e-08  4.32e-06  7.41e-01  \n 37  +5.6773e-01  +5.6773e-01  7.55e-09  2.28e-08  1.15e-09  1.79e-08  3.90e-06  1.60e-01  \n 38  +5.6771e-01  +5.6771e-01  7.05e-09  2.13e-08  1.07e-09  1.70e-08  3.49e-06  4.05e-01  \n 39  +5.6762e-01  +5.6762e-01  5.43e-09  1.33e-08  6.69e-10  1.24e-08  2.06e-06  5.21e-01  \n 40  +5.6746e-01  +5.6746e-01  1.61e-09  2.02e-09  1.04e-10  2.87e-09  3.12e-07  8.92e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 12.092733112s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:07:06,327 - xlsindy.simulation - INFO - Group 25, weight 0.74: [np.int64(31), np.int64(33), np.int64(39), np.int64(40), np.int64(41), np.int64(43), np.int64(44), np.int64(45), np.int64(48), np.int64(53), np.int64(54), np.int64(57), np.int64(58), np.int64(60), np.int64(61), np.int64(62), np.int64(69), np.int64(78), np.int64(90), np.int64(93)]\n2025-09-30 15:07:06,363 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:07:06,382 - __main__ - INFO - Regression completed in 14.90 seconds\nestimate variance between mujoco and model is :  0.12763423\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:06:52 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:06:52 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:06:52 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:06:52 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:06:52 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:06:52 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:06:52 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:06:52 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:06:52 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:06:52 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:06:53 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:06:53 PM: Finished problem compilation (took 1.151e+00 seconds).\n(CVXPY) Sep 30 03:06:53 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:07:06 PM: Problem status: optimal\n(CVXPY) Sep 30 03:07:06 PM: Optimal value: 5.674e-01\n(CVXPY) Sep 30 03:07:06 PM: Compilation took 1.151e+00 seconds\n(CVXPY) Sep 30 03:07:06 PM: Solver (including time spent in interface) took 1.247e+01 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.57s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.57s/batch]\n",
    "execution_time": 26.61590027809143,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a21e193d88e5a12c10ae913b1292c6b2 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a21e193d88e5a12c10ae913b1292c6b2",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [35, 1]\n2025-09-30 15:07:18,387 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:07:18,387 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:07:19,590 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.064670124687861\n2025-09-30 15:07:19,596 - __main__ - INFO - Regression completed in 1.21 seconds\nestimate variance between mujoco and model is :  6.8611703\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.25s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.25s/batch]\n",
    "execution_time": 13.220162868499756,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2c4b44d8fd461fcda7867a06edc7ea00 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2c4b44d8fd461fcda7867a06edc7ea00",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [35, 1]\n2025-09-30 15:07:31,322 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:07:31,323 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:07:32,528 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0646882976416153\n2025-09-30 15:07:32,534 - __main__ - INFO - Regression completed in 1.21 seconds\nestimate variance between mujoco and model is :  6.882559\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.22s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.22s/batch]\n",
    "execution_time": 13.602487325668335,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2c4b44d8fd461fcda7867a06edc7ea00 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2c4b44d8fd461fcda7867a06edc7ea00",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [35, 1]\n2025-09-30 15:07:44,936 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:07:44,936 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:07:46,141 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.07000479762143087\n2025-09-30 15:07:46,146 - __main__ - INFO - Regression completed in 1.21 seconds\nestimate variance between mujoco and model is :  7.106971\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.05s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.05s/batch]\n",
    "execution_time": 13.136225700378418,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2c4b44d8fd461fcda7867a06edc7ea00 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2c4b44d8fd461fcda7867a06edc7ea00",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56874 column 2 (char 2110031)\n",
    "execution_time": 2.8164405822753906,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2c4b44d8fd461fcda7867a06edc7ea00 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2c4b44d8fd461fcda7867a06edc7ea00",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56874 column 2 (char 2110031)\n",
    "execution_time": 3.40684175491333,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2c4b44d8fd461fcda7867a06edc7ea00 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2c4b44d8fd461fcda7867a06edc7ea00",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56874 column 2 (char 2110031)\n",
    "execution_time": 3.397934675216675,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2c4b44d8fd461fcda7867a06edc7ea00 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2c4b44d8fd461fcda7867a06edc7ea00",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56874 column 2 (char 2110031)\n",
    "execution_time": 2.8243484497070312,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2c4b44d8fd461fcda7867a06edc7ea00 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2c4b44d8fd461fcda7867a06edc7ea00",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 87, in <module>\n    simulation_dict = json.load(json_file)\n  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 56874 column 2 (char 2110031)\n",
    "execution_time": 2.940793752670288,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2c4b44d8fd461fcda7867a06edc7ea00 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2c4b44d8fd461fcda7867a06edc7ea00",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [8, 1]\n2025-09-30 15:08:13,826 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:08:13,826 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.857317686080933,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b264f744ccebb6145eae69c0b46fef5 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b264f744ccebb6145eae69c0b46fef5",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [8, 1]\n2025-09-30 15:08:19,625 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:08:19,625 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.790240287780762,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b264f744ccebb6145eae69c0b46fef5 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b264f744ccebb6145eae69c0b46fef5",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [8, 1]\n2025-09-30 15:08:25,966 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:08:25,967 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.460514545440674,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b264f744ccebb6145eae69c0b46fef5 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b264f744ccebb6145eae69c0b46fef5",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [8, 1]\n2025-09-30 15:08:32,182 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:08:32,183 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.250429391860962,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b264f744ccebb6145eae69c0b46fef5 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b264f744ccebb6145eae69c0b46fef5",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [8, 1]\n2025-09-30 15:08:38,125 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:08:38,126 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:08:38,126 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.796855449676514,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b264f744ccebb6145eae69c0b46fef5 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b264f744ccebb6145eae69c0b46fef5",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [8, 1]\n2025-09-30 15:08:43,997 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:08:43,997 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:08:43,997 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.9825170040130615,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b264f744ccebb6145eae69c0b46fef5 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b264f744ccebb6145eae69c0b46fef5",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [8, 1]\n2025-09-30 15:08:50,002 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:08:50,002 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:08:50,002 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.9053685665130615,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b264f744ccebb6145eae69c0b46fef5 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b264f744ccebb6145eae69c0b46fef5",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [8, 1]\n2025-09-30 15:08:55,827 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:08:55,827 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:08:55,827 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.927524089813232,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b264f744ccebb6145eae69c0b46fef5 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b264f744ccebb6145eae69c0b46fef5",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [23, 1]\n2025-09-30 15:09:01,406 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:09:01,406 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:09:02,422 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:09:02,447 - xlsindy.simulation - INFO - Experimental matrix norm: 376.6488466348503\n2025-09-30 15:09:02,447 - xlsindy.simulation - INFO - Experimental matrix variance: 4.01304627903274\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.96e-01  1.12e+00  1.00e+00  3.87e+01   ------   \n  1  +3.4256e-01  +3.4166e-01  8.98e-04  6.41e-03  6.81e-04  9.98e-03  4.22e-01  9.89e-01  \n  2  +3.2129e-01  +3.2103e-01  2.59e-04  4.52e-04  4.77e-05  4.48e-04  2.99e-02  9.29e-01  \n  3  +2.8369e-01  +2.9213e-01  8.44e-03  2.87e-04  3.03e-05  9.09e-03  1.90e-02  6.07e-01  \n  4  +2.6182e-01  +2.6404e-01  2.22e-03  1.14e-04  1.20e-05  2.39e-03  7.56e-03  6.63e-01  \n  5  +2.5050e-01  +2.5287e-01  2.37e-03  7.77e-05  8.19e-06  2.50e-03  5.14e-03  4.63e-01  \n  6  +2.3366e-01  +2.3440e-01  7.40e-04  4.22e-05  4.44e-06  7.82e-04  2.79e-03  6.27e-01  \n  7  +2.3139e-01  +2.3239e-01  9.99e-04  3.36e-05  3.55e-06  1.04e-03  2.23e-03  4.22e-01  \n  8  +2.1713e-01  +2.1718e-01  5.28e-05  1.30e-05  1.37e-06  6.01e-05  8.63e-04  8.58e-01  \n  9  +2.1657e-01  +2.1664e-01  7.57e-05  1.20e-05  1.27e-06  8.39e-05  8.03e-04  2.27e-01  \n 10  +2.0727e-01  +2.0728e-01  6.86e-06  5.74e-06  6.02e-07  8.10e-06  4.09e-04  7.79e-01  \n 11  +2.0432e-01  +2.0432e-01  1.99e-06  2.80e-06  2.94e-07  2.35e-06  2.79e-04  4.93e-01  \n 12  +2.0367e-01  +2.0367e-01  1.24e-06  1.76e-06  1.84e-07  1.44e-06  2.42e-04  2.45e-01  \n 13  +2.0326e-01  +2.0326e-01  8.20e-07  9.64e-07  1.01e-07  9.24e-07  1.94e-04  5.95e-01  \n 14  +2.0323e-01  +2.0323e-01  7.32e-07  8.59e-07  8.98e-08  8.26e-07  1.80e-04  1.63e-01  \n 15  +2.0320e-01  +2.0320e-01  6.54e-07  7.93e-07  8.29e-08  7.41e-07  1.68e-04  2.31e-01  \n 16  +2.0319e-01  +2.0319e-01  6.21e-07  7.56e-07  7.91e-08  7.04e-07  1.61e-04  1.50e-01  \n 17  +2.0319e-01  +2.0319e-01  5.63e-07  7.26e-07  7.60e-08  6.44e-07  1.52e-04  2.88e-01  \n 18  +2.0306e-01  +2.0306e-01  3.33e-07  4.08e-07  4.27e-08  3.80e-07  1.00e-04  3.93e-01  \n 19  +2.0301e-01  +2.0301e-01  2.07e-07  2.62e-07  2.75e-08  2.38e-07  6.39e-05  5.31e-01  \n 20  +2.0296e-01  +2.0296e-01  9.44e-08  1.22e-07  1.29e-08  1.11e-07  2.71e-05  8.09e-01  \n 21  +2.0296e-01  +2.0296e-01  7.85e-08  1.10e-07  1.16e-08  9.46e-08  2.15e-05  3.14e-01  \n 22  +2.0296e-01  +2.0296e-01  7.17e-08  1.10e-07  1.16e-08  8.79e-08  2.09e-05  9.76e-02  \n 23  +2.0294e-01  +2.0294e-01  6.48e-08  8.37e-08  8.83e-09  7.86e-08  1.40e-05  3.47e-01  \n 24  +2.0294e-01  +2.0294e-01  5.69e-08  7.76e-08  8.19e-09  7.04e-08  1.20e-05  2.18e-01  \n 25  +2.0294e-01  +2.0294e-01  4.89e-08  7.42e-08  7.83e-09  6.24e-08  1.06e-05  2.30e-01  \n 26  +2.0294e-01  +2.0294e-01  4.57e-08  7.25e-08  7.65e-09  5.92e-08  9.96e-06  1.20e-01  \n 27  +2.0293e-01  +2.0293e-01  3.59e-08  6.58e-08  6.94e-09  4.92e-08  8.10e-06  3.30e-01  \n 28  +2.0294e-01  +2.0294e-01  3.38e-08  6.55e-08  6.91e-09  4.73e-08  7.85e-06  9.78e-02  \n 29  +2.0293e-01  +2.0293e-01  3.02e-08  5.89e-08  6.21e-09  4.32e-08  6.55e-06  2.39e-01  \n 30  +2.0292e-01  +2.0292e-01  2.81e-08  5.73e-08  6.04e-09  4.09e-08  6.24e-06  8.30e-02  \n 31  +2.0292e-01  +2.0292e-01  2.57e-08  5.53e-08  5.83e-09  3.83e-08  5.84e-06  1.20e-01  \n 32  +2.0293e-01  +2.0293e-01  1.58e-08  5.21e-08  5.49e-09  2.96e-08  4.65e-06  5.75e-01  \n 33  +2.0293e-01  +2.0293e-01  1.54e-08  5.15e-08  5.42e-09  2.93e-08  4.53e-06  5.19e-02  \n 34  +2.0293e-01  +2.0293e-01  1.36e-08  4.89e-08  5.15e-09  2.77e-08  4.04e-06  2.38e-01  \n 35  +2.0290e-01  +2.0290e-01  1.40e-08  3.52e-08  3.71e-09  2.69e-08  2.55e-06  4.93e-01  \n 36  +2.0289e-01  +2.0289e-01  1.41e-08  2.93e-08  3.09e-09  2.64e-08  1.98e-06  3.22e-01  \n 37  +2.0289e-01  +2.0289e-01  1.41e-08  2.93e-08  3.09e-09  2.66e-08  1.98e-06  7.38e-03  \n 38  +2.0288e-01  +2.0288e-01  1.32e-08  2.92e-08  3.08e-09  2.54e-08  1.96e-06  3.04e-02  \n 39  +2.0288e-01  +2.0288e-01  1.25e-08  2.90e-08  3.06e-09  2.48e-08  1.92e-06  8.21e-02  \n 40  +2.0287e-01  +2.0287e-01  1.20e-08  2.75e-08  2.90e-09  2.43e-08  1.76e-06  1.92e-01  \n 41  +2.0287e-01  +2.0287e-01  1.16e-08  2.57e-08  2.71e-09  2.36e-08  1.61e-06  1.30e-01  \n 42  +2.0286e-01  +2.0286e-01  1.13e-08  2.56e-08  2.69e-09  2.34e-08  1.56e-06  1.12e-01  \n 43  +2.0286e-01  +2.0286e-01  1.09e-08  2.48e-08  2.61e-09  2.28e-08  1.50e-06  6.76e-02  \n 44  +2.0286e-01  +2.0286e-01  1.07e-08  2.38e-08  2.51e-09  2.35e-08  1.34e-06  4.07e-01  \n 45  +2.0286e-01  +2.0286e-01  1.02e-08  2.37e-08  2.50e-09  2.28e-08  1.33e-06  3.42e-02  \n 46  +2.0282e-01  +2.0282e-01  1.13e-08  1.73e-08  1.82e-09  2.26e-08  8.91e-07  4.72e-01  \n 47  +2.0281e-01  +2.0281e-01  9.99e-09  1.71e-08  1.80e-09  2.11e-08  8.66e-07  1.48e-01  \n 48  +2.0278e-01  +2.0278e-01  1.06e-08  1.40e-08  1.48e-09  2.10e-08  6.81e-07  2.76e-01  \n 49  +2.0274e-01  +2.0274e-01  1.12e-08  1.07e-08  1.13e-09  2.06e-08  4.92e-07  4.04e-01  \n 50  +2.0271e-01  +2.0271e-01  1.13e-08  8.78e-09  9.24e-10  1.99e-08  3.85e-07  3.72e-01  \n 51  +2.0266e-01  +2.0266e-01  1.11e-08  6.62e-09  6.97e-10  1.86e-08  2.81e-07  3.28e-01  \n 52  +2.0265e-01  +2.0265e-01  1.09e-08  6.51e-09  6.85e-10  1.84e-08  2.72e-07  1.78e-01  \n 53  +2.0254e-01  +2.0254e-01  9.56e-09  3.44e-09  3.63e-10  1.46e-08  1.38e-07  5.41e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 15.441508205s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:09:19,493 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00  1.34211183e-17  1.34211183e-17 ...  1.34211183e-17\n   1.34211183e-17  1.34211183e-17]\n [ 1.34211183e-17 -1.00000000e+00  1.34211183e-17 ...  1.34211183e-17\n   1.34211183e-17  1.34211183e-17]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ... -4.45304549e-01\n   2.46366608e-01 -6.74195707e-03]\n ...\n [ 0.00000000e+00  0.00000000e+00 -6.60562696e-01 ... -1.00000000e+00\n   3.37133683e-01 -7.78966885e-03]\n [ 0.00000000e+00  0.00000000e+00  1.44190838e+00 ...  1.32037150e+00\n  -1.00000000e+00  2.64074502e-02]\n [ 0.00000000e+00  0.00000000e+00 -4.74709602e-01 ... -3.52794827e-01\n   1.60811223e-01 -1.00000000e+00]]\n2025-09-30 15:09:19,518 - xlsindy.simulation - INFO - Group 12, weight 0.46: [np.int64(12), np.int64(30), np.int64(33), np.int64(36), np.int64(39), np.int64(40), np.int64(44), np.int64(57), np.int64(61), np.int64(78), np.int64(93)]\n2025-09-30 15:09:19,518 - xlsindy.simulation - INFO - Group 25, weight 0.71: [np.int64(32), np.int64(41), np.int64(45), np.int64(67), np.int64(90)]\n2025-09-30 15:09:19,571 - __main__ - INFO - Regression completed in 18.17 seconds\nestimate variance between mujoco and model is :  0.2566163\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:09:02 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:09:02 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:09:02 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:09:02 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:09:02 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:09:02 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:09:02 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:09:02 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:09:02 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:09:02 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:09:03 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:09:03 PM: Finished problem compilation (took 1.104e+00 seconds).\n(CVXPY) Sep 30 03:09:03 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:09:19 PM: Problem status: optimal\n(CVXPY) Sep 30 03:09:19 PM: Optimal value: 2.023e-01\n(CVXPY) Sep 30 03:09:19 PM: Compilation took 1.104e+00 seconds\n(CVXPY) Sep 30 03:09:19 PM: Solver (including time spent in interface) took 1.584e+01 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.56s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.56s/batch]\n",
    "execution_time": 29.25196146965027,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/35d4c47b04e6fd5f5ffac5e15475583f --algorithm mixed --regression-type implicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "35d4c47b04e6fd5f5ffac5e15475583f",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [23, 1]\n2025-09-30 15:09:30,641 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:09:30,641 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:09:31,752 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:09:31,775 - xlsindy.simulation - INFO - Experimental matrix norm: 376.6796134553195\n2025-09-30 15:09:31,775 - xlsindy.simulation - INFO - Experimental matrix variance: 4.013703590786189\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.96e-01  1.12e+00  1.00e+00  3.88e+01   ------   \n  1  +3.4254e-01  +3.4165e-01  8.98e-04  6.41e-03  6.80e-04  9.98e-03  4.22e-01  9.89e-01  \n  2  +3.2123e-01  +3.2098e-01  2.58e-04  4.52e-04  4.77e-05  4.48e-04  2.99e-02  9.30e-01  \n  3  +2.8358e-01  +2.9204e-01  8.46e-03  2.87e-04  3.02e-05  9.11e-03  1.90e-02  6.08e-01  \n  4  +2.6165e-01  +2.6388e-01  2.22e-03  1.14e-04  1.20e-05  2.40e-03  7.55e-03  6.63e-01  \n  5  +2.5030e-01  +2.5268e-01  2.38e-03  7.77e-05  8.19e-06  2.51e-03  5.14e-03  4.62e-01  \n  6  +2.3341e-01  +2.3415e-01  7.38e-04  4.21e-05  4.43e-06  7.80e-04  2.78e-03  6.29e-01  \n  7  +2.3113e-01  +2.3212e-01  9.94e-04  3.36e-05  3.54e-06  1.04e-03  2.22e-03  4.22e-01  \n  8  +2.1691e-01  +2.1696e-01  5.20e-05  1.29e-05  1.36e-06  5.92e-05  8.59e-04  8.58e-01  \n  9  +2.1634e-01  +2.1641e-01  7.44e-05  1.20e-05  1.26e-06  8.25e-05  7.99e-04  2.26e-01  \n 10  +2.0710e-01  +2.0711e-01  6.95e-06  5.71e-06  5.99e-07  8.18e-06  4.07e-04  7.80e-01  \n 11  +2.0400e-01  +2.0401e-01  3.17e-06  3.17e-06  3.32e-07  3.58e-06  3.30e-04  7.14e-01  \n 12  +2.0318e-01  +2.0318e-01  7.55e-07  1.10e-06  1.15e-07  8.77e-07  1.92e-04  5.55e-01  \n 13  +2.0297e-01  +2.0297e-01  4.95e-07  6.95e-07  7.26e-08  5.71e-07  1.53e-04  3.78e-01  \n 14  +2.0284e-01  +2.0284e-01  2.79e-07  4.01e-07  4.19e-08  3.23e-07  1.08e-04  3.98e-01  \n 15  +2.0270e-01  +2.0270e-01  4.83e-08  9.46e-08  9.89e-09  5.87e-08  3.31e-05  9.10e-01  \n 16  +2.0267e-01  +2.0267e-01  8.81e-09  2.02e-08  2.11e-09  1.10e-08  7.73e-06  8.16e-01  \n 17  +2.0266e-01  +2.0266e-01  1.21e-09  3.18e-09  3.33e-10  1.56e-09  1.25e-06  8.62e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.735319391s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:09:40,141 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -9.77632890e-20 -9.77632890e-20 ... -9.77632890e-20\n  -9.77632890e-20 -9.77632890e-20]\n [-9.77632890e-20 -1.00000000e+00 -9.77632890e-20 ... -9.77632890e-20\n  -9.77632890e-20 -9.77632890e-20]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ... -4.46051888e-01\n   2.50179505e-01 -4.26341198e-03]\n ...\n [ 0.00000000e+00  0.00000000e+00 -6.60916589e-01 ... -1.00000000e+00\n   3.42932351e-01 -5.76798941e-03]\n [ 0.00000000e+00  0.00000000e+00  1.45212001e+00 ...  1.31957395e+00\n  -1.00000000e+00  3.02484824e-02]\n [ 0.00000000e+00  0.00000000e+00 -4.44951689e-01 ... -3.18770337e-01\n   1.43835139e-01 -1.00000000e+00]]\n2025-09-30 15:09:40,188 - xlsindy.simulation - INFO - Group 36, weight 0.66: [np.int64(45), np.int64(90), np.int64(93)]\n2025-09-30 15:09:40,226 - __main__ - INFO - Regression completed in 9.58 seconds\nestimate variance between mujoco and model is :  1.2578255\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:09:31 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:09:31 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:09:31 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:09:31 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:09:31 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:09:31 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:09:31 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:09:31 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:09:31 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:09:31 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:09:32 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:09:32 PM: Finished problem compilation (took 1.126e+00 seconds).\n(CVXPY) Sep 30 03:09:32 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:09:40 PM: Problem status: optimal\n(CVXPY) Sep 30 03:09:40 PM: Optimal value: 2.027e-01\n(CVXPY) Sep 30 03:09:40 PM: Compilation took 1.126e+00 seconds\n(CVXPY) Sep 30 03:09:40 PM: Solver (including time spent in interface) took 7.129e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.66s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.66s/batch]\n",
    "execution_time": 21.482053518295288,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/35d4c47b04e6fd5f5ffac5e15475583f --algorithm mixed --regression-type implicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "35d4c47b04e6fd5f5ffac5e15475583f",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [23, 1]\n2025-09-30 15:09:52,464 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:09:52,464 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:09:53,502 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:09:53,531 - xlsindy.simulation - INFO - Experimental matrix norm: 376.9705551468618\n2025-09-30 15:09:53,531 - xlsindy.simulation - INFO - Experimental matrix variance: 4.019921391477002\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.96e-01  1.12e+00  1.00e+00  3.88e+01   ------   \n  1  +3.4258e-01  +3.4169e-01  8.97e-04  6.41e-03  6.79e-04  9.98e-03  4.23e-01  9.89e-01  \n  2  +3.2118e-01  +3.2092e-01  2.55e-04  4.57e-04  4.81e-05  4.58e-04  3.03e-02  9.29e-01  \n  3  +2.8398e-01  +2.9249e-01  8.51e-03  2.97e-04  3.13e-05  9.17e-03  1.97e-02  5.94e-01  \n  4  +2.6290e-01  +2.6498e-01  2.08e-03  1.19e-04  1.25e-05  2.25e-03  7.90e-03  6.58e-01  \n  5  +2.5131e-01  +2.5326e-01  1.95e-03  8.24e-05  8.67e-06  2.07e-03  5.46e-03  4.44e-01  \n  6  +2.3587e-01  +2.3649e-01  6.23e-04  4.41e-05  4.64e-06  6.60e-04  2.93e-03  6.54e-01  \n  7  +2.3363e-01  +2.3440e-01  7.63e-04  3.60e-05  3.79e-06  8.00e-04  2.39e-03  4.01e-01  \n  8  +2.2197e-01  +2.2198e-01  1.43e-05  1.20e-05  1.26e-06  1.96e-05  8.03e-04  8.93e-01  \n  9  +2.2156e-01  +2.2159e-01  2.31e-05  1.15e-05  1.20e-06  2.88e-05  7.67e-04  1.68e-01  \n 10  +2.1439e-01  +2.1440e-01  5.14e-06  6.08e-06  6.36e-07  6.03e-06  4.50e-04  7.40e-01  \n 11  +2.1246e-01  +2.1246e-01  1.19e-06  2.45e-06  2.55e-07  1.42e-06  2.74e-04  5.60e-01  \n 12  +2.1176e-01  +2.1176e-01  3.35e-07  4.88e-07  5.07e-08  3.75e-07  1.23e-04  7.24e-01  \n 13  +2.1166e-01  +2.1166e-01  6.46e-08  1.06e-07  1.11e-08  7.32e-08  3.46e-05  8.04e-01  \n 14  +2.1164e-01  +2.1164e-01  9.93e-09  1.85e-08  1.92e-09  1.14e-08  6.46e-06  8.40e-01  \n 15  +2.1163e-01  +2.1163e-01  1.61e-09  3.49e-09  3.63e-10  1.89e-09  1.24e-06  8.35e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.001561031s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:10:01,213 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -3.29205028e-19 -3.29205028e-19 ... -3.29205028e-19\n  -3.29205028e-19 -3.29205028e-19]\n [-3.29205028e-19 -1.00000000e+00 -3.29205028e-19 ... -3.29205028e-19\n  -3.29205028e-19 -3.29205028e-19]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ... -4.26176949e-01\n   3.07269506e-01 -1.50721204e-02]\n ...\n [ 0.00000000e+00  0.00000000e+00 -6.47820280e-01 ... -1.00000000e+00\n   4.76073811e-01  2.03359346e-02]\n [ 0.00000000e+00  0.00000000e+00  1.18086360e+00 ...  1.19614223e+00\n  -1.00000000e+00  1.81865992e-01]\n [ 0.00000000e+00  0.00000000e+00 -1.23788670e-02 ...  3.83806027e-03\n   2.93092909e-02 -1.00000000e+00]]\n2025-09-30 15:10:01,243 - xlsindy.simulation - INFO - Group 4, weight 0.23: [np.int64(4), np.int64(30), np.int64(34)]\n2025-09-30 15:10:01,261 - __main__ - INFO - Regression completed in 8.80 seconds\n",
    "stderr": "(CVXPY) Sep 30 03:09:53 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:09:53 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:09:53 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:09:53 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:09:53 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:09:53 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:09:53 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:09:53 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:09:53 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:09:53 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:09:54 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:09:54 PM: Finished problem compilation (took 1.166e+00 seconds).\n(CVXPY) Sep 30 03:09:54 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:10:01 PM: Problem status: optimal\n(CVXPY) Sep 30 03:10:01 PM: Optimal value: 2.116e-01\n(CVXPY) Sep 30 03:10:01 PM: Compilation took 1.166e+00 seconds\n(CVXPY) Sep 30 03:10:01 PM: Solver (including time spent in interface) took 6.420e+00 seconds\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 243, in <module>\n    xlsindy.dynamics_modeling.generate_acceleration_function(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/dynamics_modeling.py\", line 67, in generate_acceleration_function\n    if str(symbol_matrix[3, i]) not in str(dynamic_equations[i]):\nIndexError: index 0 is out of bounds for axis 0 with size 0\n",
    "execution_time": 12.67850399017334,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/35d4c47b04e6fd5f5ffac5e15475583f --algorithm mixed --regression-type implicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "35d4c47b04e6fd5f5ffac5e15475583f",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [23, 1]\n2025-09-30 15:10:04,712 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:10:04,713 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:10:05,752 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:10:05,773 - xlsindy.simulation - INFO - Experimental matrix norm: 376.65190906044614\n2025-09-30 15:10:05,774 - xlsindy.simulation - INFO - Experimental matrix variance: 4.0131117038473505\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.96e-01  1.12e+00  1.00e+00  3.87e+01   ------   \n  1  +3.4256e-01  +3.4166e-01  8.98e-04  6.41e-03  6.81e-04  9.98e-03  4.22e-01  9.89e-01  \n  2  +3.2128e-01  +3.2102e-01  2.58e-04  4.52e-04  4.77e-05  4.48e-04  2.99e-02  9.29e-01  \n  3  +2.8368e-01  +2.9212e-01  8.45e-03  2.87e-04  3.03e-05  9.09e-03  1.90e-02  6.07e-01  \n  4  +2.6180e-01  +2.6402e-01  2.22e-03  1.14e-04  1.20e-05  2.39e-03  7.56e-03  6.63e-01  \n  5  +2.5048e-01  +2.5285e-01  2.37e-03  7.77e-05  8.19e-06  2.50e-03  5.14e-03  4.63e-01  \n  6  +2.3363e-01  +2.3437e-01  7.40e-04  4.21e-05  4.44e-06  7.82e-04  2.79e-03  6.27e-01  \n  7  +2.3135e-01  +2.3235e-01  9.99e-04  3.36e-05  3.55e-06  1.04e-03  2.23e-03  4.22e-01  \n  8  +2.1709e-01  +2.1714e-01  5.28e-05  1.30e-05  1.37e-06  6.02e-05  8.63e-04  8.58e-01  \n  9  +2.1653e-01  +2.1660e-01  7.57e-05  1.20e-05  1.27e-06  8.39e-05  8.02e-04  2.27e-01  \n 10  +2.0723e-01  +2.0724e-01  6.85e-06  5.72e-06  6.01e-07  8.09e-06  4.08e-04  7.80e-01  \n 11  +2.0427e-01  +2.0428e-01  1.99e-06  2.80e-06  2.93e-07  2.35e-06  2.78e-04  4.95e-01  \n 12  +2.0392e-01  +2.0392e-01  1.95e-06  2.25e-06  2.36e-07  2.24e-06  2.73e-04  1.64e-01  \n 13  +2.0361e-01  +2.0361e-01  1.47e-06  1.68e-06  1.76e-07  1.68e-06  2.44e-04  1.84e-01  \n 14  +2.0342e-01  +2.0342e-01  1.18e-06  1.28e-06  1.34e-07  1.34e-06  2.15e-04  2.14e-01  \n 15  +2.0315e-01  +2.0315e-01  6.91e-07  6.67e-07  6.99e-08  7.79e-07  1.47e-04  4.87e-01  \n 16  +2.0310e-01  +2.0310e-01  5.51e-07  5.27e-07  5.52e-08  6.26e-07  1.14e-04  4.41e-01  \n 17  +2.0311e-01  +2.0311e-01  4.39e-07  4.96e-07  5.20e-08  5.13e-07  9.60e-05  4.93e-01  \n 18  +2.0299e-01  +2.0299e-01  2.98e-07  2.80e-07  2.95e-08  3.44e-07  5.80e-05  4.27e-01  \n 19  +2.0297e-01  +2.0297e-01  2.53e-07  2.43e-07  2.55e-08  2.95e-07  4.72e-05  2.70e-01  \n 20  +2.0293e-01  +2.0293e-01  1.76e-07  1.68e-07  1.77e-08  2.09e-07  2.93e-05  5.26e-01  \n 21  +2.0293e-01  +2.0293e-01  1.63e-07  1.63e-07  1.71e-08  1.96e-07  2.71e-05  1.47e-01  \n 22  +2.0293e-01  +2.0293e-01  1.43e-07  1.55e-07  1.63e-08  1.75e-07  2.44e-05  1.98e-01  \n 23  +2.0293e-01  +2.0293e-01  1.21e-07  1.51e-07  1.59e-08  1.54e-07  2.23e-05  2.22e-01  \n 24  +2.0293e-01  +2.0293e-01  1.11e-07  1.48e-07  1.56e-08  1.44e-07  2.11e-05  1.30e-01  \n 25  +2.0295e-01  +2.0295e-01  3.53e-08  1.47e-07  1.54e-08  7.09e-08  1.64e-05  7.87e-01  \n 26  +2.0293e-01  +2.0293e-01  2.85e-08  1.41e-07  1.48e-08  6.38e-08  1.45e-05  2.93e-01  \n 27  +2.0293e-01  +2.0293e-01  2.54e-08  1.37e-07  1.44e-08  6.20e-08  1.28e-05  3.17e-01  \n 28  +2.0288e-01  +2.0288e-01  2.24e-08  9.99e-08  1.05e-08  5.22e-08  8.58e-06  3.92e-01  \n 29  +2.0279e-01  +2.0279e-01  2.11e-08  5.86e-08  6.16e-09  4.23e-08  4.59e-06  4.90e-01  \n 30  +2.0275e-01  +2.0275e-01  1.79e-08  4.49e-08  4.72e-09  3.63e-08  3.27e-06  3.69e-01  \n 31  +2.0274e-01  +2.0274e-01  1.74e-08  4.48e-08  4.71e-09  3.57e-08  3.24e-06  2.69e-02  \n 32  +2.0272e-01  +2.0272e-01  1.23e-08  3.96e-08  4.17e-09  2.95e-08  2.63e-06  4.10e-01  \n 33  +2.0270e-01  +2.0270e-01  1.12e-08  3.74e-08  3.94e-09  2.79e-08  2.41e-06  1.69e-01  \n 34  +2.0261e-01  +2.0261e-01  7.44e-09  2.16e-08  2.27e-09  1.88e-08  1.21e-06  6.78e-01  \n 35  +2.0261e-01  +2.0261e-01  6.93e-09  2.10e-08  2.21e-09  1.81e-08  1.16e-06  1.03e-01  \n 36  +2.0260e-01  +2.0260e-01  6.47e-09  2.04e-08  2.15e-09  1.75e-08  1.11e-06  1.31e-01  \n 37  +2.0260e-01  +2.0260e-01  6.08e-09  2.02e-08  2.12e-09  1.70e-08  1.08e-06  7.92e-02  \n 38  +2.0258e-01  +2.0258e-01  5.42e-09  1.77e-08  1.86e-09  1.52e-08  9.26e-07  1.80e-01  \n 39  +2.0255e-01  +2.0255e-01  3.88e-09  1.45e-08  1.52e-09  1.23e-08  7.06e-07  4.71e-01  \n 40  +2.0254e-01  +2.0254e-01  3.44e-09  1.35e-08  1.42e-09  1.15e-08  6.40e-07  2.28e-01  \n 41  +2.0253e-01  +2.0253e-01  3.18e-09  1.31e-08  1.38e-09  1.10e-08  6.10e-07  1.50e-01  \n 42  +2.0250e-01  +2.0250e-01  1.65e-09  1.10e-08  1.15e-09  8.49e-09  4.45e-07  9.87e-01  \n 43  +2.0245e-01  +2.0245e-01  1.01e-09  6.07e-09  6.39e-10  5.03e-09  2.32e-07  5.61e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 12.432718535s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:10:19,820 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -6.17166561e-18 -6.17166561e-18 ... -6.17166561e-18\n  -6.17166561e-18 -6.17166561e-18]\n [-6.17166561e-18 -1.00000000e+00 -6.17166561e-18 ... -6.17166561e-18\n  -6.17166561e-18 -6.17166561e-18]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ... -4.43825811e-01\n   2.46020941e-01 -6.11402889e-03]\n ...\n [ 0.00000000e+00  0.00000000e+00 -6.59728945e-01 ... -1.00000000e+00\n   3.38025618e-01 -7.21525036e-03]\n [ 0.00000000e+00  0.00000000e+00  1.44032347e+00 ...  1.31362687e+00\n  -1.00000000e+00  2.61767150e-02]\n [ 0.00000000e+00  0.00000000e+00 -4.57091782e-01 ... -3.32340000e-01\n   1.46695065e-01 -1.00000000e+00]]\n2025-09-30 15:10:19,847 - xlsindy.simulation - INFO - Group 24, weight 0.64: [np.int64(30), np.int64(32), np.int64(33), np.int64(36), np.int64(40), np.int64(41), np.int64(45), np.int64(47), np.int64(64), np.int64(78), np.int64(90), np.int64(93)]\n2025-09-30 15:10:19,911 - __main__ - INFO - Regression completed in 15.20 seconds\nestimate variance between mujoco and model is :  1.9713242\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:10:05 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:10:05 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:10:05 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:10:05 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:10:05 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:10:05 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:10:05 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:10:05 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:10:05 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:10:05 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:10:06 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:10:06 PM: Finished problem compilation (took 1.120e+00 seconds).\n(CVXPY) Sep 30 03:10:06 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:10:19 PM: Problem status: optimal\n(CVXPY) Sep 30 03:10:19 PM: Optimal value: 2.024e-01\n(CVXPY) Sep 30 03:10:19 PM: Compilation took 1.120e+00 seconds\n(CVXPY) Sep 30 03:10:19 PM: Solver (including time spent in interface) took 1.282e+01 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.97s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.97s/batch]\n",
    "execution_time": 26.18168616294861,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/35d4c47b04e6fd5f5ffac5e15475583f --algorithm mixed --regression-type implicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "35d4c47b04e6fd5f5ffac5e15475583f",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [23, 1]\n2025-09-30 15:10:30,975 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:10:30,976 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:10:30,976 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:10:31,994 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:10:31,994 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:10:31,994 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:10:31,994 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:10:31,994 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:10:31,994 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.96e-01  1.12e+00  1.00e+00  3.87e+01   ------   \n  1  +3.4256e-01  +3.4166e-01  8.98e-04  6.41e-03  6.81e-04  9.98e-03  4.22e-01  9.89e-01  \n  2  +3.2129e-01  +3.2103e-01  2.59e-04  4.52e-04  4.77e-05  4.48e-04  2.99e-02  9.29e-01  \n  3  +2.8369e-01  +2.9213e-01  8.44e-03  2.87e-04  3.03e-05  9.09e-03  1.90e-02  6.07e-01  \n  4  +2.6182e-01  +2.6404e-01  2.22e-03  1.14e-04  1.20e-05  2.39e-03  7.56e-03  6.63e-01  \n  5  +2.5050e-01  +2.5287e-01  2.37e-03  7.77e-05  8.19e-06  2.50e-03  5.14e-03  4.63e-01  \n  6  +2.3366e-01  +2.3440e-01  7.40e-04  4.22e-05  4.44e-06  7.82e-04  2.79e-03  6.27e-01  \n  7  +2.3139e-01  +2.3239e-01  9.99e-04  3.36e-05  3.55e-06  1.04e-03  2.23e-03  4.22e-01  \n  8  +2.1713e-01  +2.1718e-01  5.28e-05  1.30e-05  1.37e-06  6.01e-05  8.63e-04  8.58e-01  \n  9  +2.1657e-01  +2.1664e-01  7.57e-05  1.20e-05  1.27e-06  8.39e-05  8.03e-04  2.27e-01  \n 10  +2.0727e-01  +2.0728e-01  6.86e-06  5.74e-06  6.02e-07  8.10e-06  4.09e-04  7.79e-01  \n 11  +2.0432e-01  +2.0432e-01  1.99e-06  2.80e-06  2.94e-07  2.35e-06  2.79e-04  4.93e-01  \n 12  +2.0367e-01  +2.0367e-01  1.24e-06  1.76e-06  1.84e-07  1.44e-06  2.42e-04  2.45e-01  \n 13  +2.0326e-01  +2.0326e-01  8.20e-07  9.64e-07  1.01e-07  9.24e-07  1.94e-04  5.95e-01  \n 14  +2.0323e-01  +2.0323e-01  7.32e-07  8.59e-07  8.98e-08  8.26e-07  1.80e-04  1.63e-01  \n 15  +2.0320e-01  +2.0320e-01  6.54e-07  7.93e-07  8.29e-08  7.41e-07  1.68e-04  2.31e-01  \n 16  +2.0319e-01  +2.0319e-01  6.21e-07  7.56e-07  7.91e-08  7.04e-07  1.61e-04  1.50e-01  \n 17  +2.0319e-01  +2.0319e-01  5.63e-07  7.26e-07  7.60e-08  6.44e-07  1.52e-04  2.88e-01  \n 18  +2.0306e-01  +2.0306e-01  3.33e-07  4.08e-07  4.27e-08  3.80e-07  1.00e-04  3.93e-01  \n 19  +2.0301e-01  +2.0301e-01  2.07e-07  2.62e-07  2.75e-08  2.38e-07  6.39e-05  5.31e-01  \n 20  +2.0296e-01  +2.0296e-01  9.44e-08  1.22e-07  1.29e-08  1.11e-07  2.71e-05  8.09e-01  \n 21  +2.0296e-01  +2.0296e-01  7.85e-08  1.10e-07  1.16e-08  9.46e-08  2.15e-05  3.14e-01  \n 22  +2.0296e-01  +2.0296e-01  7.17e-08  1.10e-07  1.16e-08  8.79e-08  2.09e-05  9.76e-02  \n 23  +2.0294e-01  +2.0294e-01  6.48e-08  8.37e-08  8.83e-09  7.86e-08  1.40e-05  3.47e-01  \n 24  +2.0294e-01  +2.0294e-01  5.69e-08  7.76e-08  8.19e-09  7.04e-08  1.20e-05  2.18e-01  \n 25  +2.0294e-01  +2.0294e-01  4.89e-08  7.42e-08  7.83e-09  6.24e-08  1.06e-05  2.30e-01  \n 26  +2.0294e-01  +2.0294e-01  4.57e-08  7.25e-08  7.65e-09  5.92e-08  9.96e-06  1.20e-01  \n 27  +2.0293e-01  +2.0293e-01  3.59e-08  6.58e-08  6.94e-09  4.92e-08  8.10e-06  3.30e-01  \n 28  +2.0294e-01  +2.0294e-01  3.38e-08  6.55e-08  6.91e-09  4.73e-08  7.85e-06  9.78e-02  \n 29  +2.0293e-01  +2.0293e-01  3.02e-08  5.89e-08  6.21e-09  4.32e-08  6.55e-06  2.39e-01  \n 30  +2.0292e-01  +2.0292e-01  2.81e-08  5.73e-08  6.04e-09  4.09e-08  6.24e-06  8.30e-02  \n 31  +2.0292e-01  +2.0292e-01  2.57e-08  5.53e-08  5.83e-09  3.83e-08  5.84e-06  1.20e-01  \n 32  +2.0293e-01  +2.0293e-01  1.58e-08  5.21e-08  5.49e-09  2.96e-08  4.65e-06  5.75e-01  \n 33  +2.0293e-01  +2.0293e-01  1.54e-08  5.15e-08  5.42e-09  2.93e-08  4.53e-06  5.19e-02  \n 34  +2.0293e-01  +2.0293e-01  1.36e-08  4.89e-08  5.15e-09  2.77e-08  4.04e-06  2.38e-01  \n 35  +2.0290e-01  +2.0290e-01  1.40e-08  3.52e-08  3.71e-09  2.69e-08  2.55e-06  4.93e-01  \n 36  +2.0289e-01  +2.0289e-01  1.41e-08  2.93e-08  3.09e-09  2.64e-08  1.98e-06  3.22e-01  \n 37  +2.0289e-01  +2.0289e-01  1.41e-08  2.93e-08  3.09e-09  2.66e-08  1.98e-06  7.38e-03  \n 38  +2.0288e-01  +2.0288e-01  1.32e-08  2.92e-08  3.08e-09  2.54e-08  1.96e-06  3.04e-02  \n 39  +2.0288e-01  +2.0288e-01  1.25e-08  2.90e-08  3.06e-09  2.48e-08  1.92e-06  8.21e-02  \n 40  +2.0287e-01  +2.0287e-01  1.20e-08  2.75e-08  2.90e-09  2.43e-08  1.76e-06  1.92e-01  \n 41  +2.0287e-01  +2.0287e-01  1.16e-08  2.57e-08  2.71e-09  2.36e-08  1.61e-06  1.30e-01  \n 42  +2.0286e-01  +2.0286e-01  1.13e-08  2.56e-08  2.69e-09  2.34e-08  1.56e-06  1.12e-01  \n 43  +2.0286e-01  +2.0286e-01  1.09e-08  2.48e-08  2.61e-09  2.28e-08  1.50e-06  6.76e-02  \n 44  +2.0286e-01  +2.0286e-01  1.07e-08  2.38e-08  2.51e-09  2.35e-08  1.34e-06  4.07e-01  \n 45  +2.0286e-01  +2.0286e-01  1.02e-08  2.37e-08  2.50e-09  2.28e-08  1.33e-06  3.42e-02  \n 46  +2.0282e-01  +2.0282e-01  1.13e-08  1.73e-08  1.82e-09  2.26e-08  8.91e-07  4.72e-01  \n 47  +2.0281e-01  +2.0281e-01  9.99e-09  1.71e-08  1.80e-09  2.11e-08  8.66e-07  1.48e-01  \n 48  +2.0278e-01  +2.0278e-01  1.06e-08  1.40e-08  1.48e-09  2.10e-08  6.81e-07  2.76e-01  \n 49  +2.0274e-01  +2.0274e-01  1.12e-08  1.07e-08  1.13e-09  2.06e-08  4.92e-07  4.04e-01  \n 50  +2.0271e-01  +2.0271e-01  1.13e-08  8.78e-09  9.24e-10  1.99e-08  3.85e-07  3.72e-01  \n 51  +2.0266e-01  +2.0266e-01  1.11e-08  6.62e-09  6.97e-10  1.86e-08  2.81e-07  3.28e-01  \n 52  +2.0265e-01  +2.0265e-01  1.09e-08  6.51e-09  6.85e-10  1.84e-08  2.72e-07  1.78e-01  \n 53  +2.0254e-01  +2.0254e-01  9.56e-09  3.44e-09  3.63e-10  1.46e-08  1.38e-07  5.41e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 15.303923173s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:10:48,880 - xlsindy.simulation - INFO - Group 2, weight 0.20: [np.int64(2), np.int64(4), np.int64(31)]\n2025-09-30 15:10:48,880 - xlsindy.simulation - INFO - Group 11, weight 0.73: [np.int64(12), np.int64(30), np.int64(32), np.int64(33), np.int64(36), np.int64(39), np.int64(40), np.int64(41), np.int64(44), np.int64(45), np.int64(47), np.int64(48), np.int64(57), np.int64(61), np.int64(67), np.int64(78), np.int64(90), np.int64(93)]\n2025-09-30 15:10:48,881 - xlsindy.simulation - INFO - Group 13, weight 0.30: [np.int64(15), np.int64(69), np.int64(87), np.int64(92)]\n2025-09-30 15:10:48,881 - xlsindy.simulation - INFO - Group 17, weight 0.31: [np.int64(20), np.int64(60), np.int64(76), np.int64(81)]\n2025-09-30 15:10:48,917 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:10:48,936 - __main__ - INFO - Regression completed in 17.96 seconds\nestimate variance between mujoco and model is :  0.24056777\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:10:31 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:10:31 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:10:31 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:10:31 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:10:31 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:10:32 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:10:32 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:10:32 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:10:32 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:10:32 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:10:32 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:10:33 PM: Finished problem compilation (took 1.132e+00 seconds).\n(CVXPY) Sep 30 03:10:33 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:10:48 PM: Problem status: optimal\n(CVXPY) Sep 30 03:10:48 PM: Optimal value: 2.023e-01\n(CVXPY) Sep 30 03:10:48 PM: Compilation took 1.132e+00 seconds\n(CVXPY) Sep 30 03:10:48 PM: Solver (including time spent in interface) took 1.568e+01 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.51s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.51s/batch]\n",
    "execution_time": 29.14280605316162,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/35d4c47b04e6fd5f5ffac5e15475583f --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "35d4c47b04e6fd5f5ffac5e15475583f",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [23, 1]\n2025-09-30 15:11:00,509 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:11:00,509 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:11:00,509 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:11:01,539 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:11:01,539 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:11:01,539 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:11:01,539 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:11:01,539 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:11:01,539 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.96e-01  1.12e+00  1.00e+00  3.88e+01   ------   \n  1  +3.4254e-01  +3.4165e-01  8.98e-04  6.41e-03  6.80e-04  9.98e-03  4.22e-01  9.89e-01  \n  2  +3.2123e-01  +3.2098e-01  2.58e-04  4.52e-04  4.77e-05  4.48e-04  2.99e-02  9.30e-01  \n  3  +2.8358e-01  +2.9204e-01  8.46e-03  2.87e-04  3.02e-05  9.11e-03  1.90e-02  6.08e-01  \n  4  +2.6165e-01  +2.6388e-01  2.22e-03  1.14e-04  1.20e-05  2.40e-03  7.55e-03  6.63e-01  \n  5  +2.5030e-01  +2.5268e-01  2.38e-03  7.77e-05  8.19e-06  2.51e-03  5.14e-03  4.62e-01  \n  6  +2.3341e-01  +2.3415e-01  7.38e-04  4.21e-05  4.43e-06  7.80e-04  2.78e-03  6.29e-01  \n  7  +2.3113e-01  +2.3212e-01  9.94e-04  3.36e-05  3.54e-06  1.04e-03  2.22e-03  4.22e-01  \n  8  +2.1691e-01  +2.1696e-01  5.20e-05  1.29e-05  1.36e-06  5.92e-05  8.59e-04  8.58e-01  \n  9  +2.1634e-01  +2.1641e-01  7.44e-05  1.20e-05  1.26e-06  8.25e-05  7.99e-04  2.26e-01  \n 10  +2.0710e-01  +2.0711e-01  6.95e-06  5.71e-06  5.99e-07  8.18e-06  4.07e-04  7.80e-01  \n 11  +2.0400e-01  +2.0401e-01  3.17e-06  3.17e-06  3.32e-07  3.58e-06  3.30e-04  7.14e-01  \n 12  +2.0318e-01  +2.0318e-01  7.55e-07  1.10e-06  1.15e-07  8.77e-07  1.92e-04  5.55e-01  \n 13  +2.0297e-01  +2.0297e-01  4.95e-07  6.95e-07  7.26e-08  5.71e-07  1.53e-04  3.78e-01  \n 14  +2.0284e-01  +2.0284e-01  2.79e-07  4.01e-07  4.19e-08  3.23e-07  1.08e-04  3.98e-01  \n 15  +2.0270e-01  +2.0270e-01  4.83e-08  9.46e-08  9.89e-09  5.87e-08  3.31e-05  9.10e-01  \n 16  +2.0267e-01  +2.0267e-01  8.81e-09  2.02e-08  2.11e-09  1.10e-08  7.73e-06  8.16e-01  \n 17  +2.0266e-01  +2.0266e-01  1.21e-09  3.18e-09  3.33e-10  1.56e-09  1.25e-06  8.62e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.797266909s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:11:09,933 - xlsindy.simulation - INFO - Group 13, weight 0.27: [np.int64(15), np.int64(20), np.int64(39), np.int64(57), np.int64(61), np.int64(62), np.int64(67), np.int64(87), np.int64(92)]\n2025-09-30 15:11:09,933 - xlsindy.simulation - INFO - Group 21, weight 0.21: [np.int64(29), np.int64(32), np.int64(34), np.int64(41)]\n2025-09-30 15:11:09,933 - xlsindy.simulation - INFO - Group 22, weight 0.25: [np.int64(30), np.int64(31), np.int64(33), np.int64(36)]\n2025-09-30 15:11:09,933 - xlsindy.simulation - INFO - Group 28, weight 0.67: [np.int64(45), np.int64(78), np.int64(90), np.int64(93)]\n2025-09-30 15:11:09,933 - xlsindy.simulation - INFO - Group 30, weight 0.31: [np.int64(47), np.int64(58), np.int64(64)]\n2025-09-30 15:11:09,991 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:11:10,014 - __main__ - INFO - Regression completed in 9.51 seconds\nestimate variance between mujoco and model is :  1.2516174\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:11:01 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:11:01 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:11:01 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:11:01 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:11:01 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:11:01 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:11:01 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:11:01 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:11:01 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:11:01 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:11:02 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:11:02 PM: Finished problem compilation (took 1.142e+00 seconds).\n(CVXPY) Sep 30 03:11:02 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:11:09 PM: Problem status: optimal\n(CVXPY) Sep 30 03:11:09 PM: Optimal value: 2.027e-01\n(CVXPY) Sep 30 03:11:09 PM: Compilation took 1.142e+00 seconds\n(CVXPY) Sep 30 03:11:09 PM: Solver (including time spent in interface) took 7.188e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.77s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.77s/batch]\n",
    "execution_time": 22.164551258087158,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/35d4c47b04e6fd5f5ffac5e15475583f --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "35d4c47b04e6fd5f5ffac5e15475583f",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [23, 1]\n2025-09-30 15:11:22,684 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:11:22,685 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:11:22,685 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:11:23,784 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:11:23,785 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:11:23,785 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:11:23,785 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:11:23,785 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:11:23,785 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.96e-01  1.12e+00  1.00e+00  3.88e+01   ------   \n  1  +3.4258e-01  +3.4169e-01  8.97e-04  6.41e-03  6.79e-04  9.98e-03  4.23e-01  9.89e-01  \n  2  +3.2118e-01  +3.2092e-01  2.55e-04  4.57e-04  4.81e-05  4.58e-04  3.03e-02  9.29e-01  \n  3  +2.8398e-01  +2.9249e-01  8.51e-03  2.97e-04  3.13e-05  9.17e-03  1.97e-02  5.94e-01  \n  4  +2.6290e-01  +2.6498e-01  2.08e-03  1.19e-04  1.25e-05  2.25e-03  7.90e-03  6.58e-01  \n  5  +2.5131e-01  +2.5326e-01  1.95e-03  8.24e-05  8.67e-06  2.07e-03  5.46e-03  4.44e-01  \n  6  +2.3587e-01  +2.3649e-01  6.23e-04  4.41e-05  4.64e-06  6.60e-04  2.93e-03  6.54e-01  \n  7  +2.3363e-01  +2.3440e-01  7.63e-04  3.60e-05  3.79e-06  8.00e-04  2.39e-03  4.01e-01  \n  8  +2.2197e-01  +2.2198e-01  1.43e-05  1.20e-05  1.26e-06  1.96e-05  8.03e-04  8.93e-01  \n  9  +2.2156e-01  +2.2159e-01  2.31e-05  1.15e-05  1.20e-06  2.88e-05  7.67e-04  1.68e-01  \n 10  +2.1439e-01  +2.1440e-01  5.14e-06  6.08e-06  6.36e-07  6.03e-06  4.50e-04  7.40e-01  \n 11  +2.1246e-01  +2.1246e-01  1.19e-06  2.45e-06  2.55e-07  1.42e-06  2.74e-04  5.60e-01  \n 12  +2.1176e-01  +2.1176e-01  3.35e-07  4.88e-07  5.07e-08  3.75e-07  1.23e-04  7.24e-01  \n 13  +2.1166e-01  +2.1166e-01  6.46e-08  1.06e-07  1.11e-08  7.32e-08  3.46e-05  8.04e-01  \n 14  +2.1164e-01  +2.1164e-01  9.93e-09  1.85e-08  1.92e-09  1.14e-08  6.46e-06  8.40e-01  \n 15  +2.1163e-01  +2.1163e-01  1.61e-09  3.49e-09  3.63e-10  1.89e-09  1.24e-06  8.35e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 5.628449189s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:11:31,004 - xlsindy.simulation - INFO - Group 2, weight 0.23: [np.int64(2), np.int64(4), np.int64(30), np.int64(33), np.int64(34), np.int64(39)]\n2025-09-30 15:11:31,004 - xlsindy.simulation - INFO - Group 17, weight 0.26: [np.int64(20), np.int64(76), np.int64(81)]\n2025-09-30 15:11:31,004 - xlsindy.simulation - INFO - Group 22, weight 0.26: [np.int64(29), np.int64(31), np.int64(32), np.int64(36), np.int64(41)]\n2025-09-30 15:11:31,004 - xlsindy.simulation - INFO - Group 28, weight 0.26: [np.int64(45), np.int64(67), np.int64(87), np.int64(90)]\n2025-09-30 15:11:31,005 - xlsindy.simulation - INFO - Group 37, weight 0.21: [np.int64(57), np.int64(61), np.int64(62)]\n2025-09-30 15:11:31,005 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:11:31,025 - __main__ - INFO - Regression completed in 8.34 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:11:23 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:11:23 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:11:23 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:11:23 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:11:23 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:11:23 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:11:23 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:11:23 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:11:23 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:11:23 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:11:24 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:11:24 PM: Finished problem compilation (took 1.155e+00 seconds).\n(CVXPY) Sep 30 03:11:24 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:11:30 PM: Problem status: optimal\n(CVXPY) Sep 30 03:11:30 PM: Optimal value: 2.116e-01\n(CVXPY) Sep 30 03:11:30 PM: Compilation took 1.155e+00 seconds\n(CVXPY) Sep 30 03:11:30 PM: Solver (including time spent in interface) took 6.011e+00 seconds\n",
    "execution_time": 12.66157603263855,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/35d4c47b04e6fd5f5ffac5e15475583f --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "35d4c47b04e6fd5f5ffac5e15475583f",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [23, 1]\n2025-09-30 15:11:34,941 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:11:34,941 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:11:34,941 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:11:35,958 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:11:35,958 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:11:35,958 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:11:35,958 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:11:35,958 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:11:35,958 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.96e-01  1.12e+00  1.00e+00  3.87e+01   ------   \n  1  +3.4256e-01  +3.4166e-01  8.98e-04  6.41e-03  6.81e-04  9.98e-03  4.22e-01  9.89e-01  \n  2  +3.2128e-01  +3.2102e-01  2.58e-04  4.52e-04  4.77e-05  4.48e-04  2.99e-02  9.29e-01  \n  3  +2.8368e-01  +2.9212e-01  8.45e-03  2.87e-04  3.03e-05  9.09e-03  1.90e-02  6.07e-01  \n  4  +2.6180e-01  +2.6402e-01  2.22e-03  1.14e-04  1.20e-05  2.39e-03  7.56e-03  6.63e-01  \n  5  +2.5048e-01  +2.5285e-01  2.37e-03  7.77e-05  8.19e-06  2.50e-03  5.14e-03  4.63e-01  \n  6  +2.3363e-01  +2.3437e-01  7.40e-04  4.21e-05  4.44e-06  7.82e-04  2.79e-03  6.27e-01  \n  7  +2.3135e-01  +2.3235e-01  9.99e-04  3.36e-05  3.55e-06  1.04e-03  2.23e-03  4.22e-01  \n  8  +2.1709e-01  +2.1714e-01  5.28e-05  1.30e-05  1.37e-06  6.02e-05  8.63e-04  8.58e-01  \n  9  +2.1653e-01  +2.1660e-01  7.57e-05  1.20e-05  1.27e-06  8.39e-05  8.02e-04  2.27e-01  \n 10  +2.0723e-01  +2.0724e-01  6.85e-06  5.72e-06  6.01e-07  8.09e-06  4.08e-04  7.80e-01  \n 11  +2.0427e-01  +2.0428e-01  1.99e-06  2.80e-06  2.93e-07  2.35e-06  2.78e-04  4.95e-01  \n 12  +2.0392e-01  +2.0392e-01  1.95e-06  2.25e-06  2.36e-07  2.24e-06  2.73e-04  1.64e-01  \n 13  +2.0361e-01  +2.0361e-01  1.47e-06  1.68e-06  1.76e-07  1.68e-06  2.44e-04  1.84e-01  \n 14  +2.0342e-01  +2.0342e-01  1.18e-06  1.28e-06  1.34e-07  1.34e-06  2.15e-04  2.14e-01  \n 15  +2.0315e-01  +2.0315e-01  6.91e-07  6.67e-07  6.99e-08  7.79e-07  1.47e-04  4.87e-01  \n 16  +2.0310e-01  +2.0310e-01  5.51e-07  5.27e-07  5.52e-08  6.26e-07  1.14e-04  4.41e-01  \n 17  +2.0311e-01  +2.0311e-01  4.39e-07  4.96e-07  5.20e-08  5.13e-07  9.60e-05  4.93e-01  \n 18  +2.0299e-01  +2.0299e-01  2.98e-07  2.80e-07  2.95e-08  3.44e-07  5.80e-05  4.27e-01  \n 19  +2.0297e-01  +2.0297e-01  2.53e-07  2.43e-07  2.55e-08  2.95e-07  4.72e-05  2.70e-01  \n 20  +2.0293e-01  +2.0293e-01  1.76e-07  1.68e-07  1.77e-08  2.09e-07  2.93e-05  5.26e-01  \n 21  +2.0293e-01  +2.0293e-01  1.63e-07  1.63e-07  1.71e-08  1.96e-07  2.71e-05  1.47e-01  \n 22  +2.0293e-01  +2.0293e-01  1.43e-07  1.55e-07  1.63e-08  1.75e-07  2.44e-05  1.98e-01  \n 23  +2.0293e-01  +2.0293e-01  1.21e-07  1.51e-07  1.59e-08  1.54e-07  2.23e-05  2.22e-01  \n 24  +2.0293e-01  +2.0293e-01  1.11e-07  1.48e-07  1.56e-08  1.44e-07  2.11e-05  1.30e-01  \n 25  +2.0295e-01  +2.0295e-01  3.53e-08  1.47e-07  1.54e-08  7.09e-08  1.64e-05  7.87e-01  \n 26  +2.0293e-01  +2.0293e-01  2.85e-08  1.41e-07  1.48e-08  6.38e-08  1.45e-05  2.93e-01  \n 27  +2.0293e-01  +2.0293e-01  2.54e-08  1.37e-07  1.44e-08  6.20e-08  1.28e-05  3.17e-01  \n 28  +2.0288e-01  +2.0288e-01  2.24e-08  9.99e-08  1.05e-08  5.22e-08  8.58e-06  3.92e-01  \n 29  +2.0279e-01  +2.0279e-01  2.11e-08  5.86e-08  6.16e-09  4.23e-08  4.59e-06  4.90e-01  \n 30  +2.0275e-01  +2.0275e-01  1.79e-08  4.49e-08  4.72e-09  3.63e-08  3.27e-06  3.69e-01  \n 31  +2.0274e-01  +2.0274e-01  1.74e-08  4.48e-08  4.71e-09  3.57e-08  3.24e-06  2.69e-02  \n 32  +2.0272e-01  +2.0272e-01  1.23e-08  3.96e-08  4.17e-09  2.95e-08  2.63e-06  4.10e-01  \n 33  +2.0270e-01  +2.0270e-01  1.12e-08  3.74e-08  3.94e-09  2.79e-08  2.41e-06  1.69e-01  \n 34  +2.0261e-01  +2.0261e-01  7.44e-09  2.16e-08  2.27e-09  1.88e-08  1.21e-06  6.78e-01  \n 35  +2.0261e-01  +2.0261e-01  6.93e-09  2.10e-08  2.21e-09  1.81e-08  1.16e-06  1.03e-01  \n 36  +2.0260e-01  +2.0260e-01  6.47e-09  2.04e-08  2.15e-09  1.75e-08  1.11e-06  1.31e-01  \n 37  +2.0260e-01  +2.0260e-01  6.08e-09  2.02e-08  2.12e-09  1.70e-08  1.08e-06  7.92e-02  \n 38  +2.0258e-01  +2.0258e-01  5.42e-09  1.77e-08  1.86e-09  1.52e-08  9.26e-07  1.80e-01  \n 39  +2.0255e-01  +2.0255e-01  3.88e-09  1.45e-08  1.52e-09  1.23e-08  7.06e-07  4.71e-01  \n 40  +2.0254e-01  +2.0254e-01  3.44e-09  1.35e-08  1.42e-09  1.15e-08  6.40e-07  2.28e-01  \n 41  +2.0253e-01  +2.0253e-01  3.18e-09  1.31e-08  1.38e-09  1.10e-08  6.10e-07  1.50e-01  \n 42  +2.0250e-01  +2.0250e-01  1.65e-09  1.10e-08  1.15e-09  8.49e-09  4.45e-07  9.87e-01  \n 43  +2.0245e-01  +2.0245e-01  1.01e-09  6.07e-09  6.39e-10  5.03e-09  2.32e-07  5.61e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 12.746636913s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:11:50,263 - xlsindy.simulation - INFO - Group 13, weight 0.31: [np.int64(15), np.int64(20), np.int64(68), np.int64(69), np.int64(87), np.int64(92)]\n2025-09-30 15:11:50,263 - xlsindy.simulation - INFO - Group 21, weight 0.42: [np.int64(29), np.int64(31), np.int64(34), np.int64(80)]\n2025-09-30 15:11:50,263 - xlsindy.simulation - INFO - Group 22, weight 0.64: [np.int64(30), np.int64(32), np.int64(33), np.int64(36), np.int64(39), np.int64(40), np.int64(41), np.int64(45), np.int64(47), np.int64(58), np.int64(61), np.int64(64), np.int64(78), np.int64(90), np.int64(93)]\n2025-09-30 15:11:50,315 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:11:50,332 - __main__ - INFO - Regression completed in 15.39 seconds\nestimate variance between mujoco and model is :  2.2067077\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:11:35 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:11:35 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:11:35 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:11:35 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:11:35 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:11:35 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:11:35 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:11:35 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:11:35 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:11:35 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:11:36 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:11:37 PM: Finished problem compilation (took 1.121e+00 seconds).\n(CVXPY) Sep 30 03:11:37 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:11:50 PM: Problem status: optimal\n(CVXPY) Sep 30 03:11:50 PM: Optimal value: 2.024e-01\n(CVXPY) Sep 30 03:11:50 PM: Compilation took 1.121e+00 seconds\n(CVXPY) Sep 30 03:11:50 PM: Solver (including time spent in interface) took 1.313e+01 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.96s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.96s/batch]\n",
    "execution_time": 26.39472198486328,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/35d4c47b04e6fd5f5ffac5e15475583f --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "35d4c47b04e6fd5f5ffac5e15475583f",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [26, 1]\n2025-09-30 15:12:01,309 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:12:01,310 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:12:02,354 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:12:02,379 - xlsindy.simulation - INFO - Experimental matrix norm: 622.1492085938486\n2025-09-30 15:12:02,379 - xlsindy.simulation - INFO - Experimental matrix variance: 10.946844284263099\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.09e+00  1.00e+00  1.71e+01   ------   \n  1  +1.0585e-01  +1.0514e-01  7.04e-04  6.30e-03  1.77e-03  9.99e-03  1.83e-01  9.89e-01  \n  2  +8.9469e-02  +8.9293e-02  1.76e-04  1.68e-04  4.71e-05  9.44e-05  4.89e-03  9.73e-01  \n  3  +6.1656e-02  +6.1996e-02  3.40e-04  4.67e-05  1.31e-05  4.81e-04  1.36e-03  7.70e-01  \n  4  +5.2733e-02  +5.3318e-02  5.85e-04  3.66e-05  1.03e-05  6.97e-04  1.07e-03  3.06e-01  \n  5  +3.1633e-02  +3.1853e-02  2.20e-04  1.76e-05  4.93e-06  2.31e-04  5.14e-04  9.89e-01  \n  6  +2.8807e-02  +2.9009e-02  2.03e-04  1.34e-05  3.76e-06  2.13e-04  3.93e-04  5.11e-01  \n  7  +2.5038e-02  +2.5052e-02  1.36e-05  5.75e-06  1.60e-06  1.59e-05  1.71e-04  6.89e-01  \n  8  +2.4194e-02  +2.4203e-02  8.99e-06  5.19e-06  1.45e-06  1.07e-05  1.58e-04  1.76e-01  \n  9  +2.2287e-02  +2.2289e-02  2.33e-06  2.64e-06  7.30e-07  2.74e-06  1.02e-04  7.43e-01  \n 10  +2.1941e-02  +2.1942e-02  1.60e-06  1.84e-06  5.07e-07  1.86e-06  8.91e-05  3.18e-01  \n 11  +2.1575e-02  +2.1575e-02  3.78e-07  5.54e-07  1.53e-07  4.50e-07  4.47e-05  6.45e-01  \n 12  +2.1445e-02  +2.1445e-02  1.14e-07  1.74e-07  4.80e-08  1.37e-07  1.99e-05  7.73e-01  \n 13  +2.1420e-02  +2.1420e-02  5.35e-08  9.29e-08  2.56e-08  6.54e-08  1.16e-05  5.24e-01  \n 14  +2.1405e-02  +2.1406e-02  1.73e-08  4.38e-08  1.21e-08  2.29e-08  5.75e-06  6.78e-01  \n 15  +2.1399e-02  +2.1399e-02  5.82e-09  2.34e-08  6.46e-09  8.82e-09  3.14e-06  6.41e-01  \n 16  +2.1394e-02  +2.1394e-02  2.55e-10  1.01e-08  2.78e-09  1.04e-09  1.34e-06  9.45e-01  \n 17  +2.1392e-02  +2.1392e-02  2.66e-10  6.28e-09  1.73e-09  5.42e-10  8.18e-07  5.57e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.260499857s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:12:10,278 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00  5.83683306e-19  5.83683306e-19 ...  5.83683306e-19\n   5.83683306e-19  5.83683306e-19]\n [ 5.83683306e-19 -1.00000000e+00  5.83683306e-19 ...  5.83683306e-19\n   5.83683306e-19  5.83683306e-19]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  1.04199877e-03\n  -7.80925583e-03  6.34587933e-04]\n ...\n [ 0.00000000e+00  0.00000000e+00  3.68263410e-02 ... -1.00000000e+00\n  -9.31508943e-01  1.00429986e+00]\n [ 0.00000000e+00  0.00000000e+00 -4.53110385e-01 ... -9.18290067e-01\n  -1.00000000e+00  9.94774337e-01]\n [ 0.00000000e+00  0.00000000e+00  1.65320908e-01 ...  9.59919185e-01\n   9.63030592e-01 -1.00000000e+00]]\n2025-09-30 15:12:10,326 - xlsindy.simulation - INFO - Group 38, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:12:10,327 - xlsindy.simulation - INFO - Group 62, weight 0.22: [np.int64(76), np.int64(79), np.int64(80)]\n2025-09-30 15:12:10,371 - __main__ - INFO - Regression completed in 9.06 seconds\nestimate variance between mujoco and model is :  0.24891347\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:12:02 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:12:02 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:12:02 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:12:02 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:12:02 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:12:02 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:12:02 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:12:02 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:12:02 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:12:02 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:12:03 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:12:03 PM: Finished problem compilation (took 1.142e+00 seconds).\n(CVXPY) Sep 30 03:12:03 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:12:10 PM: Problem status: optimal\n(CVXPY) Sep 30 03:12:10 PM: Optimal value: 2.139e-02\n(CVXPY) Sep 30 03:12:10 PM: Compilation took 1.142e+00 seconds\n(CVXPY) Sep 30 03:12:10 PM: Solver (including time spent in interface) took 6.652e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.90s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.90s/batch]\n",
    "execution_time": 19.912692546844482,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c083362f97eb79e351058d7a771a693b --algorithm mixed --regression-type implicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c083362f97eb79e351058d7a771a693b",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [26, 1]\n2025-09-30 15:12:21,270 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:12:21,270 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:12:22,311 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:12:22,333 - xlsindy.simulation - INFO - Experimental matrix norm: 622.1288764406718\n2025-09-30 15:12:22,334 - xlsindy.simulation - INFO - Experimental matrix variance: 10.946131560251755\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.09e+00  1.00e+00  1.71e+01   ------   \n  1  +1.0589e-01  +1.0518e-01  7.04e-04  6.30e-03  1.77e-03  9.99e-03  1.83e-01  9.89e-01  \n  2  +8.9508e-02  +8.9331e-02  1.76e-04  1.68e-04  4.71e-05  9.44e-05  4.89e-03  9.73e-01  \n  3  +6.1695e-02  +6.2034e-02  3.39e-04  4.67e-05  1.31e-05  4.80e-04  1.36e-03  7.70e-01  \n  4  +5.2769e-02  +5.3355e-02  5.85e-04  3.67e-05  1.03e-05  6.97e-04  1.07e-03  3.05e-01  \n  5  +3.1656e-02  +3.1875e-02  2.19e-04  1.76e-05  4.93e-06  2.31e-04  5.15e-04  9.88e-01  \n  6  +2.8770e-02  +2.8967e-02  1.97e-04  1.34e-05  3.75e-06  2.07e-04  3.92e-04  5.16e-01  \n  7  +2.5054e-02  +2.5067e-02  1.31e-05  5.68e-06  1.58e-06  1.53e-05  1.69e-04  6.90e-01  \n  8  +2.4230e-02  +2.4239e-02  8.60e-06  5.15e-06  1.44e-06  1.03e-05  1.57e-04  1.70e-01  \n  9  +2.2387e-02  +2.2390e-02  2.43e-06  2.71e-06  7.48e-07  2.84e-06  1.04e-04  7.21e-01  \n 10  +2.2051e-02  +2.2053e-02  1.63e-06  1.90e-06  5.23e-07  1.89e-06  8.97e-05  3.08e-01  \n 11  +2.1810e-02  +2.1810e-02  8.83e-07  1.09e-06  3.02e-07  1.03e-06  6.82e-05  3.64e-01  \n 12  +2.1616e-02  +2.1616e-02  3.12e-07  4.35e-07  1.20e-07  3.69e-07  3.94e-05  5.94e-01  \n 13  +2.1528e-02  +2.1528e-02  9.87e-08  1.54e-07  4.23e-08  1.19e-07  1.78e-05  6.57e-01  \n 14  +2.1488e-02  +2.1488e-02  1.86e-08  3.30e-08  9.10e-09  2.29e-08  4.42e-06  7.97e-01  \n 15  +2.1479e-02  +2.1479e-02  3.17e-09  6.15e-09  1.69e-09  3.98e-09  8.53e-07  8.24e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.277867959s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:12:30,369 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00  1.27370063e-19  1.27370063e-19 ...  1.27370063e-19\n   1.27370063e-19  1.27370063e-19]\n [ 1.27370063e-19 -1.00000000e+00  1.27370063e-19 ...  1.27370063e-19\n   1.27370063e-19  1.27370063e-19]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  3.99914172e-02\n  -5.05406993e-02 -4.12300056e-03]\n ...\n [ 0.00000000e+00  0.00000000e+00  1.82765621e-01 ... -1.00000000e+00\n  -4.64267395e-01  9.95019899e-01]\n [ 0.00000000e+00  0.00000000e+00 -3.02589301e-01 ... -5.25203413e-01\n  -1.00000000e+00  1.00910945e+00]\n [ 0.00000000e+00  0.00000000e+00  1.78147928e-02 ...  7.68029234e-01\n   7.09785529e-01 -1.00000000e+00]]\n2025-09-30 15:12:30,401 - xlsindy.simulation - INFO - Group 39, weight 0.59: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(92), np.int64(93)]\n2025-09-30 15:12:30,402 - xlsindy.simulation - INFO - Group 63, weight 0.22: [np.int64(76), np.int64(79), np.int64(80)]\n2025-09-30 15:12:30,457 - __main__ - INFO - Regression completed in 9.19 seconds\nestimate variance between mujoco and model is :  3.2442684\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:12:22 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:12:22 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:12:22 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:12:22 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:12:22 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:12:22 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:12:22 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:12:22 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:12:22 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:12:22 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:12:23 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:12:23 PM: Finished problem compilation (took 1.253e+00 seconds).\n(CVXPY) Sep 30 03:12:23 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:12:30 PM: Problem status: optimal\n(CVXPY) Sep 30 03:12:30 PM: Optimal value: 2.148e-02\n(CVXPY) Sep 30 03:12:30 PM: Compilation took 1.253e+00 seconds\n(CVXPY) Sep 30 03:12:30 PM: Solver (including time spent in interface) took 6.675e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.21s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.21s/batch]\n",
    "execution_time": 21.34979224205017,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c083362f97eb79e351058d7a771a693b --algorithm mixed --regression-type implicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c083362f97eb79e351058d7a771a693b",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [26, 1]\n2025-09-30 15:12:42,627 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:12:42,627 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:12:43,650 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:12:43,673 - xlsindy.simulation - INFO - Experimental matrix norm: 621.952286004837\n2025-09-30 15:12:43,673 - xlsindy.simulation - INFO - Experimental matrix variance: 10.9399456204106\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.09e+00  1.00e+00  1.71e+01   ------   \n  1  +1.0649e-01  +1.0578e-01  7.07e-04  6.30e-03  1.77e-03  9.99e-03  1.84e-01  9.89e-01  \n  2  +9.0166e-02  +8.9988e-02  1.79e-04  1.69e-04  4.72e-05  9.43e-05  4.96e-03  9.73e-01  \n  3  +6.2543e-02  +6.2912e-02  3.69e-04  4.80e-05  1.34e-05  5.13e-04  1.41e-03  7.68e-01  \n  4  +5.3584e-02  +5.4194e-02  6.10e-04  3.79e-05  1.06e-05  7.24e-04  1.11e-03  3.01e-01  \n  5  +3.2743e-02  +3.2963e-02  2.19e-04  1.78e-05  4.94e-06  2.31e-04  5.22e-04  9.90e-01  \n  6  +2.9188e-02  +2.9328e-02  1.41e-04  1.22e-05  3.39e-06  1.49e-04  3.59e-04  5.72e-01  \n  7  +2.5910e-02  +2.5920e-02  9.86e-06  4.92e-06  1.36e-06  1.14e-05  1.49e-04  7.01e-01  \n  8  +2.5453e-02  +2.5461e-02  8.14e-06  4.68e-06  1.30e-06  9.45e-06  1.44e-04  1.08e-01  \n  9  +2.3663e-02  +2.3665e-02  1.87e-06  1.69e-06  4.63e-07  2.07e-06  8.02e-05  9.40e-01  \n 10  +2.3371e-02  +2.3372e-02  9.55e-07  8.07e-07  2.20e-07  1.04e-06  5.78e-05  6.77e-01  \n 11  +2.3223e-02  +2.3223e-02  1.11e-07  1.23e-07  3.35e-08  1.24e-07  1.32e-05  8.26e-01  \n 12  +2.3196e-02  +2.3196e-02  1.74e-08  2.19e-08  5.98e-09  1.97e-08  2.63e-06  8.38e-01  \n 13  +2.3191e-02  +2.3191e-02  2.53e-09  3.77e-09  1.03e-09  2.93e-09  4.62e-07  8.50e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 4.696739738s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:12:50,049 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00  7.50872226e-19  7.50872226e-19 ...  7.50872226e-19\n   7.50872226e-19  7.50872226e-19]\n [ 7.50872226e-19 -1.00000000e+00  7.50872226e-19 ...  7.50872226e-19\n   7.50872226e-19  7.50872226e-19]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  1.52564740e-01\n  -1.16893569e-01 -3.97862721e-01]\n ...\n [ 0.00000000e+00  0.00000000e+00  1.93096773e-01 ... -1.00000000e+00\n   7.75565376e-01  1.10802544e+00]\n [ 0.00000000e+00  0.00000000e+00 -1.71391680e-01 ...  9.00397519e-01\n  -1.00000000e+00  7.27540770e-01]\n [ 0.00000000e+00  0.00000000e+00 -4.50151786e-02 ...  9.48702588e-02\n   5.30033149e-02 -1.00000000e+00]]\n2025-09-30 15:12:50,106 - __main__ - INFO - Regression completed in 7.48 seconds\n",
    "stderr": "(CVXPY) Sep 30 03:12:43 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:12:43 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:12:43 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:12:43 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:12:43 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:12:43 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:12:43 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:12:43 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:12:43 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:12:43 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:12:44 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:12:44 PM: Finished problem compilation (took 1.168e+00 seconds).\n(CVXPY) Sep 30 03:12:44 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:12:50 PM: Problem status: optimal\n(CVXPY) Sep 30 03:12:50 PM: Optimal value: 2.319e-02\n(CVXPY) Sep 30 03:12:50 PM: Compilation took 1.168e+00 seconds\n(CVXPY) Sep 30 03:12:50 PM: Solver (including time spent in interface) took 5.098e+00 seconds\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 243, in <module>\n    xlsindy.dynamics_modeling.generate_acceleration_function(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/dynamics_modeling.py\", line 67, in generate_acceleration_function\n    if str(symbol_matrix[3, i]) not in str(dynamic_equations[i]):\nIndexError: index 0 is out of bounds for axis 0 with size 0\n",
    "execution_time": 10.983179569244385,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c083362f97eb79e351058d7a771a693b --algorithm mixed --regression-type implicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c083362f97eb79e351058d7a771a693b",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [26, 1]\n2025-09-30 15:12:53,634 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:12:53,634 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:12:54,640 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:12:54,655 - xlsindy.simulation - INFO - Experimental matrix norm: 622.147168857965\n2025-09-30 15:12:54,655 - xlsindy.simulation - INFO - Experimental matrix variance: 10.94677277891821\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.09e+00  1.00e+00  1.71e+01   ------   \n  1  +1.0585e-01  +1.0515e-01  7.04e-04  6.30e-03  1.77e-03  9.99e-03  1.83e-01  9.89e-01  \n  2  +8.9473e-02  +8.9296e-02  1.76e-04  1.68e-04  4.71e-05  9.44e-05  4.89e-03  9.73e-01  \n  3  +6.1659e-02  +6.1999e-02  3.40e-04  4.67e-05  1.31e-05  4.81e-04  1.36e-03  7.70e-01  \n  4  +5.2735e-02  +5.3321e-02  5.85e-04  3.66e-05  1.03e-05  6.97e-04  1.07e-03  3.06e-01  \n  5  +3.1634e-02  +3.1853e-02  2.20e-04  1.76e-05  4.93e-06  2.31e-04  5.14e-04  9.89e-01  \n  6  +2.8804e-02  +2.9006e-02  2.02e-04  1.34e-05  3.76e-06  2.13e-04  3.93e-04  5.11e-01  \n  7  +2.5037e-02  +2.5051e-02  1.36e-05  5.74e-06  1.60e-06  1.59e-05  1.71e-04  6.89e-01  \n  8  +2.4195e-02  +2.4204e-02  9.00e-06  5.19e-06  1.45e-06  1.07e-05  1.58e-04  1.75e-01  \n  9  +2.2288e-02  +2.2291e-02  2.33e-06  2.64e-06  7.29e-07  2.74e-06  1.02e-04  7.43e-01  \n 10  +2.1945e-02  +2.1946e-02  1.60e-06  1.84e-06  5.08e-07  1.86e-06  8.91e-05  3.15e-01  \n 11  +2.1582e-02  +2.1582e-02  3.91e-07  5.70e-07  1.57e-07  4.65e-07  4.56e-05  6.34e-01  \n 12  +2.1482e-02  +2.1482e-02  1.83e-07  2.76e-07  7.61e-08  2.18e-07  2.85e-05  5.78e-01  \n 13  +2.1451e-02  +2.1451e-02  8.28e-08  1.68e-07  4.63e-08  1.04e-07  1.91e-05  6.44e-01  \n 14  +2.1415e-02  +2.1415e-02  2.46e-08  6.17e-08  1.70e-08  3.25e-08  7.94e-06  7.09e-01  \n 15  +2.1409e-02  +2.1409e-02  5.50e-09  3.92e-08  1.08e-08  1.05e-08  5.14e-06  7.48e-01  \n 16  +2.1402e-02  +2.1402e-02  7.64e-10  2.18e-08  6.02e-09  3.56e-09  2.91e-06  7.25e-01  \n 17  +2.1397e-02  +2.1397e-02  2.12e-10  9.65e-09  2.66e-09  1.45e-09  1.30e-06  6.12e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.112125809s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:13:02,452 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -4.11587251e-20 -4.11587251e-20 ... -4.11587251e-20\n  -4.11587251e-20 -4.11587251e-20]\n [-4.11587251e-20 -1.00000000e+00 -4.11587251e-20 ... -4.11587251e-20\n  -4.11587251e-20 -4.11587251e-20]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  1.74848266e-03\n  -8.93009324e-03  6.34084113e-04]\n ...\n [ 0.00000000e+00  0.00000000e+00  3.76193062e-02 ... -1.00000000e+00\n  -9.16198535e-01  1.00324956e+00]\n [ 0.00000000e+00  0.00000000e+00 -4.52359882e-01 ... -9.13631691e-01\n  -1.00000000e+00  9.96893947e-01]\n [ 0.00000000e+00  0.00000000e+00  1.64505869e-01 ...  9.57162802e-01\n   9.54480305e-01 -1.00000000e+00]]\n2025-09-30 15:13:02,505 - xlsindy.simulation - INFO - Group 38, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:13:02,505 - xlsindy.simulation - INFO - Group 62, weight 0.22: [np.int64(76), np.int64(79), np.int64(80)]\n2025-09-30 15:13:02,535 - __main__ - INFO - Regression completed in 8.90 seconds\nestimate variance between mujoco and model is :  0.30983582\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:12:54 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:12:54 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:12:54 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:12:54 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:12:54 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:12:54 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:12:54 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:12:54 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:12:54 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:12:54 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:12:55 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:12:55 PM: Finished problem compilation (took 1.171e+00 seconds).\n(CVXPY) Sep 30 03:12:55 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:13:02 PM: Problem status: optimal\n(CVXPY) Sep 30 03:13:02 PM: Optimal value: 2.139e-02\n(CVXPY) Sep 30 03:13:02 PM: Compilation took 1.171e+00 seconds\n(CVXPY) Sep 30 03:13:02 PM: Solver (including time spent in interface) took 6.492e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.85s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.85s/batch]\n",
    "execution_time": 20.236791849136353,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c083362f97eb79e351058d7a771a693b --algorithm mixed --regression-type implicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c083362f97eb79e351058d7a771a693b",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [26, 1]\n2025-09-30 15:13:14,135 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:13:14,136 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:13:14,136 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:13:15,207 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:13:15,208 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:13:15,208 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:13:15,208 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:13:15,208 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:13:15,208 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.09e+00  1.00e+00  1.71e+01   ------   \n  1  +1.0585e-01  +1.0514e-01  7.04e-04  6.30e-03  1.77e-03  9.99e-03  1.83e-01  9.89e-01  \n  2  +8.9469e-02  +8.9293e-02  1.76e-04  1.68e-04  4.71e-05  9.44e-05  4.89e-03  9.73e-01  \n  3  +6.1656e-02  +6.1996e-02  3.40e-04  4.67e-05  1.31e-05  4.81e-04  1.36e-03  7.70e-01  \n  4  +5.2733e-02  +5.3318e-02  5.85e-04  3.66e-05  1.03e-05  6.97e-04  1.07e-03  3.06e-01  \n  5  +3.1633e-02  +3.1853e-02  2.20e-04  1.76e-05  4.93e-06  2.31e-04  5.14e-04  9.89e-01  \n  6  +2.8807e-02  +2.9009e-02  2.03e-04  1.34e-05  3.76e-06  2.13e-04  3.93e-04  5.11e-01  \n  7  +2.5038e-02  +2.5052e-02  1.36e-05  5.75e-06  1.60e-06  1.59e-05  1.71e-04  6.89e-01  \n  8  +2.4194e-02  +2.4203e-02  8.99e-06  5.19e-06  1.45e-06  1.07e-05  1.58e-04  1.76e-01  \n  9  +2.2287e-02  +2.2289e-02  2.33e-06  2.64e-06  7.30e-07  2.74e-06  1.02e-04  7.43e-01  \n 10  +2.1941e-02  +2.1942e-02  1.60e-06  1.84e-06  5.07e-07  1.86e-06  8.91e-05  3.18e-01  \n 11  +2.1575e-02  +2.1575e-02  3.78e-07  5.54e-07  1.53e-07  4.50e-07  4.47e-05  6.45e-01  \n 12  +2.1445e-02  +2.1445e-02  1.14e-07  1.74e-07  4.80e-08  1.37e-07  1.99e-05  7.73e-01  \n 13  +2.1420e-02  +2.1420e-02  5.35e-08  9.29e-08  2.56e-08  6.54e-08  1.16e-05  5.24e-01  \n 14  +2.1405e-02  +2.1406e-02  1.73e-08  4.38e-08  1.21e-08  2.29e-08  5.75e-06  6.78e-01  \n 15  +2.1399e-02  +2.1399e-02  5.82e-09  2.34e-08  6.46e-09  8.82e-09  3.14e-06  6.41e-01  \n 16  +2.1394e-02  +2.1394e-02  2.55e-10  1.01e-08  2.78e-09  1.04e-09  1.34e-06  9.45e-01  \n 17  +2.1392e-02  +2.1392e-02  2.66e-10  6.28e-09  1.73e-09  5.42e-10  8.18e-07  5.57e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.090847714s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:13:22,886 - xlsindy.simulation - INFO - Group 16, weight 0.21: [np.int64(18), np.int64(76), np.int64(79), np.int64(80)]\n2025-09-30 15:13:22,887 - xlsindy.simulation - INFO - Group 37, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:13:22,927 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:13:22,948 - __main__ - INFO - Regression completed in 8.81 seconds\nestimate variance between mujoco and model is :  0.24891347\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:13:15 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:13:15 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:13:15 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:13:15 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:13:15 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:13:15 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:13:15 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:13:15 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:13:15 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:13:15 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:13:15 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:13:16 PM: Finished problem compilation (took 1.150e+00 seconds).\n(CVXPY) Sep 30 03:13:16 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:13:22 PM: Problem status: optimal\n(CVXPY) Sep 30 03:13:22 PM: Optimal value: 2.139e-02\n(CVXPY) Sep 30 03:13:22 PM: Compilation took 1.150e+00 seconds\n(CVXPY) Sep 30 03:13:22 PM: Solver (including time spent in interface) took 6.471e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\n",
    "execution_time": 20.914061069488525,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c083362f97eb79e351058d7a771a693b --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c083362f97eb79e351058d7a771a693b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [26, 1]\n2025-09-30 15:13:34,902 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:13:34,902 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:13:34,902 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:13:35,962 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:13:35,962 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:13:35,962 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:13:35,962 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:13:35,962 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:13:35,962 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.09e+00  1.00e+00  1.71e+01   ------   \n  1  +1.0589e-01  +1.0518e-01  7.04e-04  6.30e-03  1.77e-03  9.99e-03  1.83e-01  9.89e-01  \n  2  +8.9508e-02  +8.9331e-02  1.76e-04  1.68e-04  4.71e-05  9.44e-05  4.89e-03  9.73e-01  \n  3  +6.1695e-02  +6.2034e-02  3.39e-04  4.67e-05  1.31e-05  4.80e-04  1.36e-03  7.70e-01  \n  4  +5.2769e-02  +5.3355e-02  5.85e-04  3.67e-05  1.03e-05  6.97e-04  1.07e-03  3.05e-01  \n  5  +3.1656e-02  +3.1875e-02  2.19e-04  1.76e-05  4.93e-06  2.31e-04  5.15e-04  9.88e-01  \n  6  +2.8770e-02  +2.8967e-02  1.97e-04  1.34e-05  3.75e-06  2.07e-04  3.92e-04  5.16e-01  \n  7  +2.5054e-02  +2.5067e-02  1.31e-05  5.68e-06  1.58e-06  1.53e-05  1.69e-04  6.90e-01  \n  8  +2.4230e-02  +2.4239e-02  8.60e-06  5.15e-06  1.44e-06  1.03e-05  1.57e-04  1.70e-01  \n  9  +2.2387e-02  +2.2390e-02  2.43e-06  2.71e-06  7.48e-07  2.84e-06  1.04e-04  7.21e-01  \n 10  +2.2051e-02  +2.2053e-02  1.63e-06  1.90e-06  5.23e-07  1.89e-06  8.97e-05  3.08e-01  \n 11  +2.1810e-02  +2.1810e-02  8.83e-07  1.09e-06  3.02e-07  1.03e-06  6.82e-05  3.64e-01  \n 12  +2.1616e-02  +2.1616e-02  3.12e-07  4.35e-07  1.20e-07  3.69e-07  3.94e-05  5.94e-01  \n 13  +2.1528e-02  +2.1528e-02  9.87e-08  1.54e-07  4.23e-08  1.19e-07  1.78e-05  6.57e-01  \n 14  +2.1488e-02  +2.1488e-02  1.86e-08  3.30e-08  9.10e-09  2.29e-08  4.42e-06  7.97e-01  \n 15  +2.1479e-02  +2.1479e-02  3.17e-09  6.15e-09  1.69e-09  3.98e-09  8.53e-07  8.24e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.303385584s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:13:43,870 - xlsindy.simulation - INFO - Group 37, weight 0.59: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:13:43,870 - xlsindy.simulation - INFO - Group 60, weight 0.21: [np.int64(79), np.int64(80), np.int64(87)]\n2025-09-30 15:13:43,884 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:13:43,905 - __main__ - INFO - Regression completed in 9.00 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:13:35 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:13:35 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:13:35 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:13:35 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:13:35 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:13:35 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:13:35 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:13:35 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:13:35 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:13:35 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:13:36 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:13:37 PM: Finished problem compilation (took 1.121e+00 seconds).\n(CVXPY) Sep 30 03:13:37 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:13:43 PM: Problem status: optimal\n(CVXPY) Sep 30 03:13:43 PM: Optimal value: 2.148e-02\n(CVXPY) Sep 30 03:13:43 PM: Compilation took 1.121e+00 seconds\n(CVXPY) Sep 30 03:13:43 PM: Solver (including time spent in interface) took 6.683e+00 seconds\n",
    "execution_time": 12.99616551399231,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c083362f97eb79e351058d7a771a693b --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c083362f97eb79e351058d7a771a693b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [26, 1]\n2025-09-30 15:13:47,800 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:13:47,800 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:13:47,800 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:13:48,854 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:13:48,854 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:13:48,854 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:13:48,854 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:13:48,854 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:13:48,854 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.09e+00  1.00e+00  1.71e+01   ------   \n  1  +1.0649e-01  +1.0578e-01  7.07e-04  6.30e-03  1.77e-03  9.99e-03  1.84e-01  9.89e-01  \n  2  +9.0166e-02  +8.9988e-02  1.79e-04  1.69e-04  4.72e-05  9.43e-05  4.96e-03  9.73e-01  \n  3  +6.2543e-02  +6.2912e-02  3.69e-04  4.80e-05  1.34e-05  5.13e-04  1.41e-03  7.68e-01  \n  4  +5.3584e-02  +5.4194e-02  6.10e-04  3.79e-05  1.06e-05  7.24e-04  1.11e-03  3.01e-01  \n  5  +3.2743e-02  +3.2963e-02  2.19e-04  1.78e-05  4.94e-06  2.31e-04  5.22e-04  9.90e-01  \n  6  +2.9188e-02  +2.9328e-02  1.41e-04  1.22e-05  3.39e-06  1.49e-04  3.59e-04  5.72e-01  \n  7  +2.5910e-02  +2.5920e-02  9.86e-06  4.92e-06  1.36e-06  1.14e-05  1.49e-04  7.01e-01  \n  8  +2.5453e-02  +2.5461e-02  8.14e-06  4.68e-06  1.30e-06  9.45e-06  1.44e-04  1.08e-01  \n  9  +2.3663e-02  +2.3665e-02  1.87e-06  1.69e-06  4.63e-07  2.07e-06  8.02e-05  9.40e-01  \n 10  +2.3371e-02  +2.3372e-02  9.55e-07  8.07e-07  2.20e-07  1.04e-06  5.78e-05  6.77e-01  \n 11  +2.3223e-02  +2.3223e-02  1.11e-07  1.23e-07  3.35e-08  1.24e-07  1.32e-05  8.26e-01  \n 12  +2.3196e-02  +2.3196e-02  1.74e-08  2.19e-08  5.98e-09  1.97e-08  2.63e-06  8.38e-01  \n 13  +2.3191e-02  +2.3191e-02  2.53e-09  3.77e-09  1.03e-09  2.93e-09  4.62e-07  8.50e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 4.710185918s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:13:55,142 - xlsindy.simulation - INFO - Group 7, weight 0.22: [np.int64(8), np.int64(15), np.int64(91), np.int64(92)]\n2025-09-30 15:13:55,142 - xlsindy.simulation - INFO - Group 16, weight 0.20: [np.int64(19), np.int64(53), np.int64(54)]\n2025-09-30 15:13:55,142 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:13:55,162 - __main__ - INFO - Regression completed in 7.36 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:13:48 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:13:48 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:13:48 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:13:48 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:13:48 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:13:48 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:13:48 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:13:48 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:13:48 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:13:48 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:13:49 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:13:49 PM: Finished problem compilation (took 1.135e+00 seconds).\n(CVXPY) Sep 30 03:13:49 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:13:55 PM: Problem status: optimal\n(CVXPY) Sep 30 03:13:55 PM: Optimal value: 2.319e-02\n(CVXPY) Sep 30 03:13:55 PM: Compilation took 1.135e+00 seconds\n(CVXPY) Sep 30 03:13:55 PM: Solver (including time spent in interface) took 5.093e+00 seconds\n",
    "execution_time": 11.16121792793274,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c083362f97eb79e351058d7a771a693b --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c083362f97eb79e351058d7a771a693b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [26, 1]\n2025-09-30 15:13:59,244 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:13:59,245 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:13:59,245 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:14:00,285 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:14:00,285 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:14:00,285 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:14:00,285 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:14:00,286 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:14:00,286 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.09e+00  1.00e+00  1.71e+01   ------   \n  1  +1.0585e-01  +1.0515e-01  7.04e-04  6.30e-03  1.77e-03  9.99e-03  1.83e-01  9.89e-01  \n  2  +8.9473e-02  +8.9296e-02  1.76e-04  1.68e-04  4.71e-05  9.44e-05  4.89e-03  9.73e-01  \n  3  +6.1659e-02  +6.1999e-02  3.40e-04  4.67e-05  1.31e-05  4.81e-04  1.36e-03  7.70e-01  \n  4  +5.2735e-02  +5.3321e-02  5.85e-04  3.66e-05  1.03e-05  6.97e-04  1.07e-03  3.06e-01  \n  5  +3.1634e-02  +3.1853e-02  2.20e-04  1.76e-05  4.93e-06  2.31e-04  5.14e-04  9.89e-01  \n  6  +2.8804e-02  +2.9006e-02  2.02e-04  1.34e-05  3.76e-06  2.13e-04  3.93e-04  5.11e-01  \n  7  +2.5037e-02  +2.5051e-02  1.36e-05  5.74e-06  1.60e-06  1.59e-05  1.71e-04  6.89e-01  \n  8  +2.4195e-02  +2.4204e-02  9.00e-06  5.19e-06  1.45e-06  1.07e-05  1.58e-04  1.75e-01  \n  9  +2.2288e-02  +2.2291e-02  2.33e-06  2.64e-06  7.29e-07  2.74e-06  1.02e-04  7.43e-01  \n 10  +2.1945e-02  +2.1946e-02  1.60e-06  1.84e-06  5.08e-07  1.86e-06  8.91e-05  3.15e-01  \n 11  +2.1582e-02  +2.1582e-02  3.91e-07  5.70e-07  1.57e-07  4.65e-07  4.56e-05  6.34e-01  \n 12  +2.1482e-02  +2.1482e-02  1.83e-07  2.76e-07  7.61e-08  2.18e-07  2.85e-05  5.78e-01  \n 13  +2.1451e-02  +2.1451e-02  8.28e-08  1.68e-07  4.63e-08  1.04e-07  1.91e-05  6.44e-01  \n 14  +2.1415e-02  +2.1415e-02  2.46e-08  6.17e-08  1.70e-08  3.25e-08  7.94e-06  7.09e-01  \n 15  +2.1409e-02  +2.1409e-02  5.50e-09  3.92e-08  1.08e-08  1.05e-08  5.14e-06  7.48e-01  \n 16  +2.1402e-02  +2.1402e-02  7.64e-10  2.18e-08  6.02e-09  3.56e-09  2.91e-06  7.25e-01  \n 17  +2.1397e-02  +2.1397e-02  2.12e-10  9.65e-09  2.66e-09  1.45e-09  1.30e-06  6.12e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.159657023s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:14:08,023 - xlsindy.simulation - INFO - Group 16, weight 0.21: [np.int64(18), np.int64(76), np.int64(79), np.int64(80)]\n2025-09-30 15:14:08,024 - xlsindy.simulation - INFO - Group 37, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:14:08,071 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:14:08,091 - __main__ - INFO - Regression completed in 8.85 seconds\nestimate variance between mujoco and model is :  0.30983582\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:14:00 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:14:00 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:14:00 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:14:00 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:14:00 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:14:00 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:14:00 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:14:00 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:14:00 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:14:00 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:14:01 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:14:01 PM: Finished problem compilation (took 1.127e+00 seconds).\n(CVXPY) Sep 30 03:14:01 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:14:07 PM: Problem status: optimal\n(CVXPY) Sep 30 03:14:07 PM: Optimal value: 2.139e-02\n(CVXPY) Sep 30 03:14:07 PM: Compilation took 1.127e+00 seconds\n(CVXPY) Sep 30 03:14:07 PM: Solver (including time spent in interface) took 6.546e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.93s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.93s/batch]\n",
    "execution_time": 21.68216300010681,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c083362f97eb79e351058d7a771a693b --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c083362f97eb79e351058d7a771a693b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [15, 1]\n2025-09-30 15:14:20,905 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:14:20,905 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:14:22,820 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0009373741910746172\n2025-09-30 15:14:22,964 - __main__ - INFO - Regression completed in 2.06 seconds\nestimate variance between mujoco and model is :  0.9318608\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.101e-01, tolerance: 4.881e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.101e-01, tolerance: 4.881e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.91s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.91s/batch]\n",
    "execution_time": 14.06632399559021,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2309a619371a07bf0147527fca53574d --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2309a619371a07bf0147527fca53574d",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [15, 1]\n2025-09-30 15:14:35,030 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:14:35,030 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:14:36,908 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0009369628444943692\n2025-09-30 15:14:37,049 - __main__ - INFO - Regression completed in 2.02 seconds\nestimate variance between mujoco and model is :  0.9355003\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-01, tolerance: 4.880e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-01, tolerance: 4.880e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.04s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.04s/batch]\n",
    "execution_time": 13.537153005599976,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2309a619371a07bf0147527fca53574d --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2309a619371a07bf0147527fca53574d",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [15, 1]\n2025-09-30 15:14:48,264 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:14:48,264 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:14:50,221 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0009331944766283918\n2025-09-30 15:14:50,382 - __main__ - INFO - Regression completed in 2.12 seconds\nestimate variance between mujoco and model is :  1.2388799\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+00, tolerance: 4.879e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+00, tolerance: 4.879e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.92s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.92s/batch]\n",
    "execution_time": 14.008900880813599,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2309a619371a07bf0147527fca53574d --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2309a619371a07bf0147527fca53574d",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [15, 1]\n2025-09-30 15:15:02,459 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:15:02,459 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:15:04,359 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0009373331215937265\n2025-09-30 15:15:04,523 - __main__ - INFO - Regression completed in 2.06 seconds\nestimate variance between mujoco and model is :  0.9313689\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.099e-01, tolerance: 4.881e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.099e-01, tolerance: 4.881e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.99s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.99s/batch]\n",
    "execution_time": 14.251271963119507,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2309a619371a07bf0147527fca53574d --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2309a619371a07bf0147527fca53574d",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [15, 1]\n2025-09-30 15:15:16,776 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:15:16,776 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:15:16,776 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:15:17,802 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:15:17,803 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:15:17,803 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:15:17,803 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:15:17,803 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:15:17,803 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:15:18,547 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0009373741910746165\n2025-09-30 15:15:18,705 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:15:18,705 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:15:18,705 - __main__ - INFO - Regression completed in 1.93 seconds\nestimate variance between mujoco and model is :  0.9318608\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.101e-01, tolerance: 4.881e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.101e-01, tolerance: 4.881e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.90s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.90s/batch]\n",
    "execution_time": 14.445452213287354,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2309a619371a07bf0147527fca53574d --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2309a619371a07bf0147527fca53574d",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [15, 1]\n2025-09-30 15:15:31,115 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:15:31,116 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:15:31,116 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:15:32,138 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:15:32,139 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:15:32,139 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:15:32,139 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:15:32,139 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:15:32,139 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:15:32,869 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0009369628444943688\n2025-09-30 15:15:33,006 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:15:33,006 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:15:33,006 - __main__ - INFO - Regression completed in 1.89 seconds\nestimate variance between mujoco and model is :  0.9355003\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-01, tolerance: 4.880e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-01, tolerance: 4.880e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\n",
    "execution_time": 13.632537126541138,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2309a619371a07bf0147527fca53574d --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2309a619371a07bf0147527fca53574d",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [15, 1]\n2025-09-30 15:15:44,760 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:15:44,761 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:15:44,761 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:15:45,782 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:15:45,783 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:15:45,783 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:15:45,783 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:15:45,783 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:15:45,783 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:15:46,625 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0009331944766283917\n2025-09-30 15:15:46,787 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:15:46,787 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:15:46,787 - __main__ - INFO - Regression completed in 2.03 seconds\nestimate variance between mujoco and model is :  1.2388799\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+00, tolerance: 4.879e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+00, tolerance: 4.879e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\n",
    "execution_time": 14.074884414672852,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2309a619371a07bf0147527fca53574d --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2309a619371a07bf0147527fca53574d",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [15, 1]\n2025-09-30 15:15:58,626 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:15:58,626 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:15:58,626 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:15:59,651 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:15:59,651 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:15:59,651 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:15:59,651 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:15:59,652 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:15:59,652 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:16:00,389 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0009373331215937267\n2025-09-30 15:16:00,527 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:16:00,527 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:16:00,527 - __main__ - INFO - Regression completed in 1.90 seconds\nestimate variance between mujoco and model is :  0.9313689\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.099e-01, tolerance: 4.881e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.099e-01, tolerance: 4.881e-02\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.09s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.09s/batch]\n",
    "execution_time": 13.724049091339111,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2309a619371a07bf0147527fca53574d --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2309a619371a07bf0147527fca53574d",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [4, 1]\n2025-09-30 15:16:12,399 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:16:12,399 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:16:14,356 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.042163452885586136\n2025-09-30 15:16:14,363 - __main__ - INFO - Regression completed in 1.96 seconds\nestimate variance between mujoco and model is :  5.0610805\n2025-09-30 15:16:20,990 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  6.95batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  6.95batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 12.435324907302856,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/d0e68da8f552f6446a3b14a5b661507e --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "d0e68da8f552f6446a3b14a5b661507e",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [4, 1]\n2025-09-30 15:16:24,763 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:16:24,763 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:16:26,674 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.042272151937707385\n2025-09-30 15:16:26,681 - __main__ - INFO - Regression completed in 1.92 seconds\nestimate variance between mujoco and model is :  5.1543655\n2025-09-30 15:16:33,113 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.88batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.87batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 12.003261089324951,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/d0e68da8f552f6446a3b14a5b661507e --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "d0e68da8f552f6446a3b14a5b661507e",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [4, 1]\n2025-09-30 15:16:36,980 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:16:36,981 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:16:38,766 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.04324392613339681\n2025-09-30 15:16:38,775 - __main__ - INFO - Regression completed in 1.79 seconds\nestimate variance between mujoco and model is :  4.723467\n2025-09-30 15:16:45,182 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.28batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.27batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 12.30069088935852,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/d0e68da8f552f6446a3b14a5b661507e --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "d0e68da8f552f6446a3b14a5b661507e",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [4, 1]\n2025-09-30 15:16:49,281 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:16:49,282 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:16:51,209 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0421743292069083\n2025-09-30 15:16:51,217 - __main__ - INFO - Regression completed in 1.93 seconds\nestimate variance between mujoco and model is :  5.068426\n2025-09-30 15:16:56,884 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.68batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.67batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.373546838760376,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/d0e68da8f552f6446a3b14a5b661507e --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "d0e68da8f552f6446a3b14a5b661507e",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [4, 1]\n2025-09-30 15:17:01,406 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:17:01,407 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:17:01,407 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:17:02,447 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:17:02,447 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:17:02,447 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:17:02,448 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:17:02,448 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:17:02,448 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:17:03,212 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.042163452885586136\n2025-09-30 15:17:03,220 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:17:03,220 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:17:03,220 - __main__ - INFO - Regression completed in 1.81 seconds\nestimate variance between mujoco and model is :  5.0610805\n2025-09-30 15:17:09,450 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.53batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.53batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 12.573286533355713,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/d0e68da8f552f6446a3b14a5b661507e --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "d0e68da8f552f6446a3b14a5b661507e",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [4, 1]\n2025-09-30 15:17:13,172 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:17:13,173 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:17:13,173 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:17:14,216 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:17:14,217 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:17:14,217 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:17:14,217 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:17:14,217 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:17:14,218 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:17:14,952 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.04227215193770745\n2025-09-30 15:17:14,959 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:17:14,959 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:17:14,959 - __main__ - INFO - Regression completed in 1.79 seconds\nestimate variance between mujoco and model is :  5.1543655\n2025-09-30 15:17:21,246 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.49batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.49batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.861728191375732,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/d0e68da8f552f6446a3b14a5b661507e --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "d0e68da8f552f6446a3b14a5b661507e",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [4, 1]\n2025-09-30 15:17:24,935 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:17:24,936 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:17:24,936 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:17:25,976 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:17:25,976 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:17:25,976 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:17:25,976 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:17:25,977 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:17:25,977 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:17:26,622 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.04324392613339676\n2025-09-30 15:17:26,630 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:17:26,630 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:17:26,630 - __main__ - INFO - Regression completed in 1.69 seconds\nestimate variance between mujoco and model is :  4.723467\n2025-09-30 15:17:32,799 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.27batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  8.26batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.542936563491821,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/d0e68da8f552f6446a3b14a5b661507e --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "d0e68da8f552f6446a3b14a5b661507e",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [4, 1]\n2025-09-30 15:17:36,477 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:17:36,477 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:17:36,477 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:17:37,490 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:17:37,490 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:17:37,490 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:17:37,490 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:17:37,490 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:17:37,490 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:17:38,255 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.04217432920690828\n2025-09-30 15:17:38,262 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:17:38,262 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:17:38,262 - __main__ - INFO - Regression completed in 1.79 seconds\nestimate variance between mujoco and model is :  5.068426\n2025-09-30 15:17:44,516 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.77batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.77batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 11.71560287475586,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/d0e68da8f552f6446a3b14a5b661507e --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "d0e68da8f552f6446a3b14a5b661507e",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [12, 1]\n2025-09-30 15:17:48,401 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:17:48,401 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:17:49,619 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0344980174875051\n2025-09-30 15:17:49,663 - __main__ - INFO - Regression completed in 1.26 seconds\nestimate variance between mujoco and model is :  4.3364816\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.49s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.49s/batch]\n",
    "execution_time": 12.497179508209229,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/4efad3f9007af9796ee297c3e7074f6a --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "4efad3f9007af9796ee297c3e7074f6a",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [12, 1]\n2025-09-30 15:18:00,744 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:18:00,744 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:18:02,429 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03532891637621764\n2025-09-30 15:18:02,468 - __main__ - INFO - Regression completed in 1.72 seconds\nestimate variance between mujoco and model is :  4.469644\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.52s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.52s/batch]\n",
    "execution_time": 13.290636539459229,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/4efad3f9007af9796ee297c3e7074f6a --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "4efad3f9007af9796ee297c3e7074f6a",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [12, 1]\n2025-09-30 15:18:14,005 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:18:14,005 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:18:15,794 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.28784059407913853\n2025-09-30 15:18:15,801 - __main__ - INFO - Regression completed in 1.80 seconds\nestimate variance between mujoco and model is :  9.387126\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.66s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.66s/batch]\n",
    "execution_time": 12.976261138916016,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/4efad3f9007af9796ee297c3e7074f6a --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "4efad3f9007af9796ee297c3e7074f6a",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [12, 1]\n2025-09-30 15:18:26,945 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:18:26,945 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:18:28,178 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03458162479402929\n2025-09-30 15:18:28,218 - __main__ - INFO - Regression completed in 1.27 seconds\nestimate variance between mujoco and model is :  4.344994\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.53s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.53s/batch]\n",
    "execution_time": 11.863225221633911,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/4efad3f9007af9796ee297c3e7074f6a --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "4efad3f9007af9796ee297c3e7074f6a",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [12, 1]\n2025-09-30 15:18:38,826 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:18:38,827 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:18:38,827 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:18:39,844 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:18:39,845 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:18:39,845 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:18:39,845 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:18:39,845 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:18:39,845 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:18:40,030 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.034498017487505125\n2025-09-30 15:18:40,073 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:18:40,073 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:18:40,074 - __main__ - INFO - Regression completed in 1.25 seconds\nestimate variance between mujoco and model is :  4.3364816\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.64s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.64s/batch]\n",
    "execution_time": 12.427261590957642,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/4efad3f9007af9796ee297c3e7074f6a --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "4efad3f9007af9796ee297c3e7074f6a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [12, 1]\n2025-09-30 15:18:51,502 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:18:51,502 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:18:51,503 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:18:52,522 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:18:52,522 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:18:52,522 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:18:52,522 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:18:52,522 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:18:52,522 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:18:52,710 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03532891637621764\n2025-09-30 15:18:52,747 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:18:52,747 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:18:52,747 - __main__ - INFO - Regression completed in 1.24 seconds\nestimate variance between mujoco and model is :  4.469644\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.70s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.70s/batch]\n",
    "execution_time": 12.7826406955719,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/4efad3f9007af9796ee297c3e7074f6a --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "4efad3f9007af9796ee297c3e7074f6a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [12, 1]\n2025-09-30 15:19:03,992 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:19:03,992 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:19:03,992 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:19:05,014 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:19:05,014 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:19:05,014 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:19:05,014 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:19:05,014 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:19:05,014 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:19:05,127 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.28784059407913853\n2025-09-30 15:19:05,131 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:19:05,131 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:19:05,131 - __main__ - INFO - Regression completed in 1.14 seconds\nestimate variance between mujoco and model is :  9.387126\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.76s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.76s/batch]\n",
    "execution_time": 12.91810941696167,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/4efad3f9007af9796ee297c3e7074f6a --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "4efad3f9007af9796ee297c3e7074f6a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [12, 1]\n2025-09-30 15:19:17,159 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:19:17,160 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:19:17,160 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:19:18,766 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:19:18,767 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:19:18,767 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:19:18,767 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:19:18,767 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:19:18,767 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:19:19,004 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.034581624794029306\n2025-09-30 15:19:19,044 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:19:19,044 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:19:19,044 - __main__ - INFO - Regression completed in 1.88 seconds\nestimate variance between mujoco and model is :  4.344994\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.61s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.61s/batch]\n",
    "execution_time": 13.60022759437561,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/4efad3f9007af9796ee297c3e7074f6a --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "4efad3f9007af9796ee297c3e7074f6a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [29, 1]\n2025-09-30 15:19:31,086 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:19:31,086 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.356684446334839,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/67c8aadb4858a2a874fa2f7253a8d2c6 --algorithm mixed --regression-type implicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "67c8aadb4858a2a874fa2f7253a8d2c6",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [29, 1]\n2025-09-30 15:19:37,498 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:19:37,498 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.350435018539429,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/67c8aadb4858a2a874fa2f7253a8d2c6 --algorithm mixed --regression-type implicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "67c8aadb4858a2a874fa2f7253a8d2c6",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [29, 1]\n2025-09-30 15:19:43,665 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:19:43,666 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.934382438659668,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/67c8aadb4858a2a874fa2f7253a8d2c6 --algorithm mixed --regression-type implicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "67c8aadb4858a2a874fa2f7253a8d2c6",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [29, 1]\n2025-09-30 15:19:49,559 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:19:49,559 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.150123834609985,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/67c8aadb4858a2a874fa2f7253a8d2c6 --algorithm mixed --regression-type implicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "67c8aadb4858a2a874fa2f7253a8d2c6",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [29, 1]\n2025-09-30 15:19:55,716 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:19:55,716 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:19:55,716 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.091723918914795,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/67c8aadb4858a2a874fa2f7253a8d2c6 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "67c8aadb4858a2a874fa2f7253a8d2c6",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [29, 1]\n2025-09-30 15:20:01,747 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:20:01,747 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:20:01,747 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.811976671218872,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/67c8aadb4858a2a874fa2f7253a8d2c6 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "67c8aadb4858a2a874fa2f7253a8d2c6",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [29, 1]\n2025-09-30 15:20:07,531 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:20:07,531 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:20:07,532 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.731011867523193,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/67c8aadb4858a2a874fa2f7253a8d2c6 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "67c8aadb4858a2a874fa2f7253a8d2c6",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [29, 1]\n2025-09-30 15:20:13,572 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:20:13,572 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:20:13,572 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.176928520202637,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/67c8aadb4858a2a874fa2f7253a8d2c6 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "67c8aadb4858a2a874fa2f7253a8d2c6",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [17, 1]\n2025-09-30 15:20:19,718 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:20:19,719 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.101217746734619,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c78a50b25fd239479aebdbd9fffd1f23 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c78a50b25fd239479aebdbd9fffd1f23",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [17, 1]\n2025-09-30 15:20:25,607 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:20:25,608 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.884750127792358,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c78a50b25fd239479aebdbd9fffd1f23 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c78a50b25fd239479aebdbd9fffd1f23",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [17, 1]\n2025-09-30 15:20:31,726 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:20:31,726 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.259020090103149,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c78a50b25fd239479aebdbd9fffd1f23 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c78a50b25fd239479aebdbd9fffd1f23",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [17, 1]\n2025-09-30 15:20:37,732 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:20:37,732 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.79449200630188,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c78a50b25fd239479aebdbd9fffd1f23 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c78a50b25fd239479aebdbd9fffd1f23",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [17, 1]\n2025-09-30 15:20:43,494 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:20:43,494 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:20:43,494 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.765795469284058,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c78a50b25fd239479aebdbd9fffd1f23 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c78a50b25fd239479aebdbd9fffd1f23",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [17, 1]\n2025-09-30 15:20:49,270 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:20:49,270 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:20:49,270 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.788020610809326,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c78a50b25fd239479aebdbd9fffd1f23 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c78a50b25fd239479aebdbd9fffd1f23",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [17, 1]\n2025-09-30 15:20:55,117 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:20:55,118 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:20:55,118 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.897808790206909,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c78a50b25fd239479aebdbd9fffd1f23 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c78a50b25fd239479aebdbd9fffd1f23",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [17, 1]\n2025-09-30 15:21:00,983 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:21:00,984 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:21:00,984 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.8024373054504395,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/c78a50b25fd239479aebdbd9fffd1f23 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "c78a50b25fd239479aebdbd9fffd1f23",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [24, 1]\n2025-09-30 15:21:06,421 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:21:06,421 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:21:07,431 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:21:07,447 - xlsindy.simulation - INFO - Experimental matrix norm: 1920.5374980295228\n2025-09-30 15:21:07,447 - xlsindy.simulation - INFO - Experimental matrix variance: 104.35626053960239\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.27e+00  1.00e+00  5.31e+01   ------   \n  1  +1.2382e+00  +1.2367e+00  1.22e-03  6.77e-03  4.50e-04  9.97e-03  6.11e-01  9.88e-01  \n  2  +1.1979e+00  +1.1978e+00  4.10e-05  5.63e-04  3.72e-05  8.26e-04  5.10e-02  9.17e-01  \n  3  +1.1471e+00  +1.1608e+00  1.19e-02  3.98e-04  2.62e-05  1.45e-02  3.60e-02  5.36e-01  \n  4  +1.1219e+00  +1.1238e+00  1.74e-03  1.64e-04  1.08e-05  2.14e-03  1.48e-02  6.42e-01  \n  5  +1.1068e+00  +1.1076e+00  7.61e-04  1.37e-04  9.04e-06  9.43e-04  1.24e-02  2.58e-01  \n  6  +1.0917e+00  +1.0921e+00  3.57e-04  6.22e-05  4.09e-06  4.06e-04  5.65e-03  9.90e-01  \n  7  +1.0887e+00  +1.0889e+00  2.05e-04  5.46e-05  3.59e-06  2.33e-04  4.99e-03  3.18e-01  \n  8  +1.0863e+00  +1.0864e+00  6.23e-05  3.69e-05  2.42e-06  7.10e-05  3.46e-03  4.37e-01  \n  9  +1.0863e+00  +1.0864e+00  9.33e-05  3.50e-05  2.30e-06  1.05e-04  3.41e-03  8.65e-02  \n 10  +1.0855e+00  +1.0856e+00  8.61e-05  2.46e-05  1.61e-06  9.68e-05  2.81e-03  2.64e-01  \n 11  +1.0849e+00  +1.0850e+00  4.98e-05  2.22e-05  1.45e-06  5.64e-05  2.65e-03  2.64e-01  \n 12  +1.0845e+00  +1.0846e+00  6.78e-05  1.37e-05  9.02e-07  7.62e-05  2.03e-03  4.51e-01  \n 13  +1.0835e+00  +1.0835e+00  1.61e-05  8.97e-06  5.89e-07  1.88e-05  1.51e-03  5.82e-01  \n 14  +1.0834e+00  +1.0834e+00  2.14e-05  6.46e-06  4.25e-07  2.49e-05  1.12e-03  5.89e-01  \n 15  +1.0818e+00  +1.0818e+00  2.26e-06  2.18e-06  1.43e-07  2.91e-06  5.62e-04  7.69e-01  \n 16  +1.0816e+00  +1.0816e+00  2.99e-06  1.90e-06  1.25e-07  3.79e-06  4.69e-04  3.71e-01  \n 17  +1.0805e+00  +1.0805e+00  1.37e-06  8.43e-07  5.55e-08  1.71e-06  3.11e-04  6.14e-01  \n 18  +1.0800e+00  +1.0800e+00  6.25e-07  5.10e-07  3.36e-08  8.18e-07  1.83e-04  9.90e-01  \n 19  +1.0795e+00  +1.0795e+00  2.20e-07  1.91e-07  1.26e-08  2.94e-07  7.55e-05  7.71e-01  \n 20  +1.0791e+00  +1.0791e+00  4.08e-08  5.43e-08  3.62e-09  6.11e-08  2.11e-05  9.90e-01  \n 21  +1.0788e+00  +1.0788e+00  9.65e-09  1.32e-08  1.00e-09  1.49e-08  5.01e-06  8.63e-01  \n 22  +1.0788e+00  +1.0788e+00  1.72e-09  7.99e-09  7.27e-10  4.59e-09  3.14e-06  8.16e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 7.844527118s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:21:16,977 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00  2.47552795e-18  2.47552795e-18 ...  2.47552795e-18\n   2.47552795e-18  2.47552795e-18]\n [ 2.47552795e-18 -1.00000000e+00  2.47552795e-18 ...  2.47552795e-18\n   2.47552795e-18  2.47552795e-18]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ... -1.47654846e-01\n   1.90904671e-01 -5.77485861e-02]\n ...\n [ 0.00000000e+00  0.00000000e+00 -1.42017208e-01 ... -1.00000000e+00\n   1.98495415e-01 -5.32311430e-01]\n [ 0.00000000e+00  0.00000000e+00  1.24139488e-01 ...  1.34309532e-01\n  -1.00000000e+00 -5.34076347e-02]\n [ 0.00000000e+00  0.00000000e+00 -2.63722738e-02 ... -2.53284943e-01\n  -3.99377655e-02 -1.00000000e+00]]\n2025-09-30 15:21:17,001 - xlsindy.simulation - INFO - Group 4, weight 0.63: [np.int64(4), np.int64(12), np.int64(15), np.int64(20), np.int64(36), np.int64(43), np.int64(45), np.int64(46), np.int64(48), np.int64(58), np.int64(59), np.int64(61), np.int64(62), np.int64(64), np.int64(69), np.int64(91), np.int64(92)]\n2025-09-30 15:21:17,060 - __main__ - INFO - Regression completed in 10.64 seconds\nestimate variance between mujoco and model is :  5.233375\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:21:07 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:21:07 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:21:07 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:21:07 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:21:07 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:21:07 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:21:07 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:21:07 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:21:07 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:21:07 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:21:08 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:21:08 PM: Finished problem compilation (took 1.109e+00 seconds).\n(CVXPY) Sep 30 03:21:08 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:21:16 PM: Problem status: optimal\n(CVXPY) Sep 30 03:21:16 PM: Optimal value: 1.079e+00\n(CVXPY) Sep 30 03:21:16 PM: Compilation took 1.109e+00 seconds\n(CVXPY) Sep 30 03:21:16 PM: Solver (including time spent in interface) took 8.299e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.88s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.88s/batch]\n",
    "execution_time": 21.95198965072632,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/b01d9cc367eded3fb7280b414ade8c9f --algorithm mixed --regression-type implicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "b01d9cc367eded3fb7280b414ade8c9f",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [24, 1]\n2025-09-30 15:21:28,373 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:21:28,373 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:21:29,391 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:21:29,407 - xlsindy.simulation - INFO - Experimental matrix norm: 1920.4430297907313\n2025-09-30 15:21:29,407 - xlsindy.simulation - INFO - Experimental matrix variance: 104.34599563983741\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.27e+00  1.00e+00  5.31e+01   ------   \n  1  +1.2387e+00  +1.2372e+00  1.21e-03  6.77e-03  4.50e-04  9.97e-03  6.11e-01  9.88e-01  \n  2  +1.1984e+00  +1.1983e+00  4.09e-05  5.63e-04  3.71e-05  8.26e-04  5.10e-02  9.17e-01  \n  3  +1.1475e+00  +1.1612e+00  1.19e-02  3.97e-04  2.62e-05  1.45e-02  3.60e-02  5.37e-01  \n  4  +1.1222e+00  +1.1242e+00  1.74e-03  1.63e-04  1.07e-05  2.14e-03  1.48e-02  6.43e-01  \n  5  +1.1071e+00  +1.1080e+00  7.72e-04  1.36e-04  8.95e-06  9.56e-04  1.23e-02  2.62e-01  \n  6  +1.0919e+00  +1.0923e+00  3.73e-04  6.11e-05  4.02e-06  4.24e-04  5.55e-03  9.90e-01  \n  7  +1.0884e+00  +1.0887e+00  2.10e-04  4.80e-05  3.15e-06  2.38e-04  4.39e-03  4.38e-01  \n  8  +1.0862e+00  +1.0863e+00  8.47e-05  3.47e-05  2.27e-06  9.60e-05  3.22e-03  4.07e-01  \n  9  +1.0859e+00  +1.0860e+00  9.73e-05  3.22e-05  2.11e-06  1.10e-04  3.01e-03  1.97e-01  \n 10  +1.0842e+00  +1.0842e+00  2.27e-05  2.01e-05  1.31e-06  2.61e-05  2.07e-03  6.06e-01  \n 11  +1.0842e+00  +1.0842e+00  3.12e-05  1.78e-05  1.16e-06  3.56e-05  1.96e-03  2.06e-01  \n 12  +1.0831e+00  +1.0831e+00  6.84e-06  7.47e-06  4.88e-07  8.03e-06  1.32e-03  5.51e-01  \n 13  +1.0828e+00  +1.0828e+00  5.46e-06  3.52e-06  2.31e-07  6.40e-06  9.96e-04  5.12e-01  \n 14  +1.0823e+00  +1.0823e+00  1.73e-06  1.67e-06  1.10e-07  2.08e-06  6.43e-04  5.88e-01  \n 15  +1.0822e+00  +1.0822e+00  1.28e-06  1.20e-06  7.91e-08  1.57e-06  4.45e-04  6.47e-01  \n 16  +1.0820e+00  +1.0820e+00  4.53e-07  3.96e-07  2.61e-08  5.66e-07  1.75e-04  7.64e-01  \n 17  +1.0817e+00  +1.0817e+00  5.23e-08  1.17e-07  7.73e-09  8.30e-08  5.22e-05  9.90e-01  \n 18  +1.0815e+00  +1.0815e+00  4.46e-09  2.73e-08  1.82e-09  1.20e-08  1.24e-05  9.90e-01  \n 19  +1.0813e+00  +1.0813e+00  6.89e-10  3.82e-09  2.81e-10  1.80e-09  1.90e-06  9.30e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.265908593s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:21:37,342 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00  4.74943037e-18  4.74943037e-18 ...  4.74943037e-18\n   4.74943037e-18  4.74943037e-18]\n [ 4.74943037e-18 -1.00000000e+00  4.74943037e-18 ...  4.74943037e-18\n   4.74943037e-18  4.74943037e-18]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ... -1.47448092e-01\n   1.95645163e-01 -6.03547583e-02]\n ...\n [ 0.00000000e+00  0.00000000e+00 -1.41272609e-01 ... -1.00000000e+00\n   1.85533414e-01 -5.35713426e-01]\n [ 0.00000000e+00  0.00000000e+00  1.20471129e-01 ...  1.18061577e-01\n  -1.00000000e+00 -5.68801988e-02]\n [ 0.00000000e+00  0.00000000e+00 -2.59409529e-02 ... -2.59053667e-01\n  -4.26188695e-02 -1.00000000e+00]]\n2025-09-30 15:21:37,372 - xlsindy.simulation - INFO - Group 23, weight 0.87: [np.int64(29), np.int64(34), np.int64(50), np.int64(91)]\n2025-09-30 15:21:37,372 - xlsindy.simulation - INFO - Group 29, weight 0.68: [np.int64(36), np.int64(43), np.int64(54)]\n2025-09-30 15:21:37,372 - xlsindy.simulation - INFO - Group 37, weight 0.61: [np.int64(47), np.int64(57), np.int64(61), np.int64(78), np.int64(93)]\n2025-09-30 15:21:37,441 - __main__ - INFO - Regression completed in 9.07 seconds\nestimate variance between mujoco and model is :  22.528906\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:21:29 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:21:29 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:21:29 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:21:29 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:21:29 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:21:29 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:21:29 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:21:29 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:21:29 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:21:29 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:21:30 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:21:30 PM: Finished problem compilation (took 1.117e+00 seconds).\n(CVXPY) Sep 30 03:21:30 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:21:37 PM: Problem status: optimal\n(CVXPY) Sep 30 03:21:37 PM: Optimal value: 1.081e+00\n(CVXPY) Sep 30 03:21:37 PM: Compilation took 1.117e+00 seconds\n(CVXPY) Sep 30 03:21:37 PM: Solver (including time spent in interface) took 6.707e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.54s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.54s/batch]\n",
    "execution_time": 19.796982765197754,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/b01d9cc367eded3fb7280b414ade8c9f --algorithm mixed --regression-type implicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "b01d9cc367eded3fb7280b414ade8c9f",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [24, 1]\n2025-09-30 15:21:48,667 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:21:48,667 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:21:49,739 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:21:49,755 - xlsindy.simulation - INFO - Experimental matrix norm: 1919.7512210901423\n2025-09-30 15:21:49,755 - xlsindy.simulation - INFO - Experimental matrix variance: 104.27084340083353\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.27e+00  1.00e+00  5.33e+01   ------   \n  1  +1.2439e+00  +1.2424e+00  1.21e-03  6.77e-03  4.48e-04  9.97e-03  6.13e-01  9.88e-01  \n  2  +1.2031e+00  +1.2031e+00  3.46e-05  5.63e-04  3.70e-05  8.34e-04  5.12e-02  9.17e-01  \n  3  +1.1517e+00  +1.1656e+00  1.21e-02  3.96e-04  2.61e-05  1.48e-02  3.61e-02  5.39e-01  \n  4  +1.1261e+00  +1.1281e+00  1.77e-03  1.63e-04  1.07e-05  2.19e-03  1.48e-02  6.43e-01  \n  5  +1.1107e+00  +1.1116e+00  7.76e-04  1.36e-04  8.91e-06  9.64e-04  1.24e-02  2.61e-01  \n  6  +1.0954e+00  +1.0958e+00  3.70e-04  6.11e-05  4.01e-06  4.21e-04  5.58e-03  9.90e-01  \n  7  +1.0924e+00  +1.0927e+00  2.43e-04  5.26e-05  3.44e-06  2.76e-04  4.82e-03  3.36e-01  \n  8  +1.0894e+00  +1.0895e+00  5.53e-05  3.18e-05  2.07e-06  6.31e-05  3.01e-03  5.72e-01  \n  9  +1.0893e+00  +1.0894e+00  6.67e-05  3.07e-05  2.00e-06  7.59e-05  2.95e-03  8.66e-02  \n 10  +1.0876e+00  +1.0876e+00  1.16e-05  1.57e-05  1.02e-06  1.34e-05  1.91e-03  7.08e-01  \n 11  +1.0876e+00  +1.0876e+00  1.45e-05  1.44e-05  9.36e-07  1.67e-05  1.87e-03  1.07e-01  \n 12  +1.0868e+00  +1.0868e+00  1.22e-06  4.24e-06  2.73e-07  1.50e-06  1.11e-03  7.12e-01  \n 13  +1.0866e+00  +1.0866e+00  2.78e-07  7.77e-07  5.01e-08  3.35e-07  4.48e-04  8.23e-01  \n 14  +1.0865e+00  +1.0865e+00  5.16e-08  1.61e-07  1.04e-08  6.28e-08  1.16e-04  8.04e-01  \n 15  +1.0865e+00  +1.0865e+00  1.20e-08  4.15e-08  2.68e-09  1.48e-08  3.16e-05  7.59e-01  \n 16  +1.0865e+00  +1.0865e+00  2.24e-09  8.41e-09  5.43e-10  2.79e-09  6.49e-06  8.10e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.150881869s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:21:57,553 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -1.55126127e-20 -1.55126127e-20 ... -1.55126127e-20\n  -1.55126127e-20 -1.55126127e-20]\n [-1.55126127e-20 -1.00000000e+00 -1.55126127e-20 ... -1.55126127e-20\n  -1.55126127e-20 -1.55126127e-20]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ... -1.49787281e-01\n   1.83188368e-01 -6.92715167e-02]\n ...\n [ 0.00000000e+00  0.00000000e+00 -1.45347360e-01 ... -1.00000000e+00\n   1.76169679e-01 -5.49048367e-01]\n [ 0.00000000e+00  0.00000000e+00  1.09907999e-01 ...  1.08492416e-01\n  -1.00000000e+00 -5.42197250e-02]\n [ 0.00000000e+00  0.00000000e+00 -3.20520044e-02 ... -2.64336014e-01\n  -4.20319503e-02 -1.00000000e+00]]\n2025-09-30 15:21:57,617 - __main__ - INFO - Regression completed in 8.95 seconds\n",
    "stderr": "(CVXPY) Sep 30 03:21:49 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:21:49 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:21:49 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:21:49 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:21:49 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:21:49 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:21:49 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:21:49 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:21:49 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:21:49 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:21:50 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:21:50 PM: Finished problem compilation (took 1.133e+00 seconds).\n(CVXPY) Sep 30 03:21:50 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:21:57 PM: Problem status: optimal\n(CVXPY) Sep 30 03:21:57 PM: Optimal value: 1.087e+00\n(CVXPY) Sep 30 03:21:57 PM: Compilation took 1.133e+00 seconds\n(CVXPY) Sep 30 03:21:57 PM: Solver (including time spent in interface) took 6.545e+00 seconds\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 243, in <module>\n    xlsindy.dynamics_modeling.generate_acceleration_function(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/dynamics_modeling.py\", line 67, in generate_acceleration_function\n    if str(symbol_matrix[3, i]) not in str(dynamic_equations[i]):\nIndexError: index 0 is out of bounds for axis 0 with size 0\n",
    "execution_time": 13.077747821807861,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/b01d9cc367eded3fb7280b414ade8c9f --algorithm mixed --regression-type implicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "b01d9cc367eded3fb7280b414ade8c9f",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [24, 1]\n2025-09-30 15:22:01,320 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:22:01,320 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:22:02,411 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:22:02,431 - xlsindy.simulation - INFO - Experimental matrix norm: 1920.52789426853\n2025-09-30 15:22:02,431 - xlsindy.simulation - INFO - Experimental matrix variance: 104.35521697036617\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.27e+00  1.00e+00  5.31e+01   ------   \n  1  +1.2383e+00  +1.2368e+00  1.22e-03  6.77e-03  4.50e-04  9.97e-03  6.11e-01  9.88e-01  \n  2  +1.1979e+00  +1.1979e+00  4.10e-05  5.63e-04  3.72e-05  8.26e-04  5.10e-02  9.17e-01  \n  3  +1.1471e+00  +1.1608e+00  1.19e-02  3.98e-04  2.62e-05  1.45e-02  3.60e-02  5.36e-01  \n  4  +1.1219e+00  +1.1239e+00  1.74e-03  1.64e-04  1.08e-05  2.14e-03  1.48e-02  6.42e-01  \n  5  +1.1069e+00  +1.1077e+00  7.61e-04  1.37e-04  9.04e-06  9.43e-04  1.24e-02  2.58e-01  \n  6  +1.0917e+00  +1.0921e+00  3.57e-04  6.22e-05  4.09e-06  4.06e-04  5.65e-03  9.90e-01  \n  7  +1.0887e+00  +1.0889e+00  2.04e-04  5.45e-05  3.58e-06  2.32e-04  4.98e-03  3.20e-01  \n  8  +1.0861e+00  +1.0861e+00  4.36e-05  3.19e-05  2.08e-06  4.98e-05  3.01e-03  5.61e-01  \n  9  +1.0861e+00  +1.0862e+00  6.96e-05  3.03e-05  1.98e-06  7.89e-05  2.98e-03  9.96e-02  \n 10  +1.0854e+00  +1.0855e+00  6.73e-05  2.19e-05  1.44e-06  7.58e-05  2.42e-03  2.74e-01  \n 11  +1.0851e+00  +1.0852e+00  4.75e-05  2.13e-05  1.40e-06  5.39e-05  2.38e-03  1.03e-01  \n 12  +1.0850e+00  +1.0850e+00  6.89e-05  1.62e-05  1.06e-06  7.75e-05  2.00e-03  3.79e-01  \n 13  +1.0838e+00  +1.0838e+00  1.56e-05  1.07e-05  7.01e-07  1.83e-05  1.57e-03  5.81e-01  \n 14  +1.0837e+00  +1.0837e+00  2.04e-05  7.11e-06  4.68e-07  2.37e-05  1.15e-03  5.61e-01  \n 15  +1.0820e+00  +1.0820e+00  1.90e-06  2.53e-06  1.66e-07  2.53e-06  6.52e-04  7.49e-01  \n 16  +1.0817e+00  +1.0817e+00  2.15e-06  1.92e-06  1.27e-07  2.82e-06  4.92e-04  4.85e-01  \n 17  +1.0805e+00  +1.0805e+00  8.89e-07  7.48e-07  4.92e-08  1.14e-06  3.57e-04  4.96e-01  \n 18  +1.0804e+00  +1.0804e+00  6.25e-07  5.47e-07  3.60e-08  8.13e-07  2.54e-04  5.76e-01  \n 19  +1.0800e+00  +1.0800e+00  2.53e-07  2.18e-07  1.44e-08  3.31e-07  1.10e-04  7.08e-01  \n 20  +1.0798e+00  +1.0798e+00  4.37e-08  7.26e-08  4.83e-09  6.77e-08  3.37e-05  9.71e-01  \n 21  +1.0796e+00  +1.0796e+00  1.20e-08  3.69e-08  2.50e-09  2.42e-08  1.51e-05  7.91e-01  \n 22  +1.0795e+00  +1.0795e+00  6.53e-09  1.88e-08  1.37e-09  1.31e-08  6.59e-06  6.24e-01  \n 23  +1.0795e+00  +1.0795e+00  5.64e-09  1.85e-08  1.35e-09  1.21e-08  6.39e-06  1.53e-01  \n 24  +1.0794e+00  +1.0794e+00  2.92e-09  9.80e-09  8.63e-10  6.51e-09  3.21e-06  5.46e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 8.246018266s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:22:12,353 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -1.23508053e-17 -1.23508053e-17 ... -1.23508053e-17\n  -1.23508053e-17 -1.23508053e-17]\n [-1.23508053e-17 -1.00000000e+00 -1.23508053e-17 ... -1.23508053e-17\n  -1.23508053e-17 -1.23508053e-17]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ... -1.49036691e-01\n   1.98124912e-01 -5.62458429e-02]\n ...\n [ 0.00000000e+00  0.00000000e+00 -1.43549041e-01 ... -1.00000000e+00\n   1.98405841e-01 -5.29648590e-01]\n [ 0.00000000e+00  0.00000000e+00  1.29370336e-01 ...  1.34535041e-01\n  -1.00000000e+00 -5.69879939e-02]\n [ 0.00000000e+00  0.00000000e+00 -2.57932596e-02 ... -2.52827833e-01\n  -4.23419877e-02 -1.00000000e+00]]\n2025-09-30 15:22:12,375 - xlsindy.simulation - INFO - Group 2, weight 0.65: [np.int64(2), np.int64(4), np.int64(12), np.int64(15), np.int64(20), np.int64(43), np.int64(45), np.int64(59), np.int64(62), np.int64(69), np.int64(91), np.int64(92)]\n2025-09-30 15:22:12,375 - xlsindy.simulation - INFO - Group 13, weight 0.36: [np.int64(17), np.int64(60), np.int64(61), np.int64(64)]\n2025-09-30 15:22:12,375 - xlsindy.simulation - INFO - Group 19, weight 0.39: [np.int64(29), np.int64(33), np.int64(78), np.int64(93)]\n2025-09-30 15:22:12,375 - xlsindy.simulation - INFO - Group 22, weight 0.64: [np.int64(32), np.int64(41), np.int64(54)]\n2025-09-30 15:22:12,451 - __main__ - INFO - Regression completed in 11.13 seconds\nestimate variance between mujoco and model is :  5.975529\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% 2025-09-30 15:22:18,512 - xlsindy.dynamics_modeling - ERROR - RuntimeError in RK45 integration\n",
    "stderr": "(CVXPY) Sep 30 03:22:02 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:22:02 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:22:02 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:22:02 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:22:02 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:22:02 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:22:02 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:22:02 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:22:02 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:22:02 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:22:03 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:22:03 PM: Finished problem compilation (took 1.173e+00 seconds).\n(CVXPY) Sep 30 03:22:03 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:22:12 PM: Problem status: optimal\n(CVXPY) Sep 30 03:22:12 PM: Optimal value: 1.079e+00\n(CVXPY) Sep 30 03:22:12 PM: Compilation took 1.173e+00 seconds\n(CVXPY) Sep 30 03:22:12 PM: Solver (including time spent in interface) took 8.630e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n                                                            \n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  9.13batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  9.12batch/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 332, in <module>\n    **json_format_time_series(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/util.py\", line 333, in json_format_time_series\n    raise ValueError(\"Not enough data points to sample from.\")\nValueError: Not enough data points to sample from.\n",
    "execution_time": 20.854618310928345,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/b01d9cc367eded3fb7280b414ade8c9f --algorithm mixed --regression-type implicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "b01d9cc367eded3fb7280b414ade8c9f",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [24, 1]\n2025-09-30 15:22:22,962 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:22:22,963 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:22:22,963 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:22:24,023 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:22:24,024 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:22:24,024 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:22:24,024 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:22:24,024 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:22:24,024 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.27e+00  1.00e+00  5.31e+01   ------   \n  1  +1.2382e+00  +1.2367e+00  1.22e-03  6.77e-03  4.50e-04  9.97e-03  6.11e-01  9.88e-01  \n  2  +1.1979e+00  +1.1978e+00  4.10e-05  5.63e-04  3.72e-05  8.26e-04  5.10e-02  9.17e-01  \n  3  +1.1471e+00  +1.1608e+00  1.19e-02  3.98e-04  2.62e-05  1.45e-02  3.60e-02  5.36e-01  \n  4  +1.1219e+00  +1.1238e+00  1.74e-03  1.64e-04  1.08e-05  2.14e-03  1.48e-02  6.42e-01  \n  5  +1.1068e+00  +1.1076e+00  7.61e-04  1.37e-04  9.04e-06  9.43e-04  1.24e-02  2.58e-01  \n  6  +1.0917e+00  +1.0921e+00  3.57e-04  6.22e-05  4.09e-06  4.06e-04  5.65e-03  9.90e-01  \n  7  +1.0887e+00  +1.0889e+00  2.05e-04  5.46e-05  3.59e-06  2.33e-04  4.99e-03  3.18e-01  \n  8  +1.0863e+00  +1.0864e+00  6.23e-05  3.69e-05  2.42e-06  7.10e-05  3.46e-03  4.37e-01  \n  9  +1.0863e+00  +1.0864e+00  9.33e-05  3.50e-05  2.30e-06  1.05e-04  3.41e-03  8.65e-02  \n 10  +1.0855e+00  +1.0856e+00  8.61e-05  2.46e-05  1.61e-06  9.68e-05  2.81e-03  2.64e-01  \n 11  +1.0849e+00  +1.0850e+00  4.98e-05  2.22e-05  1.45e-06  5.64e-05  2.65e-03  2.64e-01  \n 12  +1.0845e+00  +1.0846e+00  6.78e-05  1.37e-05  9.02e-07  7.62e-05  2.03e-03  4.51e-01  \n 13  +1.0835e+00  +1.0835e+00  1.61e-05  8.97e-06  5.89e-07  1.88e-05  1.51e-03  5.82e-01  \n 14  +1.0834e+00  +1.0834e+00  2.14e-05  6.46e-06  4.25e-07  2.49e-05  1.12e-03  5.89e-01  \n 15  +1.0818e+00  +1.0818e+00  2.26e-06  2.18e-06  1.43e-07  2.91e-06  5.62e-04  7.69e-01  \n 16  +1.0816e+00  +1.0816e+00  2.99e-06  1.90e-06  1.25e-07  3.79e-06  4.69e-04  3.71e-01  \n 17  +1.0805e+00  +1.0805e+00  1.37e-06  8.43e-07  5.55e-08  1.71e-06  3.11e-04  6.14e-01  \n 18  +1.0800e+00  +1.0800e+00  6.25e-07  5.10e-07  3.36e-08  8.18e-07  1.83e-04  9.90e-01  \n 19  +1.0795e+00  +1.0795e+00  2.20e-07  1.91e-07  1.26e-08  2.94e-07  7.55e-05  7.71e-01  \n 20  +1.0791e+00  +1.0791e+00  4.08e-08  5.43e-08  3.62e-09  6.11e-08  2.11e-05  9.90e-01  \n 21  +1.0788e+00  +1.0788e+00  9.65e-09  1.32e-08  1.00e-09  1.49e-08  5.01e-06  8.63e-01  \n 22  +1.0788e+00  +1.0788e+00  1.72e-09  7.99e-09  7.27e-10  4.59e-09  3.14e-06  8.16e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 7.677522748s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:22:33,262 - xlsindy.simulation - INFO - Group 2, weight 0.38: [np.int64(2), np.int64(4), np.int64(12), np.int64(15), np.int64(20), np.int64(36), np.int64(40), np.int64(41), np.int64(43), np.int64(45), np.int64(46), np.int64(48), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(64), np.int64(67), np.int64(69), np.int64(75), np.int64(91), np.int64(92)]\n2025-09-30 15:22:33,263 - xlsindy.simulation - INFO - Group 22, weight 0.58: [np.int64(32), np.int64(44), np.int64(54)]\n2025-09-30 15:22:33,303 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:22:33,323 - __main__ - INFO - Regression completed in 10.36 seconds\nestimate variance between mujoco and model is :  0.85505086\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:22:24 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:22:24 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:22:24 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:22:24 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:22:24 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:22:24 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:22:24 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:22:24 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:22:24 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:22:24 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:22:24 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:22:25 PM: Finished problem compilation (took 1.126e+00 seconds).\n(CVXPY) Sep 30 03:22:25 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:22:33 PM: Problem status: optimal\n(CVXPY) Sep 30 03:22:33 PM: Optimal value: 1.079e+00\n(CVXPY) Sep 30 03:22:33 PM: Compilation took 1.126e+00 seconds\n(CVXPY) Sep 30 03:22:33 PM: Solver (including time spent in interface) took 8.065e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.20s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.20s/batch]\n",
    "execution_time": 23.136089324951172,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/b01d9cc367eded3fb7280b414ade8c9f --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "b01d9cc367eded3fb7280b414ade8c9f",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [24, 1]\n2025-09-30 15:22:45,501 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:22:45,501 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:22:45,501 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:22:46,539 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:22:46,540 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:22:46,540 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:22:46,540 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:22:46,540 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:22:46,540 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.27e+00  1.00e+00  5.31e+01   ------   \n  1  +1.2387e+00  +1.2372e+00  1.21e-03  6.77e-03  4.50e-04  9.97e-03  6.11e-01  9.88e-01  \n  2  +1.1984e+00  +1.1983e+00  4.09e-05  5.63e-04  3.71e-05  8.26e-04  5.10e-02  9.17e-01  \n  3  +1.1475e+00  +1.1612e+00  1.19e-02  3.97e-04  2.62e-05  1.45e-02  3.60e-02  5.37e-01  \n  4  +1.1222e+00  +1.1242e+00  1.74e-03  1.63e-04  1.07e-05  2.14e-03  1.48e-02  6.43e-01  \n  5  +1.1071e+00  +1.1080e+00  7.72e-04  1.36e-04  8.95e-06  9.56e-04  1.23e-02  2.62e-01  \n  6  +1.0919e+00  +1.0923e+00  3.73e-04  6.11e-05  4.02e-06  4.24e-04  5.55e-03  9.90e-01  \n  7  +1.0884e+00  +1.0887e+00  2.10e-04  4.80e-05  3.15e-06  2.38e-04  4.39e-03  4.38e-01  \n  8  +1.0862e+00  +1.0863e+00  8.47e-05  3.47e-05  2.27e-06  9.60e-05  3.22e-03  4.07e-01  \n  9  +1.0859e+00  +1.0860e+00  9.73e-05  3.22e-05  2.11e-06  1.10e-04  3.01e-03  1.97e-01  \n 10  +1.0842e+00  +1.0842e+00  2.27e-05  2.01e-05  1.31e-06  2.61e-05  2.07e-03  6.06e-01  \n 11  +1.0842e+00  +1.0842e+00  3.12e-05  1.78e-05  1.16e-06  3.56e-05  1.96e-03  2.06e-01  \n 12  +1.0831e+00  +1.0831e+00  6.84e-06  7.47e-06  4.88e-07  8.03e-06  1.32e-03  5.51e-01  \n 13  +1.0828e+00  +1.0828e+00  5.46e-06  3.52e-06  2.31e-07  6.40e-06  9.96e-04  5.12e-01  \n 14  +1.0823e+00  +1.0823e+00  1.73e-06  1.67e-06  1.10e-07  2.08e-06  6.43e-04  5.88e-01  \n 15  +1.0822e+00  +1.0822e+00  1.28e-06  1.20e-06  7.91e-08  1.57e-06  4.45e-04  6.47e-01  \n 16  +1.0820e+00  +1.0820e+00  4.53e-07  3.96e-07  2.61e-08  5.66e-07  1.75e-04  7.64e-01  \n 17  +1.0817e+00  +1.0817e+00  5.23e-08  1.17e-07  7.73e-09  8.30e-08  5.22e-05  9.90e-01  \n 18  +1.0815e+00  +1.0815e+00  4.46e-09  2.73e-08  1.82e-09  1.20e-08  1.24e-05  9.90e-01  \n 19  +1.0813e+00  +1.0813e+00  6.89e-10  3.82e-09  2.81e-10  1.80e-09  1.90e-06  9.30e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.580204673s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:22:54,717 - xlsindy.simulation - INFO - Group 4, weight 0.26: [np.int64(4), np.int64(17), np.int64(45)]\n2025-09-30 15:22:54,717 - xlsindy.simulation - INFO - Group 12, weight 0.78: [np.int64(12), np.int64(34), np.int64(41), np.int64(47), np.int64(48), np.int64(50), np.int64(57), np.int64(61), np.int64(62), np.int64(78), np.int64(93)]\n2025-09-30 15:22:54,717 - xlsindy.simulation - INFO - Group 22, weight 0.56: [np.int64(29), np.int64(36), np.int64(43), np.int64(54), np.int64(67), np.int64(91)]\n2025-09-30 15:22:54,779 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:22:54,799 - __main__ - INFO - Regression completed in 9.30 seconds\nestimate variance between mujoco and model is :  16.472717\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:22:46 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:22:46 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:22:46 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:22:46 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:22:46 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:22:46 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:22:46 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:22:46 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:22:46 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:22:46 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:22:47 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:22:47 PM: Finished problem compilation (took 1.139e+00 seconds).\n(CVXPY) Sep 30 03:22:47 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:22:54 PM: Problem status: optimal\n(CVXPY) Sep 30 03:22:54 PM: Optimal value: 1.081e+00\n(CVXPY) Sep 30 03:22:54 PM: Compilation took 1.139e+00 seconds\n(CVXPY) Sep 30 03:22:54 PM: Solver (including time spent in interface) took 6.984e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.74s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.74s/batch]\n",
    "execution_time": 20.947810173034668,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/b01d9cc367eded3fb7280b414ade8c9f --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "b01d9cc367eded3fb7280b414ade8c9f",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [24, 1]\n2025-09-30 15:23:06,121 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:23:06,122 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:23:06,122 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:23:07,157 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:23:07,158 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:23:07,158 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:23:07,158 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:23:07,158 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:23:07,158 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.27e+00  1.00e+00  5.33e+01   ------   \n  1  +1.2439e+00  +1.2424e+00  1.21e-03  6.77e-03  4.48e-04  9.97e-03  6.13e-01  9.88e-01  \n  2  +1.2031e+00  +1.2031e+00  3.46e-05  5.63e-04  3.70e-05  8.34e-04  5.12e-02  9.17e-01  \n  3  +1.1517e+00  +1.1656e+00  1.21e-02  3.96e-04  2.61e-05  1.48e-02  3.61e-02  5.39e-01  \n  4  +1.1261e+00  +1.1281e+00  1.77e-03  1.63e-04  1.07e-05  2.19e-03  1.48e-02  6.43e-01  \n  5  +1.1107e+00  +1.1116e+00  7.76e-04  1.36e-04  8.91e-06  9.64e-04  1.24e-02  2.61e-01  \n  6  +1.0954e+00  +1.0958e+00  3.70e-04  6.11e-05  4.01e-06  4.21e-04  5.58e-03  9.90e-01  \n  7  +1.0924e+00  +1.0927e+00  2.43e-04  5.26e-05  3.44e-06  2.76e-04  4.82e-03  3.36e-01  \n  8  +1.0894e+00  +1.0895e+00  5.53e-05  3.18e-05  2.07e-06  6.31e-05  3.01e-03  5.72e-01  \n  9  +1.0893e+00  +1.0894e+00  6.67e-05  3.07e-05  2.00e-06  7.59e-05  2.95e-03  8.66e-02  \n 10  +1.0876e+00  +1.0876e+00  1.16e-05  1.57e-05  1.02e-06  1.34e-05  1.91e-03  7.08e-01  \n 11  +1.0876e+00  +1.0876e+00  1.45e-05  1.44e-05  9.36e-07  1.67e-05  1.87e-03  1.07e-01  \n 12  +1.0868e+00  +1.0868e+00  1.22e-06  4.24e-06  2.73e-07  1.50e-06  1.11e-03  7.12e-01  \n 13  +1.0866e+00  +1.0866e+00  2.78e-07  7.77e-07  5.01e-08  3.35e-07  4.48e-04  8.23e-01  \n 14  +1.0865e+00  +1.0865e+00  5.16e-08  1.61e-07  1.04e-08  6.28e-08  1.16e-04  8.04e-01  \n 15  +1.0865e+00  +1.0865e+00  1.20e-08  4.15e-08  2.68e-09  1.48e-08  3.16e-05  7.59e-01  \n 16  +1.0865e+00  +1.0865e+00  2.24e-09  8.41e-09  5.43e-10  2.79e-09  6.49e-06  8.10e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 5.902202482s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:23:14,644 - xlsindy.simulation - INFO - Group 28, weight 0.57: [np.int64(34), np.int64(91), np.int64(93)]\n2025-09-30 15:23:14,679 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:23:14,698 - __main__ - INFO - Regression completed in 8.58 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:23:07 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:23:07 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:23:07 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:23:07 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:23:07 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:23:07 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:23:07 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:23:07 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:23:07 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:23:07 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:23:07 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:23:08 PM: Finished problem compilation (took 1.129e+00 seconds).\n(CVXPY) Sep 30 03:23:08 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:23:14 PM: Problem status: optimal\n(CVXPY) Sep 30 03:23:14 PM: Optimal value: 1.087e+00\n(CVXPY) Sep 30 03:23:14 PM: Compilation took 1.129e+00 seconds\n(CVXPY) Sep 30 03:23:14 PM: Solver (including time spent in interface) took 6.295e+00 seconds\n",
    "execution_time": 12.245965242385864,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/b01d9cc367eded3fb7280b414ade8c9f --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "b01d9cc367eded3fb7280b414ade8c9f",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [24, 1]\n2025-09-30 15:23:18,686 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:23:18,686 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:23:18,686 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:23:19,716 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:23:19,716 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:23:19,716 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:23:19,716 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:23:19,717 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:23:19,717 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.98e-01  1.27e+00  1.00e+00  5.31e+01   ------   \n  1  +1.2383e+00  +1.2368e+00  1.22e-03  6.77e-03  4.50e-04  9.97e-03  6.11e-01  9.88e-01  \n  2  +1.1979e+00  +1.1979e+00  4.10e-05  5.63e-04  3.72e-05  8.26e-04  5.10e-02  9.17e-01  \n  3  +1.1471e+00  +1.1608e+00  1.19e-02  3.98e-04  2.62e-05  1.45e-02  3.60e-02  5.36e-01  \n  4  +1.1219e+00  +1.1239e+00  1.74e-03  1.64e-04  1.08e-05  2.14e-03  1.48e-02  6.42e-01  \n  5  +1.1069e+00  +1.1077e+00  7.61e-04  1.37e-04  9.04e-06  9.43e-04  1.24e-02  2.58e-01  \n  6  +1.0917e+00  +1.0921e+00  3.57e-04  6.22e-05  4.09e-06  4.06e-04  5.65e-03  9.90e-01  \n  7  +1.0887e+00  +1.0889e+00  2.04e-04  5.45e-05  3.58e-06  2.32e-04  4.98e-03  3.20e-01  \n  8  +1.0861e+00  +1.0861e+00  4.36e-05  3.19e-05  2.08e-06  4.98e-05  3.01e-03  5.61e-01  \n  9  +1.0861e+00  +1.0862e+00  6.96e-05  3.03e-05  1.98e-06  7.89e-05  2.98e-03  9.96e-02  \n 10  +1.0854e+00  +1.0855e+00  6.73e-05  2.19e-05  1.44e-06  7.58e-05  2.42e-03  2.74e-01  \n 11  +1.0851e+00  +1.0852e+00  4.75e-05  2.13e-05  1.40e-06  5.39e-05  2.38e-03  1.03e-01  \n 12  +1.0850e+00  +1.0850e+00  6.89e-05  1.62e-05  1.06e-06  7.75e-05  2.00e-03  3.79e-01  \n 13  +1.0838e+00  +1.0838e+00  1.56e-05  1.07e-05  7.01e-07  1.83e-05  1.57e-03  5.81e-01  \n 14  +1.0837e+00  +1.0837e+00  2.04e-05  7.11e-06  4.68e-07  2.37e-05  1.15e-03  5.61e-01  \n 15  +1.0820e+00  +1.0820e+00  1.90e-06  2.53e-06  1.66e-07  2.53e-06  6.52e-04  7.49e-01  \n 16  +1.0817e+00  +1.0817e+00  2.15e-06  1.92e-06  1.27e-07  2.82e-06  4.92e-04  4.85e-01  \n 17  +1.0805e+00  +1.0805e+00  8.89e-07  7.48e-07  4.92e-08  1.14e-06  3.57e-04  4.96e-01  \n 18  +1.0804e+00  +1.0804e+00  6.25e-07  5.47e-07  3.60e-08  8.13e-07  2.54e-04  5.76e-01  \n 19  +1.0800e+00  +1.0800e+00  2.53e-07  2.18e-07  1.44e-08  3.31e-07  1.10e-04  7.08e-01  \n 20  +1.0798e+00  +1.0798e+00  4.37e-08  7.26e-08  4.83e-09  6.77e-08  3.37e-05  9.71e-01  \n 21  +1.0796e+00  +1.0796e+00  1.20e-08  3.69e-08  2.50e-09  2.42e-08  1.51e-05  7.91e-01  \n 22  +1.0795e+00  +1.0795e+00  6.53e-09  1.88e-08  1.37e-09  1.31e-08  6.59e-06  6.24e-01  \n 23  +1.0795e+00  +1.0795e+00  5.64e-09  1.85e-08  1.35e-09  1.21e-08  6.39e-06  1.53e-01  \n 24  +1.0794e+00  +1.0794e+00  2.92e-09  9.80e-09  8.63e-10  6.51e-09  3.21e-06  5.46e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 8.5589059s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:23:29,845 - xlsindy.simulation - INFO - Group 2, weight 0.57: [np.int64(2), np.int64(4), np.int64(12), np.int64(15), np.int64(17), np.int64(20), np.int64(31), np.int64(32), np.int64(36), np.int64(40), np.int64(41), np.int64(43), np.int64(45), np.int64(46), np.int64(54), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(64), np.int64(68), np.int64(69), np.int64(75), np.int64(91), np.int64(92)]\n2025-09-30 15:23:29,845 - xlsindy.simulation - INFO - Group 18, weight 0.77: [np.int64(29), np.int64(33), np.int64(34), np.int64(78), np.int64(93)]\n2025-09-30 15:23:29,903 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:23:29,921 - __main__ - INFO - Regression completed in 11.24 seconds\nestimate variance between mujoco and model is :  0.40236288\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:23:19 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:23:19 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:23:19 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:23:19 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:23:19 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:23:19 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:23:19 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:23:19 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:23:19 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:23:19 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:23:20 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:23:20 PM: Finished problem compilation (took 1.142e+00 seconds).\n(CVXPY) Sep 30 03:23:20 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:23:29 PM: Problem status: optimal\n(CVXPY) Sep 30 03:23:29 PM: Optimal value: 1.079e+00\n(CVXPY) Sep 30 03:23:29 PM: Compilation took 1.142e+00 seconds\n(CVXPY) Sep 30 03:23:29 PM: Solver (including time spent in interface) took 8.935e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.71s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.71s/batch]\n",
    "execution_time": 22.485376834869385,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/b01d9cc367eded3fb7280b414ade8c9f --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "b01d9cc367eded3fb7280b414ade8c9f",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [39, 1]\n2025-09-30 15:23:41,298 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:23:41,298 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.8581719398498535,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2dea39cb0790bb55dc957127a693a112 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2dea39cb0790bb55dc957127a693a112",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [39, 1]\n2025-09-30 15:23:47,353 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:23:47,353 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.2107274532318115,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2dea39cb0790bb55dc957127a693a112 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2dea39cb0790bb55dc957127a693a112",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [39, 1]\n2025-09-30 15:23:53,403 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:23:53,403 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.862584114074707,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2dea39cb0790bb55dc957127a693a112 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2dea39cb0790bb55dc957127a693a112",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [39, 1]\n2025-09-30 15:23:59,331 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:23:59,332 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.911932706832886,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2dea39cb0790bb55dc957127a693a112 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2dea39cb0790bb55dc957127a693a112",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [39, 1]\n2025-09-30 15:24:05,145 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:05,145 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:24:05,145 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.803038597106934,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2dea39cb0790bb55dc957127a693a112 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2dea39cb0790bb55dc957127a693a112",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [39, 1]\n2025-09-30 15:24:10,937 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:10,937 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:24:10,937 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.811161518096924,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2dea39cb0790bb55dc957127a693a112 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2dea39cb0790bb55dc957127a693a112",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [39, 1]\n2025-09-30 15:24:16,693 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:16,693 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:24:16,694 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.834853887557983,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2dea39cb0790bb55dc957127a693a112 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2dea39cb0790bb55dc957127a693a112",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [39, 1]\n2025-09-30 15:24:22,514 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:22,515 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:24:22,515 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.791676044464111,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2dea39cb0790bb55dc957127a693a112 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2dea39cb0790bb55dc957127a693a112",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [40, 1]\n2025-09-30 15:24:28,314 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:28,315 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.013413667678833,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/854054c488b5c1d13fec2c6271ac10e7 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "854054c488b5c1d13fec2c6271ac10e7",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [40, 1]\n2025-09-30 15:24:34,413 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:34,414 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.927391052246094,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/854054c488b5c1d13fec2c6271ac10e7 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "854054c488b5c1d13fec2c6271ac10e7",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [40, 1]\n2025-09-30 15:24:40,646 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:40,647 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.453201532363892,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/854054c488b5c1d13fec2c6271ac10e7 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "854054c488b5c1d13fec2c6271ac10e7",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [40, 1]\n2025-09-30 15:24:46,776 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:46,776 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.09860897064209,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/854054c488b5c1d13fec2c6271ac10e7 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "854054c488b5c1d13fec2c6271ac10e7",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [40, 1]\n2025-09-30 15:24:52,836 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:52,837 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:24:52,837 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.919842004776001,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/854054c488b5c1d13fec2c6271ac10e7 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "854054c488b5c1d13fec2c6271ac10e7",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [40, 1]\n2025-09-30 15:24:58,822 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:24:58,822 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:24:58,822 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.926950216293335,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/854054c488b5c1d13fec2c6271ac10e7 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "854054c488b5c1d13fec2c6271ac10e7",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [40, 1]\n2025-09-30 15:25:04,759 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:25:04,760 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:25:04,760 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.904996871948242,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/854054c488b5c1d13fec2c6271ac10e7 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "854054c488b5c1d13fec2c6271ac10e7",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [40, 1]\n2025-09-30 15:25:10,967 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:25:10,968 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:25:10,968 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.542407989501953,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/854054c488b5c1d13fec2c6271ac10e7 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "854054c488b5c1d13fec2c6271ac10e7",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [3, 1]\n2025-09-30 15:25:16,754 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:25:16,754 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:25:18,262 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03893839381834392\n2025-09-30 15:25:18,404 - __main__ - INFO - Regression completed in 1.65 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 5.184741258621216,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/685d59014dccccdad20eb25ac5180889 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "685d59014dccccdad20eb25ac5180889",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [3, 1]\n2025-09-30 15:25:22,101 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:25:22,101 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:25:23,710 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03907975446418613\n2025-09-30 15:25:23,851 - __main__ - INFO - Regression completed in 1.75 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.482e-02, tolerance: 5.011e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 5.467684984207153,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/685d59014dccccdad20eb25ac5180889 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "685d59014dccccdad20eb25ac5180889",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [3, 1]\n2025-09-30 15:25:27,715 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:25:27,715 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:25:30,204 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.13740017966566598\n2025-09-30 15:25:30,252 - __main__ - INFO - Regression completed in 2.54 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
    "execution_time": 6.452353477478027,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/685d59014dccccdad20eb25ac5180889 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "685d59014dccccdad20eb25ac5180889",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [3, 1]\n2025-09-30 15:25:34,176 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:25:34,176 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:25:35,708 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03895265344321363\n2025-09-30 15:25:35,864 - __main__ - INFO - Regression completed in 1.69 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 5.534769535064697,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/685d59014dccccdad20eb25ac5180889 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "685d59014dccccdad20eb25ac5180889",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [3, 1]\n2025-09-30 15:25:39,494 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:25:39,494 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:25:39,494 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:25:40,525 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:25:40,525 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:25:40,525 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:25:40,525 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:25:40,525 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:25:40,525 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:25:40,983 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0389383938183439\n2025-09-30 15:25:41,125 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:25:41,125 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:25:41,125 - __main__ - INFO - Regression completed in 1.63 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 5.260350942611694,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/685d59014dccccdad20eb25ac5180889 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "685d59014dccccdad20eb25ac5180889",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [3, 1]\n2025-09-30 15:25:45,046 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:25:45,047 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:25:45,047 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:25:46,066 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:25:46,066 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:25:46,066 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:25:46,066 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:25:46,067 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:25:46,067 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:25:46,524 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.03907975446418613\n2025-09-30 15:25:46,657 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:25:46,657 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:25:46,657 - __main__ - INFO - Regression completed in 1.61 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.482e-02, tolerance: 5.011e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 5.57319450378418,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/685d59014dccccdad20eb25ac5180889 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "685d59014dccccdad20eb25ac5180889",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [3, 1]\n2025-09-30 15:25:50,387 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:25:50,387 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:25:50,387 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:25:51,401 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:25:51,401 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:25:51,401 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:25:51,401 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:25:51,401 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:25:51,401 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:25:52,106 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.13740017966566603\n2025-09-30 15:25:52,152 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:25:52,152 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:25:52,152 - __main__ - INFO - Regression completed in 1.77 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
    "execution_time": 5.472097635269165,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/685d59014dccccdad20eb25ac5180889 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "685d59014dccccdad20eb25ac5180889",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [3, 1]\n2025-09-30 15:25:55,839 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:25:55,840 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:25:55,840 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:25:56,878 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:25:56,878 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:25:56,878 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:25:56,878 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:25:56,878 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:25:56,878 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:25:57,348 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.038952653443213615\n2025-09-30 15:25:57,509 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:25:57,509 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:25:57,509 - __main__ - INFO - Regression completed in 1.67 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+01, tolerance: 5.039e-02\n  model = cd_fast.enet_coordinate_descent(\n",
    "execution_time": 5.377365350723267,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/685d59014dccccdad20eb25ac5180889 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "685d59014dccccdad20eb25ac5180889",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [11, 1]\n2025-09-30 15:26:01,253 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:26:01,253 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:26:03,162 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.00614700497008863\n2025-09-30 15:26:03,192 - __main__ - INFO - Regression completed in 1.94 seconds\nestimate variance between mujoco and model is :  2.8271642\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.23s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.23s/batch]\n",
    "execution_time": 13.776739120483398,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/0c1b989cbc8cdad7105d37c8c6a61058 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "0c1b989cbc8cdad7105d37c8c6a61058",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [11, 1]\n2025-09-30 15:26:14,957 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:26:14,957 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:26:16,274 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0061470910423408\n2025-09-30 15:26:16,304 - __main__ - INFO - Regression completed in 1.35 seconds\nestimate variance between mujoco and model is :  2.855411\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.15s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.15s/batch]\n",
    "execution_time": 13.120899438858032,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/0c1b989cbc8cdad7105d37c8c6a61058 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "0c1b989cbc8cdad7105d37c8c6a61058",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [11, 1]\n2025-09-30 15:26:28,225 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:26:28,226 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:26:29,754 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.006173859399007995\n2025-09-30 15:26:29,805 - __main__ - INFO - Regression completed in 1.58 seconds\nestimate variance between mujoco and model is :  3.6679387\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.17s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.17s/batch]\n",
    "execution_time": 14.308956623077393,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/0c1b989cbc8cdad7105d37c8c6a61058 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "0c1b989cbc8cdad7105d37c8c6a61058",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [11, 1]\n2025-09-30 15:26:42,388 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:26:42,388 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:26:43,987 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.006147013574673287\n2025-09-30 15:26:44,030 - __main__ - INFO - Regression completed in 1.64 seconds\nestimate variance between mujoco and model is :  2.8290777\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.07s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.07s/batch]\n",
    "execution_time": 13.647886276245117,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/0c1b989cbc8cdad7105d37c8c6a61058 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "0c1b989cbc8cdad7105d37c8c6a61058",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [11, 1]\n2025-09-30 15:26:55,991 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:26:55,991 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:26:55,991 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:26:57,053 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:26:57,053 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:26:57,053 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:26:57,053 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:26:57,053 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:26:57,053 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:26:57,295 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.006147004970088623\n2025-09-30 15:26:57,330 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:26:57,330 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:26:57,330 - __main__ - INFO - Regression completed in 1.34 seconds\nestimate variance between mujoco and model is :  2.8271642\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.12s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.12s/batch]\n",
    "execution_time": 13.159905195236206,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/0c1b989cbc8cdad7105d37c8c6a61058 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "0c1b989cbc8cdad7105d37c8c6a61058",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [11, 1]\n2025-09-30 15:27:09,292 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:27:09,292 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:27:09,292 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:27:10,316 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:27:10,316 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:27:10,316 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:27:10,316 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:27:10,316 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:27:10,316 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:27:10,546 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0061470910423407936\n2025-09-30 15:27:10,579 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:27:10,579 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:27:10,580 - __main__ - INFO - Regression completed in 1.29 seconds\nestimate variance between mujoco and model is :  2.855411\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.08s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.08s/batch]\n",
    "execution_time": 13.35828161239624,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/0c1b989cbc8cdad7105d37c8c6a61058 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "0c1b989cbc8cdad7105d37c8c6a61058",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [11, 1]\n2025-09-30 15:27:22,524 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:27:22,524 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:27:22,524 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:27:23,548 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:27:23,548 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:27:23,548 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:27:23,548 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:27:23,548 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:27:23,548 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:27:23,945 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.006173859399007995\n2025-09-30 15:27:23,994 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:27:23,994 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:27:23,994 - __main__ - INFO - Regression completed in 1.47 seconds\nestimate variance between mujoco and model is :  3.6679387\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.08s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.08s/batch]\n",
    "execution_time": 13.4887375831604,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/0c1b989cbc8cdad7105d37c8c6a61058 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "0c1b989cbc8cdad7105d37c8c6a61058",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [11, 1]\n2025-09-30 15:27:36,193 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:27:36,193 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:27:36,193 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:27:37,261 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:27:37,261 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:27:37,261 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:27:37,261 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:27:37,262 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:27:37,262 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:27:37,489 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.00614701357467329\n2025-09-30 15:27:37,519 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:27:37,519 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:27:37,519 - __main__ - INFO - Regression completed in 1.33 seconds\nestimate variance between mujoco and model is :  2.8290777\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.47s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.47s/batch]\n",
    "execution_time": 14.953237295150757,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/0c1b989cbc8cdad7105d37c8c6a61058 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "0c1b989cbc8cdad7105d37c8c6a61058",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [19, 1]\n2025-09-30 15:27:51,256 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:27:51,256 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.778249979019165,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/51bdf931f43c322ed7a51cb095271d9c --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "51bdf931f43c322ed7a51cb095271d9c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [19, 1]\n2025-09-30 15:27:57,621 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:27:57,621 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.536361217498779,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/51bdf931f43c322ed7a51cb095271d9c --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "51bdf931f43c322ed7a51cb095271d9c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [19, 1]\n2025-09-30 15:28:03,591 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:28:03,591 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.037408828735352,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/51bdf931f43c322ed7a51cb095271d9c --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "51bdf931f43c322ed7a51cb095271d9c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [19, 1]\n2025-09-30 15:28:10,530 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:28:10,532 - __main__ - INFO - Starting explicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 202, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_explicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 56, in regression_explicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.7844250202178955,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/51bdf931f43c322ed7a51cb095271d9c --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "51bdf931f43c322ed7a51cb095271d9c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [19, 1]\n2025-09-30 15:28:16,447 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:28:16,447 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:28:16,448 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.86887526512146,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/51bdf931f43c322ed7a51cb095271d9c --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "51bdf931f43c322ed7a51cb095271d9c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [19, 1]\n2025-09-30 15:28:22,268 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:28:22,268 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:28:22,268 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.799143552780151,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/51bdf931f43c322ed7a51cb095271d9c --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "51bdf931f43c322ed7a51cb095271d9c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [19, 1]\n2025-09-30 15:28:28,034 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:28:28,034 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:28:28,034 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.711320638656616,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/51bdf931f43c322ed7a51cb095271d9c --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "51bdf931f43c322ed7a51cb095271d9c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [19, 1]\n2025-09-30 15:28:34,225 - __main__ - INFO - Sampled 580 points uniformly from 3000 total samples\n2025-09-30 15:28:34,226 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:28:34,226 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.479363203048706,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/51bdf931f43c322ed7a51cb095271d9c --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "51bdf931f43c322ed7a51cb095271d9c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [37, 1]\n2025-09-30 15:28:40,037 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:28:40,037 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:28:41,279 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.12209444827853387\n2025-09-30 15:28:41,283 - __main__ - INFO - Regression completed in 1.25 seconds\nestimate variance between mujoco and model is :  7.1855373\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.16s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.16s/batch]\n",
    "execution_time": 13.30541443824768,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8ba658b55ff60dc9dc2d86c551285c3b --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8ba658b55ff60dc9dc2d86c551285c3b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [37, 1]\n2025-09-30 15:28:53,825 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:28:53,826 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:28:55,149 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.13221083442713388\n2025-09-30 15:28:55,154 - __main__ - INFO - Regression completed in 1.33 seconds\nestimate variance between mujoco and model is :  7.3714266\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.20s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.20s/batch]\n",
    "execution_time": 13.653906106948853,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8ba658b55ff60dc9dc2d86c551285c3b --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8ba658b55ff60dc9dc2d86c551285c3b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [37, 1]\n2025-09-30 15:29:07,040 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:29:07,040 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:29:08,286 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.13548793531228973\n2025-09-30 15:29:08,289 - __main__ - INFO - Regression completed in 1.25 seconds\nestimate variance between mujoco and model is :  7.6195545\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.20s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.20s/batch]\n",
    "execution_time": 13.383888721466064,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8ba658b55ff60dc9dc2d86c551285c3b --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8ba658b55ff60dc9dc2d86c551285c3b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [37, 1]\n2025-09-30 15:29:20,333 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:29:20,333 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:29:21,588 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.1318751026474636\n2025-09-30 15:29:21,592 - __main__ - INFO - Regression completed in 1.26 seconds\nestimate variance between mujoco and model is :  7.3544874\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.31s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.31s/batch]\n",
    "execution_time": 13.364593744277954,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8ba658b55ff60dc9dc2d86c551285c3b --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8ba658b55ff60dc9dc2d86c551285c3b",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [37, 1]\n2025-09-30 15:29:33,675 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:29:33,675 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:29:33,675 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:29:34,725 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:29:34,725 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:29:34,725 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:29:34,725 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:29:34,725 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:29:34,725 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:29:34,936 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.122094448278534\n2025-09-30 15:29:34,940 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:29:34,940 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:29:34,941 - __main__ - INFO - Regression completed in 1.27 seconds\nestimate variance between mujoco and model is :  7.1855373\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.24s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.24s/batch]\n",
    "execution_time": 12.833699941635132,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8ba658b55ff60dc9dc2d86c551285c3b --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8ba658b55ff60dc9dc2d86c551285c3b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [37, 1]\n2025-09-30 15:29:46,813 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:29:46,813 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:29:46,813 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:29:47,875 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:29:47,876 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:29:47,876 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:29:47,876 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:29:47,876 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:29:47,876 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:29:48,068 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.13221083442713388\n2025-09-30 15:29:48,071 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:29:48,072 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:29:48,072 - __main__ - INFO - Regression completed in 1.26 seconds\nestimate variance between mujoco and model is :  7.3714266\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.20s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.20s/batch]\n",
    "execution_time": 14.019118070602417,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8ba658b55ff60dc9dc2d86c551285c3b --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8ba658b55ff60dc9dc2d86c551285c3b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [37, 1]\n2025-09-30 15:30:00,678 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:30:00,678 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:30:00,678 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:30:01,703 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:30:01,704 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:30:01,704 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:30:01,704 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:30:01,704 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:30:01,704 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:30:01,888 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.13548793531228967\n2025-09-30 15:30:01,891 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:30:01,891 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:30:01,891 - __main__ - INFO - Regression completed in 1.21 seconds\nestimate variance between mujoco and model is :  7.6195545\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.17s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.17s/batch]\n",
    "execution_time": 14.093083620071411,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8ba658b55ff60dc9dc2d86c551285c3b --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8ba658b55ff60dc9dc2d86c551285c3b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [37, 1]\n2025-09-30 15:30:14,909 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:30:14,910 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:30:14,910 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:30:15,951 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:30:15,952 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:30:15,952 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:30:15,952 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:30:15,952 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:30:15,952 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:30:16,140 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.1318751026474636\n2025-09-30 15:30:16,144 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:30:16,144 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:30:16,144 - __main__ - INFO - Regression completed in 1.23 seconds\nestimate variance between mujoco and model is :  7.3544874\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.22s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.22s/batch]\n",
    "execution_time": 13.992774486541748,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/8ba658b55ff60dc9dc2d86c551285c3b --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "8ba658b55ff60dc9dc2d86c551285c3b",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [30, 1]\n2025-09-30 15:30:29,116 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:30:29,116 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.006085157394409,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fb6154e2bf5fd6ec71c36da41c0dd34a --algorithm mixed --regression-type implicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fb6154e2bf5fd6ec71c36da41c0dd34a",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [30, 1]\n2025-09-30 15:30:35,777 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:30:35,778 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.705492973327637,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fb6154e2bf5fd6ec71c36da41c0dd34a --algorithm mixed --regression-type implicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fb6154e2bf5fd6ec71c36da41c0dd34a",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [30, 1]\n2025-09-30 15:30:42,237 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:30:42,237 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.490223407745361,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fb6154e2bf5fd6ec71c36da41c0dd34a --algorithm mixed --regression-type implicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fb6154e2bf5fd6ec71c36da41c0dd34a",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [30, 1]\n2025-09-30 15:30:48,145 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:30:48,145 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.742154121398926,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fb6154e2bf5fd6ec71c36da41c0dd34a --algorithm mixed --regression-type implicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fb6154e2bf5fd6ec71c36da41c0dd34a",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [30, 1]\n2025-09-30 15:30:54,015 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:30:54,015 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:30:54,015 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.987271547317505,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fb6154e2bf5fd6ec71c36da41c0dd34a --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fb6154e2bf5fd6ec71c36da41c0dd34a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [30, 1]\n2025-09-30 15:31:00,375 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:31:00,376 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:31:00,376 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.663771867752075,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fb6154e2bf5fd6ec71c36da41c0dd34a --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fb6154e2bf5fd6ec71c36da41c0dd34a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [30, 1]\n2025-09-30 15:31:06,564 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:31:06,564 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:31:06,564 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.856051921844482,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fb6154e2bf5fd6ec71c36da41c0dd34a --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fb6154e2bf5fd6ec71c36da41c0dd34a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [30, 1]\n2025-09-30 15:31:12,523 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:31:12,524 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:31:12,524 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.026938199996948,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/fb6154e2bf5fd6ec71c36da41c0dd34a --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "fb6154e2bf5fd6ec71c36da41c0dd34a",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [27, 1]\n2025-09-30 15:31:18,217 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:31:18,218 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:31:19,241 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:31:19,263 - xlsindy.simulation - INFO - Experimental matrix norm: 494.0614385575431\n2025-09-30 15:31:19,263 - xlsindy.simulation - INFO - Experimental matrix variance: 6.900252981267233\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.14e+00  1.00e+00  1.62e+01   ------   \n  1  +1.3655e-01  +1.3571e-01  8.33e-04  6.37e-03  1.64e-03  9.98e-03  1.76e-01  9.89e-01  \n  2  +1.1203e-01  +1.1196e-01  7.08e-05  1.51e-04  3.87e-05  1.77e-04  4.19e-03  9.76e-01  \n  3  +7.8955e-02  +7.9733e-02  7.77e-04  4.11e-05  1.05e-05  9.28e-04  1.14e-03  8.11e-01  \n  4  +5.5152e-02  +5.5496e-02  3.44e-04  2.56e-05  6.55e-06  3.70e-04  7.10e-04  6.60e-01  \n  5  +5.3167e-02  +5.3461e-02  2.94e-04  2.17e-05  5.56e-06  3.17e-04  6.03e-04  3.23e-01  \n  6  +4.7736e-02  +4.7761e-02  2.49e-05  1.15e-05  2.94e-06  2.99e-05  3.22e-04  7.91e-01  \n  7  +4.5703e-02  +4.5715e-02  1.20e-05  7.44e-06  1.89e-06  1.41e-05  2.14e-04  5.54e-01  \n  8  +4.4600e-02  +4.4604e-02  4.00e-06  4.53e-06  1.14e-06  4.78e-06  1.44e-04  4.42e-01  \n  9  +4.4535e-02  +4.4539e-02  4.28e-06  4.30e-06  1.09e-06  5.05e-06  1.43e-04  7.28e-02  \n 10  +4.3783e-02  +4.3783e-02  5.72e-07  1.24e-06  3.10e-07  7.18e-07  6.71e-05  7.38e-01  \n 11  +4.3652e-02  +4.3653e-02  4.53e-07  8.54e-07  2.14e-07  5.49e-07  5.94e-05  3.44e-01  \n 12  +4.3550e-02  +4.3550e-02  2.29e-07  4.29e-07  1.07e-07  2.76e-07  3.96e-05  4.65e-01  \n 13  +4.3528e-02  +4.3528e-02  1.48e-07  3.23e-07  8.10e-08  1.83e-07  3.21e-05  4.56e-01  \n 14  +4.3496e-02  +4.3496e-02  5.30e-08  1.69e-07  4.23e-08  7.16e-08  1.90e-05  7.38e-01  \n 15  +4.3473e-02  +4.3473e-02  1.05e-08  6.86e-08  1.72e-08  1.81e-08  8.55e-06  8.32e-01  \n 16  +4.3464e-02  +4.3464e-02  1.39e-09  3.42e-08  8.58e-09  5.18e-09  4.36e-06  7.78e-01  \n 17  +4.3460e-02  +4.3460e-02  1.17e-09  1.67e-08  4.20e-09  6.94e-10  2.07e-06  9.90e-01  \n 18  +4.3459e-02  +4.3459e-02  1.04e-09  1.44e-08  3.63e-09  5.75e-10  1.73e-06  2.76e-01  \n 19  +4.3456e-02  +4.3456e-02  5.39e-10  6.59e-09  1.67e-09  2.08e-10  7.05e-07  9.90e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.63778073s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:31:27,621 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -2.49420801e-19 -2.49420801e-19 ... -2.49420801e-19\n  -2.49420801e-19 -2.49420801e-19]\n [-2.49420801e-19 -1.00000000e+00 -2.49420801e-19 ... -2.49420801e-19\n  -2.49420801e-19 -2.49420801e-19]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  1.15187782e-04\n   2.97041699e-03 -1.45329349e-03]\n ...\n [ 0.00000000e+00  0.00000000e+00  2.91229027e-02 ... -1.00000000e+00\n  -9.75551218e-01  1.00066555e+00]\n [ 0.00000000e+00  0.00000000e+00  3.99744104e-01 ... -9.76884318e-01\n  -1.00000000e+00  9.98108859e-01]\n [ 0.00000000e+00  0.00000000e+00 -3.06885418e-01 ...  9.89865631e-01\n   9.85747509e-01 -1.00000000e+00]]\n2025-09-30 15:31:27,653 - xlsindy.simulation - INFO - Group 39, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:31:27,776 - __main__ - INFO - Regression completed in 9.56 seconds\nestimate variance between mujoco and model is :  0.16564974\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:31:19 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:31:19 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:31:19 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:31:19 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:31:19 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:31:19 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:31:19 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:31:19 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:31:19 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:31:19 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:31:20 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:31:20 PM: Finished problem compilation (took 1.228e+00 seconds).\n(CVXPY) Sep 30 03:31:20 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:31:27 PM: Problem status: optimal\n(CVXPY) Sep 30 03:31:27 PM: Optimal value: 4.345e-02\n(CVXPY) Sep 30 03:31:27 PM: Compilation took 1.228e+00 seconds\n(CVXPY) Sep 30 03:31:27 PM: Solver (including time spent in interface) took 7.013e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.91s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.91s/batch]\n",
    "execution_time": 21.341766119003296,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b4cd683b2a3635ec5252fdb2393da68 --algorithm mixed --regression-type implicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b4cd683b2a3635ec5252fdb2393da68",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [27, 1]\n2025-09-30 15:31:39,504 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:31:39,504 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:31:40,537 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:31:40,551 - xlsindy.simulation - INFO - Experimental matrix norm: 494.06948562488157\n2025-09-30 15:31:40,551 - xlsindy.simulation - INFO - Experimental matrix variance: 6.900472253721865\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.14e+00  1.00e+00  1.62e+01   ------   \n  1  +1.3652e-01  +1.3568e-01  8.33e-04  6.37e-03  1.64e-03  9.98e-03  1.76e-01  9.89e-01  \n  2  +1.1200e-01  +1.1193e-01  7.09e-05  1.52e-04  3.88e-05  1.77e-04  4.20e-03  9.76e-01  \n  3  +7.8983e-02  +7.9766e-02  7.82e-04  4.14e-05  1.06e-05  9.33e-04  1.14e-03  8.11e-01  \n  4  +5.5240e-02  +5.5585e-02  3.45e-04  2.57e-05  6.56e-06  3.71e-04  7.11e-04  6.64e-01  \n  5  +5.3267e-02  +5.3561e-02  2.94e-04  2.18e-05  5.57e-06  3.17e-04  6.04e-04  3.21e-01  \n  6  +4.7838e-02  +4.7861e-02  2.31e-05  1.14e-05  2.90e-06  2.79e-05  3.18e-04  8.05e-01  \n  7  +4.5828e-02  +4.5839e-02  1.12e-05  7.33e-06  1.86e-06  1.32e-05  2.11e-04  5.53e-01  \n  8  +4.4774e-02  +4.4778e-02  4.05e-06  4.59e-06  1.16e-06  4.84e-06  1.46e-04  4.28e-01  \n  9  +4.4703e-02  +4.4708e-02  4.45e-06  4.33e-06  1.09e-06  5.25e-06  1.44e-04  8.83e-02  \n 10  +4.4073e-02  +4.4074e-02  1.42e-06  2.15e-06  5.40e-07  1.71e-06  9.87e-05  5.51e-01  \n 11  +4.3962e-02  +4.3963e-02  1.18e-06  1.69e-06  4.24e-07  1.41e-06  9.01e-05  1.95e-01  \n 12  +4.3804e-02  +4.3805e-02  6.83e-07  1.01e-06  2.54e-07  8.24e-07  7.08e-05  3.43e-01  \n 13  +4.3682e-02  +4.3682e-02  3.23e-07  5.34e-07  1.35e-07  4.01e-07  5.00e-05  6.64e-01  \n 14  +4.3583e-02  +4.3583e-02  8.26e-08  1.68e-07  4.23e-08  1.07e-07  2.13e-05  7.79e-01  \n 15  +4.3546e-02  +4.3546e-02  1.94e-08  5.11e-08  1.29e-08  2.71e-08  7.49e-06  7.74e-01  \n 16  +4.3531e-02  +4.3531e-02  2.35e-09  9.42e-09  2.38e-09  3.77e-09  1.48e-06  8.77e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 5.8545056s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:31:48,045 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00  1.83453019e-18  1.83453019e-18 ...  1.83453019e-18\n   1.83453019e-18  1.83453019e-18]\n [ 1.83453019e-18 -1.00000000e+00  1.83453019e-18 ...  1.83453019e-18\n   1.83453019e-18  1.83453019e-18]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  4.80891410e-03\n   1.60686194e-02 -1.25205546e-02]\n ...\n [ 0.00000000e+00  0.00000000e+00  4.34418735e-02 ... -1.00000000e+00\n  -9.07144335e-01  1.00492600e+00]\n [ 0.00000000e+00  0.00000000e+00  3.96870393e-01 ... -8.85382234e-01\n  -1.00000000e+00  9.79845118e-01]\n [ 0.00000000e+00  0.00000000e+00 -3.13772322e-01 ...  9.52927602e-01\n   9.48399434e-01 -1.00000000e+00]]\n2025-09-30 15:31:48,076 - xlsindy.simulation - INFO - Group 37, weight 0.64: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:31:48,139 - __main__ - INFO - Regression completed in 8.63 seconds\nestimate variance between mujoco and model is :  1.0130742\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:31:40 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:31:40 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:31:40 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:31:40 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:31:40 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:31:40 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:31:40 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:31:40 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:31:40 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:31:40 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:31:41 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:31:41 PM: Finished problem compilation (took 1.144e+00 seconds).\n(CVXPY) Sep 30 03:31:41 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:31:48 PM: Problem status: optimal\n(CVXPY) Sep 30 03:31:48 PM: Optimal value: 4.353e-02\n(CVXPY) Sep 30 03:31:48 PM: Compilation took 1.144e+00 seconds\n(CVXPY) Sep 30 03:31:48 PM: Solver (including time spent in interface) took 6.238e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.00s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.00s/batch]\n",
    "execution_time": 20.65783429145813,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b4cd683b2a3635ec5252fdb2393da68 --algorithm mixed --regression-type implicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b4cd683b2a3635ec5252fdb2393da68",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [27, 1]\n2025-09-30 15:32:00,174 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:32:00,174 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:32:01,233 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:32:01,251 - xlsindy.simulation - INFO - Experimental matrix norm: 494.14049008736384\n2025-09-30 15:32:01,251 - xlsindy.simulation - INFO - Experimental matrix variance: 6.902407613375731\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.14e+00  1.00e+00  1.62e+01   ------   \n  1  +1.3652e-01  +1.3568e-01  8.34e-04  6.38e-03  1.64e-03  9.98e-03  1.76e-01  9.89e-01  \n  2  +1.1217e-01  +1.1209e-01  7.38e-05  1.53e-04  3.91e-05  1.76e-04  4.23e-03  9.76e-01  \n  3  +8.0047e-02  +8.0898e-02  8.51e-04  4.49e-05  1.15e-05  1.01e-03  1.24e-03  8.03e-01  \n  4  +5.6969e-02  +5.7340e-02  3.71e-04  2.62e-05  6.71e-06  3.98e-04  7.27e-04  6.85e-01  \n  5  +5.4902e-02  +5.5210e-02  3.08e-04  2.23e-05  5.69e-06  3.31e-04  6.17e-04  3.18e-01  \n  6  +4.9149e-02  +4.9148e-02  5.25e-07  8.57e-06  2.18e-06  2.60e-06  2.40e-04  9.90e-01  \n  7  +4.7714e-02  +4.7715e-02  1.22e-06  7.20e-06  1.83e-06  3.15e-06  2.06e-04  3.23e-01  \n  8  +4.6332e-02  +4.6332e-02  1.49e-07  2.20e-06  5.52e-07  4.12e-07  7.65e-05  7.63e-01  \n  9  +4.6282e-02  +4.6282e-02  2.09e-07  2.13e-06  5.34e-07  4.62e-07  7.61e-05  4.18e-02  \n 10  +4.5743e-02  +4.5744e-02  2.36e-07  4.61e-07  1.15e-07  2.75e-07  3.91e-05  7.52e-01  \n 11  +4.5700e-02  +4.5700e-02  3.21e-08  8.23e-08  2.05e-08  3.90e-08  8.40e-06  8.29e-01  \n 12  +4.5690e-02  +4.5690e-02  4.96e-09  1.44e-08  3.59e-09  6.18e-09  1.55e-06  8.37e-01  \n 13  +4.5688e-02  +4.5688e-02  5.50e-10  2.11e-09  5.24e-10  7.28e-10  2.28e-07  8.83e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 4.900992925s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:32:07,873 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -5.85999944e-20 -5.85999944e-20 ... -5.85999944e-20\n  -5.85999944e-20 -5.85999944e-20]\n [-5.85999944e-20 -1.00000000e+00 -5.85999944e-20 ... -5.85999944e-20\n  -5.85999944e-20 -5.85999944e-20]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  3.61984694e-02\n   1.53298846e-01 -3.23509134e-01]\n ...\n [ 0.00000000e+00  0.00000000e+00  8.76505660e-02 ... -1.00000000e+00\n   5.08870243e-01  1.09680085e+00]\n [ 0.00000000e+00  0.00000000e+00  3.12235385e-01 ...  4.27724651e-01\n  -1.00000000e+00  3.39930354e-01]\n [ 0.00000000e+00  0.00000000e+00 -3.06596221e-01 ...  4.31088658e-01\n   1.61519994e-01 -1.00000000e+00]]\n2025-09-30 15:32:07,918 - xlsindy.simulation - INFO - Group 19, weight 0.20: [np.int64(19), np.int64(20), np.int64(56)]\n2025-09-30 15:32:07,934 - __main__ - INFO - Regression completed in 7.76 seconds\n",
    "stderr": "(CVXPY) Sep 30 03:32:01 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:32:01 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:32:01 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:32:01 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:32:01 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:32:01 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:32:01 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:32:01 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:32:01 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:32:01 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:32:02 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:32:02 PM: Finished problem compilation (took 1.176e+00 seconds).\n(CVXPY) Sep 30 03:32:02 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:32:07 PM: Problem status: optimal\n(CVXPY) Sep 30 03:32:07 PM: Optimal value: 4.569e-02\n(CVXPY) Sep 30 03:32:07 PM: Compilation took 1.176e+00 seconds\n(CVXPY) Sep 30 03:32:07 PM: Solver (including time spent in interface) took 5.298e+00 seconds\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 243, in <module>\n    xlsindy.dynamics_modeling.generate_acceleration_function(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/dynamics_modeling.py\", line 67, in generate_acceleration_function\n    if str(symbol_matrix[3, i]) not in str(dynamic_equations[i]):\nIndexError: index 0 is out of bounds for axis 0 with size 0\n",
    "execution_time": 11.320758819580078,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b4cd683b2a3635ec5252fdb2393da68 --algorithm mixed --regression-type implicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b4cd683b2a3635ec5252fdb2393da68",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [27, 1]\n2025-09-30 15:32:11,520 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:32:11,521 - __main__ - INFO - Starting implicit regression\n2025-09-30 15:32:12,574 - xlsindy.simulation - INFO - debug : some information\n2025-09-30 15:32:12,587 - xlsindy.simulation - INFO - Experimental matrix norm: 494.06224471813044\n2025-09-30 15:32:12,587 - xlsindy.simulation - INFO - Experimental matrix variance: 6.900274947572346\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.14e+00  1.00e+00  1.62e+01   ------   \n  1  +1.3654e-01  +1.3571e-01  8.33e-04  6.37e-03  1.64e-03  9.98e-03  1.76e-01  9.89e-01  \n  2  +1.1203e-01  +1.1196e-01  7.08e-05  1.51e-04  3.88e-05  1.77e-04  4.19e-03  9.76e-01  \n  3  +7.8957e-02  +7.9735e-02  7.78e-04  4.11e-05  1.05e-05  9.28e-04  1.14e-03  8.11e-01  \n  4  +5.5160e-02  +5.5504e-02  3.44e-04  2.56e-05  6.55e-06  3.70e-04  7.10e-04  6.60e-01  \n  5  +5.3176e-02  +5.3470e-02  2.94e-04  2.17e-05  5.56e-06  3.17e-04  6.03e-04  3.23e-01  \n  6  +4.7748e-02  +4.7773e-02  2.49e-05  1.15e-05  2.94e-06  2.99e-05  3.22e-04  7.92e-01  \n  7  +4.5717e-02  +4.5729e-02  1.20e-05  7.44e-06  1.89e-06  1.41e-05  2.14e-04  5.54e-01  \n  8  +4.4614e-02  +4.4618e-02  4.00e-06  4.53e-06  1.14e-06  4.78e-06  1.44e-04  4.42e-01  \n  9  +4.4549e-02  +4.4554e-02  4.28e-06  4.30e-06  1.09e-06  5.05e-06  1.43e-04  7.29e-02  \n 10  +4.3841e-02  +4.3842e-02  7.85e-07  1.51e-06  3.79e-07  9.67e-07  7.71e-05  6.40e-01  \n 11  +4.3687e-02  +4.3688e-02  5.48e-07  9.98e-07  2.50e-07  6.61e-07  6.63e-05  3.47e-01  \n 12  +4.3635e-02  +4.3635e-02  4.27e-07  7.85e-07  1.97e-07  5.15e-07  5.91e-05  3.14e-01  \n 13  +4.3543e-02  +4.3543e-02  1.79e-07  3.46e-07  8.67e-08  2.17e-07  3.45e-05  5.11e-01  \n 14  +4.3538e-02  +4.3538e-02  1.33e-07  3.04e-07  7.63e-08  1.67e-07  3.09e-05  3.53e-01  \n 15  +4.3504e-02  +4.3504e-02  3.21e-08  1.37e-07  3.43e-08  4.72e-08  1.59e-05  8.92e-01  \n 16  +4.3493e-02  +4.3493e-02  1.50e-08  8.70e-08  2.18e-08  2.47e-08  1.06e-05  5.24e-01  \n 17  +4.3492e-02  +4.3492e-02  1.17e-08  8.26e-08  2.07e-08  2.08e-08  1.00e-05  1.89e-01  \n 18  +4.3486e-02  +4.3486e-02  5.87e-09  5.88e-08  1.47e-08  1.24e-08  7.32e-06  4.29e-01  \n 19  +4.3480e-02  +4.3480e-02  1.27e-09  3.55e-08  8.91e-09  5.23e-09  4.47e-06  6.39e-01  \n 20  +4.3480e-02  +4.3480e-02  7.75e-10  3.50e-08  8.76e-09  4.66e-09  4.40e-06  1.31e-01  \n 21  +4.3478e-02  +4.3478e-02  1.51e-10  2.92e-08  7.32e-09  3.39e-09  3.68e-06  3.05e-01  \n 22  +4.3477e-02  +4.3477e-02  1.86e-09  2.35e-08  5.88e-09  7.58e-10  2.87e-06  9.90e-01  \n 23  +4.3471e-02  +4.3471e-02  3.38e-10  4.21e-09  1.06e-09  1.32e-10  5.36e-07  8.85e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 7.80098573s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:32:22,089 - xlsindy.simulation - INFO - CVXPY problem solved with solution: [[-1.00000000e+00 -5.34951589e-20 -5.34951589e-20 ... -5.34951589e-20\n  -5.34951589e-20 -5.34951589e-20]\n [-5.34951589e-20 -1.00000000e+00 -5.34951589e-20 ... -5.34951589e-20\n  -5.34951589e-20 -5.34951589e-20]\n [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 ...  4.80844553e-04\n   3.38237902e-03 -1.79390174e-03]\n ...\n [ 0.00000000e+00  0.00000000e+00  3.07926307e-02 ... -1.00000000e+00\n  -9.76392280e-01  1.00065415e+00]\n [ 0.00000000e+00  0.00000000e+00  3.99610348e-01 ... -9.75982765e-01\n  -1.00000000e+00  9.97868736e-01]\n [ 0.00000000e+00  0.00000000e+00 -3.07795774e-01 ...  9.89578876e-01\n   9.86317826e-01 -1.00000000e+00]]\n2025-09-30 15:32:22,154 - xlsindy.simulation - INFO - Group 39, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:32:22,184 - __main__ - INFO - Regression completed in 10.66 seconds\nestimate variance between mujoco and model is :  0.109340236\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:32:12 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:32:12 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:32:12 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:32:12 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:32:12 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:32:12 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:32:12 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:32:12 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:32:12 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:32:12 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:32:13 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:32:13 PM: Finished problem compilation (took 1.189e+00 seconds).\n(CVXPY) Sep 30 03:32:13 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:32:22 PM: Problem status: optimal\n(CVXPY) Sep 30 03:32:22 PM: Optimal value: 4.347e-02\n(CVXPY) Sep 30 03:32:22 PM: Compilation took 1.189e+00 seconds\n(CVXPY) Sep 30 03:32:22 PM: Solver (including time spent in interface) took 8.194e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.94s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.94s/batch]\n",
    "execution_time": 22.770748138427734,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b4cd683b2a3635ec5252fdb2393da68 --algorithm mixed --regression-type implicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b4cd683b2a3635ec5252fdb2393da68",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [27, 1]\n2025-09-30 15:32:34,510 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:32:34,510 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:32:34,510 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:32:35,559 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:32:35,560 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:32:35,560 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:32:35,560 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:32:35,560 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:32:35,560 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.14e+00  1.00e+00  1.62e+01   ------   \n  1  +1.3655e-01  +1.3571e-01  8.33e-04  6.37e-03  1.64e-03  9.98e-03  1.76e-01  9.89e-01  \n  2  +1.1203e-01  +1.1196e-01  7.08e-05  1.51e-04  3.87e-05  1.77e-04  4.19e-03  9.76e-01  \n  3  +7.8955e-02  +7.9733e-02  7.77e-04  4.11e-05  1.05e-05  9.28e-04  1.14e-03  8.11e-01  \n  4  +5.5152e-02  +5.5496e-02  3.44e-04  2.56e-05  6.55e-06  3.70e-04  7.10e-04  6.60e-01  \n  5  +5.3167e-02  +5.3461e-02  2.94e-04  2.17e-05  5.56e-06  3.17e-04  6.03e-04  3.23e-01  \n  6  +4.7736e-02  +4.7761e-02  2.49e-05  1.15e-05  2.94e-06  2.99e-05  3.22e-04  7.91e-01  \n  7  +4.5703e-02  +4.5715e-02  1.20e-05  7.44e-06  1.89e-06  1.41e-05  2.14e-04  5.54e-01  \n  8  +4.4600e-02  +4.4604e-02  4.00e-06  4.53e-06  1.14e-06  4.78e-06  1.44e-04  4.42e-01  \n  9  +4.4535e-02  +4.4539e-02  4.28e-06  4.30e-06  1.09e-06  5.05e-06  1.43e-04  7.28e-02  \n 10  +4.3783e-02  +4.3783e-02  5.72e-07  1.24e-06  3.10e-07  7.18e-07  6.71e-05  7.38e-01  \n 11  +4.3652e-02  +4.3653e-02  4.53e-07  8.54e-07  2.14e-07  5.49e-07  5.94e-05  3.44e-01  \n 12  +4.3550e-02  +4.3550e-02  2.29e-07  4.29e-07  1.07e-07  2.76e-07  3.96e-05  4.65e-01  \n 13  +4.3528e-02  +4.3528e-02  1.48e-07  3.23e-07  8.10e-08  1.83e-07  3.21e-05  4.56e-01  \n 14  +4.3496e-02  +4.3496e-02  5.30e-08  1.69e-07  4.23e-08  7.16e-08  1.90e-05  7.38e-01  \n 15  +4.3473e-02  +4.3473e-02  1.05e-08  6.86e-08  1.72e-08  1.81e-08  8.55e-06  8.32e-01  \n 16  +4.3464e-02  +4.3464e-02  1.39e-09  3.42e-08  8.58e-09  5.18e-09  4.36e-06  7.78e-01  \n 17  +4.3460e-02  +4.3460e-02  1.17e-09  1.67e-08  4.20e-09  6.94e-10  2.07e-06  9.90e-01  \n 18  +4.3459e-02  +4.3459e-02  1.04e-09  1.44e-08  3.63e-09  5.75e-10  1.73e-06  2.76e-01  \n 19  +4.3456e-02  +4.3456e-02  5.39e-10  6.59e-09  1.67e-09  2.08e-10  7.05e-07  9.90e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 6.764834271s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:32:43,942 - xlsindy.simulation - INFO - Group 19, weight 0.17: [np.int64(19), np.int64(20), np.int64(56)]\n2025-09-30 15:32:43,943 - xlsindy.simulation - INFO - Group 37, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:32:43,943 - xlsindy.simulation - INFO - Group 59, weight 0.18: [np.int64(76), np.int64(79), np.int64(80)]\n2025-09-30 15:32:43,974 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:32:43,995 - __main__ - INFO - Regression completed in 9.49 seconds\nestimate variance between mujoco and model is :  0.16564974\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:32:35 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:32:35 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:32:35 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:32:35 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:32:35 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:32:35 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:32:35 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:32:35 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:32:35 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:32:35 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:32:36 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:32:36 PM: Finished problem compilation (took 1.122e+00 seconds).\n(CVXPY) Sep 30 03:32:36 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:32:43 PM: Problem status: optimal\n(CVXPY) Sep 30 03:32:43 PM: Optimal value: 4.345e-02\n(CVXPY) Sep 30 03:32:43 PM: Compilation took 1.122e+00 seconds\n(CVXPY) Sep 30 03:32:43 PM: Solver (including time spent in interface) took 7.179e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\n",
    "execution_time": 21.033042430877686,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b4cd683b2a3635ec5252fdb2393da68 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b4cd683b2a3635ec5252fdb2393da68",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [27, 1]\n2025-09-30 15:32:55,342 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:32:55,342 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:32:55,342 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:32:56,398 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:32:56,398 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:32:56,398 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:32:56,398 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:32:56,398 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:32:56,398 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.14e+00  1.00e+00  1.62e+01   ------   \n  1  +1.3652e-01  +1.3568e-01  8.33e-04  6.37e-03  1.64e-03  9.98e-03  1.76e-01  9.89e-01  \n  2  +1.1200e-01  +1.1193e-01  7.09e-05  1.52e-04  3.88e-05  1.77e-04  4.20e-03  9.76e-01  \n  3  +7.8983e-02  +7.9766e-02  7.82e-04  4.14e-05  1.06e-05  9.33e-04  1.14e-03  8.11e-01  \n  4  +5.5240e-02  +5.5585e-02  3.45e-04  2.57e-05  6.56e-06  3.71e-04  7.11e-04  6.64e-01  \n  5  +5.3267e-02  +5.3561e-02  2.94e-04  2.18e-05  5.57e-06  3.17e-04  6.04e-04  3.21e-01  \n  6  +4.7838e-02  +4.7861e-02  2.31e-05  1.14e-05  2.90e-06  2.79e-05  3.18e-04  8.05e-01  \n  7  +4.5828e-02  +4.5839e-02  1.12e-05  7.33e-06  1.86e-06  1.32e-05  2.11e-04  5.53e-01  \n  8  +4.4774e-02  +4.4778e-02  4.05e-06  4.59e-06  1.16e-06  4.84e-06  1.46e-04  4.28e-01  \n  9  +4.4703e-02  +4.4708e-02  4.45e-06  4.33e-06  1.09e-06  5.25e-06  1.44e-04  8.83e-02  \n 10  +4.4073e-02  +4.4074e-02  1.42e-06  2.15e-06  5.40e-07  1.71e-06  9.87e-05  5.51e-01  \n 11  +4.3962e-02  +4.3963e-02  1.18e-06  1.69e-06  4.24e-07  1.41e-06  9.01e-05  1.95e-01  \n 12  +4.3804e-02  +4.3805e-02  6.83e-07  1.01e-06  2.54e-07  8.24e-07  7.08e-05  3.43e-01  \n 13  +4.3682e-02  +4.3682e-02  3.23e-07  5.34e-07  1.35e-07  4.01e-07  5.00e-05  6.64e-01  \n 14  +4.3583e-02  +4.3583e-02  8.26e-08  1.68e-07  4.23e-08  1.07e-07  2.13e-05  7.79e-01  \n 15  +4.3546e-02  +4.3546e-02  1.94e-08  5.11e-08  1.29e-08  2.71e-08  7.49e-06  7.74e-01  \n 16  +4.3531e-02  +4.3531e-02  2.35e-09  9.42e-09  2.38e-09  3.77e-09  1.48e-06  8.77e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 5.844282894s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:33:03,818 - xlsindy.simulation - INFO - Group 5, weight 0.37: [np.int64(5), np.int64(8), np.int64(18)]\n2025-09-30 15:33:03,818 - xlsindy.simulation - INFO - Group 13, weight 0.27: [np.int64(14), np.int64(19), np.int64(20), np.int64(30), np.int64(56), np.int64(65), np.int64(87)]\n2025-09-30 15:33:03,819 - xlsindy.simulation - INFO - Group 34, weight 0.64: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:33:03,851 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:33:03,871 - __main__ - INFO - Regression completed in 8.53 seconds\nestimate variance between mujoco and model is :  1.0130742\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:32:56 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:32:56 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:32:56 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:32:56 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:32:56 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:32:56 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:32:56 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:32:56 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:32:56 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:32:56 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:32:57 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:32:57 PM: Finished problem compilation (took 1.135e+00 seconds).\n(CVXPY) Sep 30 03:32:57 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:33:03 PM: Problem status: optimal\n(CVXPY) Sep 30 03:33:03 PM: Optimal value: 4.353e-02\n(CVXPY) Sep 30 03:33:03 PM: Compilation took 1.135e+00 seconds\n(CVXPY) Sep 30 03:33:03 PM: Solver (including time spent in interface) took 6.232e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.89s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.89s/batch]\n",
    "execution_time": 20.93509817123413,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b4cd683b2a3635ec5252fdb2393da68 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b4cd683b2a3635ec5252fdb2393da68",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [27, 1]\n2025-09-30 15:33:16,283 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:33:16,283 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:33:16,283 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:33:17,357 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:33:17,357 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:33:17,357 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:33:17,357 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:33:17,358 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:33:17,358 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.14e+00  1.00e+00  1.62e+01   ------   \n  1  +1.3652e-01  +1.3568e-01  8.34e-04  6.38e-03  1.64e-03  9.98e-03  1.76e-01  9.89e-01  \n  2  +1.1217e-01  +1.1209e-01  7.38e-05  1.53e-04  3.91e-05  1.76e-04  4.23e-03  9.76e-01  \n  3  +8.0047e-02  +8.0898e-02  8.51e-04  4.49e-05  1.15e-05  1.01e-03  1.24e-03  8.03e-01  \n  4  +5.6969e-02  +5.7340e-02  3.71e-04  2.62e-05  6.71e-06  3.98e-04  7.27e-04  6.85e-01  \n  5  +5.4902e-02  +5.5210e-02  3.08e-04  2.23e-05  5.69e-06  3.31e-04  6.17e-04  3.18e-01  \n  6  +4.9149e-02  +4.9148e-02  5.25e-07  8.57e-06  2.18e-06  2.60e-06  2.40e-04  9.90e-01  \n  7  +4.7714e-02  +4.7715e-02  1.22e-06  7.20e-06  1.83e-06  3.15e-06  2.06e-04  3.23e-01  \n  8  +4.6332e-02  +4.6332e-02  1.49e-07  2.20e-06  5.52e-07  4.12e-07  7.65e-05  7.63e-01  \n  9  +4.6282e-02  +4.6282e-02  2.09e-07  2.13e-06  5.34e-07  4.62e-07  7.61e-05  4.18e-02  \n 10  +4.5743e-02  +4.5744e-02  2.36e-07  4.61e-07  1.15e-07  2.75e-07  3.91e-05  7.52e-01  \n 11  +4.5700e-02  +4.5700e-02  3.21e-08  8.23e-08  2.05e-08  3.90e-08  8.40e-06  8.29e-01  \n 12  +4.5690e-02  +4.5690e-02  4.96e-09  1.44e-08  3.59e-09  6.18e-09  1.55e-06  8.37e-01  \n 13  +4.5688e-02  +4.5688e-02  5.50e-10  2.11e-09  5.24e-10  7.28e-10  2.28e-07  8.83e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 4.844767188s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:33:23,806 - xlsindy.simulation - INFO - Group 19, weight 0.20: [np.int64(19), np.int64(20), np.int64(56)]\n2025-09-30 15:33:23,806 - xlsindy.simulation - INFO - Group 59, weight 0.25: [np.int64(76), np.int64(79), np.int64(80)]\n2025-09-30 15:33:23,806 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:33:23,826 - __main__ - INFO - Regression completed in 7.54 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:33:17 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:33:17 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:33:17 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:33:17 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:33:17 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:33:17 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:33:17 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:33:17 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:33:17 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:33:17 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:33:18 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:33:18 PM: Finished problem compilation (took 1.148e+00 seconds).\n(CVXPY) Sep 30 03:33:18 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:33:23 PM: Problem status: optimal\n(CVXPY) Sep 30 03:33:23 PM: Optimal value: 4.569e-02\n(CVXPY) Sep 30 03:33:23 PM: Compilation took 1.148e+00 seconds\n(CVXPY) Sep 30 03:33:23 PM: Solver (including time spent in interface) took 5.231e+00 seconds\n",
    "execution_time": 11.598824977874756,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b4cd683b2a3635ec5252fdb2393da68 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b4cd683b2a3635ec5252fdb2393da68",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [27, 1]\n2025-09-30 15:33:27,727 - __main__ - INFO - Sampled 188 points uniformly from 3002 total samples\n2025-09-30 15:33:27,727 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:33:27,727 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:33:28,745 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:33:28,745 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:33:28,745 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:33:28,745 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:33:28,746 - xlsindy.simulation - INFO -  0 coordinates activated by the external forces and function interlink : \n [0 0]\n2025-09-30 15:33:28,746 - xlsindy.simulation - INFO - Performing implicit regression on the remaining coordinates...\n===============================================================================\n                                     CVXPY                                     \n                                     v1.7.3                                    \n===============================================================================\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n-------------------------------------------------------------\n           Clarabel.rs v0.11.1  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 17673\n  constraints   = 53111\n  nnz(P)        = 0\n  nnz(A)        = 2438831\n  cones (total) = 3\n    :        Zero = 1,  numel = 94\n    : Nonnegative = 1,  numel = 17672\n    : SecondOrder = 1,  numel = 35345\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit (1 thread)\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +0.0000e+00  -0.0000e+00  0.00e+00  9.94e-01  1.14e+00  1.00e+00  1.62e+01   ------   \n  1  +1.3654e-01  +1.3571e-01  8.33e-04  6.37e-03  1.64e-03  9.98e-03  1.76e-01  9.89e-01  \n  2  +1.1203e-01  +1.1196e-01  7.08e-05  1.51e-04  3.88e-05  1.77e-04  4.19e-03  9.76e-01  \n  3  +7.8957e-02  +7.9735e-02  7.78e-04  4.11e-05  1.05e-05  9.28e-04  1.14e-03  8.11e-01  \n  4  +5.5160e-02  +5.5504e-02  3.44e-04  2.56e-05  6.55e-06  3.70e-04  7.10e-04  6.60e-01  \n  5  +5.3176e-02  +5.3470e-02  2.94e-04  2.17e-05  5.56e-06  3.17e-04  6.03e-04  3.23e-01  \n  6  +4.7748e-02  +4.7773e-02  2.49e-05  1.15e-05  2.94e-06  2.99e-05  3.22e-04  7.92e-01  \n  7  +4.5717e-02  +4.5729e-02  1.20e-05  7.44e-06  1.89e-06  1.41e-05  2.14e-04  5.54e-01  \n  8  +4.4614e-02  +4.4618e-02  4.00e-06  4.53e-06  1.14e-06  4.78e-06  1.44e-04  4.42e-01  \n  9  +4.4549e-02  +4.4554e-02  4.28e-06  4.30e-06  1.09e-06  5.05e-06  1.43e-04  7.29e-02  \n 10  +4.3841e-02  +4.3842e-02  7.85e-07  1.51e-06  3.79e-07  9.67e-07  7.71e-05  6.40e-01  \n 11  +4.3687e-02  +4.3688e-02  5.48e-07  9.98e-07  2.50e-07  6.61e-07  6.63e-05  3.47e-01  \n 12  +4.3635e-02  +4.3635e-02  4.27e-07  7.85e-07  1.97e-07  5.15e-07  5.91e-05  3.14e-01  \n 13  +4.3543e-02  +4.3543e-02  1.79e-07  3.46e-07  8.67e-08  2.17e-07  3.45e-05  5.11e-01  \n 14  +4.3538e-02  +4.3538e-02  1.33e-07  3.04e-07  7.63e-08  1.67e-07  3.09e-05  3.53e-01  \n 15  +4.3504e-02  +4.3504e-02  3.21e-08  1.37e-07  3.43e-08  4.72e-08  1.59e-05  8.92e-01  \n 16  +4.3493e-02  +4.3493e-02  1.50e-08  8.70e-08  2.18e-08  2.47e-08  1.06e-05  5.24e-01  \n 17  +4.3492e-02  +4.3492e-02  1.17e-08  8.26e-08  2.07e-08  2.08e-08  1.00e-05  1.89e-01  \n 18  +4.3486e-02  +4.3486e-02  5.87e-09  5.88e-08  1.47e-08  1.24e-08  7.32e-06  4.29e-01  \n 19  +4.3480e-02  +4.3480e-02  1.27e-09  3.55e-08  8.91e-09  5.23e-09  4.47e-06  6.39e-01  \n 20  +4.3480e-02  +4.3480e-02  7.75e-10  3.50e-08  8.76e-09  4.66e-09  4.40e-06  1.31e-01  \n 21  +4.3478e-02  +4.3478e-02  1.51e-10  2.92e-08  7.32e-09  3.39e-09  3.68e-06  3.05e-01  \n 22  +4.3477e-02  +4.3477e-02  1.86e-09  2.35e-08  5.88e-09  7.58e-10  2.87e-06  9.90e-01  \n 23  +4.3471e-02  +4.3471e-02  3.38e-10  4.21e-09  1.06e-09  1.32e-10  5.36e-07  8.85e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 7.914112918s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n2025-09-30 15:33:38,275 - xlsindy.simulation - INFO - Group 38, weight 0.65: [np.int64(39), np.int64(54), np.int64(77), np.int64(78), np.int64(90), np.int64(91), np.int64(92), np.int64(93)]\n2025-09-30 15:33:38,276 - xlsindy.simulation - INFO - Group 60, weight 0.23: [np.int64(76), np.int64(79), np.int64(80)]\n2025-09-30 15:33:38,300 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:33:38,316 - __main__ - INFO - Regression completed in 10.59 seconds\nestimate variance between mujoco and model is :  0.109340236\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "(CVXPY) Sep 30 03:33:28 PM: Your problem has 8836 variables, 94 constraints, and 0 parameters.\n(CVXPY) Sep 30 03:33:28 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Sep 30 03:33:28 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Sep 30 03:33:28 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Sep 30 03:33:28 PM: Your problem is compiled with the CPP canonicalization backend.\n(CVXPY) Sep 30 03:33:28 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Sep 30 03:33:28 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n(CVXPY) Sep 30 03:33:28 PM: Applying reduction Dcp2Cone\n(CVXPY) Sep 30 03:33:28 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Sep 30 03:33:28 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Sep 30 03:33:29 PM: Applying reduction CLARABEL\n(CVXPY) Sep 30 03:33:29 PM: Finished problem compilation (took 1.130e+00 seconds).\n(CVXPY) Sep 30 03:33:29 PM: Invoking solver CLARABEL  to obtain a solution.\n(CVXPY) Sep 30 03:33:38 PM: Problem status: optimal\n(CVXPY) Sep 30 03:33:38 PM: Optimal value: 4.347e-02\n(CVXPY) Sep 30 03:33:38 PM: Compilation took 1.130e+00 seconds\n(CVXPY) Sep 30 03:33:38 PM: Solver (including time spent in interface) took 8.303e+00 seconds\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.88s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.88s/batch]\n",
    "execution_time": 21.840521335601807,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/2b4cd683b2a3635ec5252fdb2393da68 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "2b4cd683b2a3635ec5252fdb2393da68",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [31, 1]\n2025-09-30 15:33:49,966 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:33:49,966 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.8007471561431885,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5a5ba2b386a8e7abcdaa6fe9ca268947 --algorithm mixed --regression-type implicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5a5ba2b386a8e7abcdaa6fe9ca268947",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [31, 1]\n2025-09-30 15:33:55,738 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:33:55,739 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.870590686798096,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5a5ba2b386a8e7abcdaa6fe9ca268947 --algorithm mixed --regression-type implicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5a5ba2b386a8e7abcdaa6fe9ca268947",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [31, 1]\n2025-09-30 15:34:01,886 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:34:01,887 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.111114263534546,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5a5ba2b386a8e7abcdaa6fe9ca268947 --algorithm mixed --regression-type implicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5a5ba2b386a8e7abcdaa6fe9ca268947",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [31, 1]\n2025-09-30 15:34:08,137 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:34:08,137 - __main__ - INFO - Starting implicit regression\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 188, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_implicite(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 143, in regression_implicite\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.328054666519165,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5a5ba2b386a8e7abcdaa6fe9ca268947 --algorithm mixed --regression-type implicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5a5ba2b386a8e7abcdaa6fe9ca268947",
    "algorithm": "mixed",
    "regression_type": "implicit",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [31, 1]\n2025-09-30 15:34:14,113 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:34:14,114 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:34:14,114 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.834676504135132,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5a5ba2b386a8e7abcdaa6fe9ca268947 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5a5ba2b386a8e7abcdaa6fe9ca268947",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [31, 1]\n2025-09-30 15:34:19,936 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:34:19,936 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:34:19,936 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.9010069370269775,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5a5ba2b386a8e7abcdaa6fe9ca268947 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5a5ba2b386a8e7abcdaa6fe9ca268947",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [31, 1]\n2025-09-30 15:34:25,805 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:34:25,805 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:34:25,805 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 5.760067462921143,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5a5ba2b386a8e7abcdaa6fe9ca268947 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5a5ba2b386a8e7abcdaa6fe9ca268947",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "zero"
  },
  {
    "success": false,
    "returncode": 1,
    "stdout": "random seed is : [31, 1]\n2025-09-30 15:34:31,692 - __main__ - INFO - Sampled 580 points uniformly from 3002 total samples\n2025-09-30 15:34:31,692 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:34:31,692 - xlsindy.simulation - INFO - Starting mixed regression process...\n",
    "stderr": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/script/align_data.py\", line 217, in <module>\n    solution, exp_matrix = xlsindy.simulation.regression_mixed(\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/simulation.py\", line 386, in regression_mixed\n    catalog = catalog_repartition.expand_catalog()\n  File \"/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/xlsindy/catalog.py\", line 209, in expand_catalog\n    return np.concatenate(res, axis=0)\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 3\n",
    "execution_time": 6.1650965213775635,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/5a5ba2b386a8e7abcdaa6fe9ca268947 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "5a5ba2b386a8e7abcdaa6fe9ca268947",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [14, 1]\n2025-09-30 15:34:37,713 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:34:37,713 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:34:40,732 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0018488639496508693\n2025-09-30 15:34:40,860 - __main__ - INFO - Regression completed in 3.15 seconds\nestimate variance between mujoco and model is :  0.2614195\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.07s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.07s/batch]\n",
    "execution_time": 15.851593732833862,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a98be39c67e314b62da01fa5020a8536 --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a98be39c67e314b62da01fa5020a8536",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [14, 1]\n2025-09-30 15:34:53,344 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:34:53,345 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:34:55,595 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0018482310641147388\n2025-09-30 15:34:55,718 - __main__ - INFO - Regression completed in 2.37 seconds\nestimate variance between mujoco and model is :  0.3032743\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.98s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.98s/batch]\n",
    "execution_time": 14.34248161315918,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a98be39c67e314b62da01fa5020a8536 --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a98be39c67e314b62da01fa5020a8536",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [14, 1]\n2025-09-30 15:35:07,654 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:35:07,654 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:35:10,065 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.001841786580217004\n2025-09-30 15:35:10,233 - __main__ - INFO - Regression completed in 2.58 seconds\nestimate variance between mujoco and model is :  1.6996278\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.93s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.93s/batch]\n",
    "execution_time": 14.332250833511353,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a98be39c67e314b62da01fa5020a8536 --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a98be39c67e314b62da01fa5020a8536",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [14, 1]\n2025-09-30 15:35:21,965 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:35:21,965 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:35:24,177 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.001848801412499042\n2025-09-30 15:35:24,313 - __main__ - INFO - Regression completed in 2.35 seconds\nestimate variance between mujoco and model is :  0.25717652\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.97s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.98s/batch]\n",
    "execution_time": 14.32202434539795,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a98be39c67e314b62da01fa5020a8536 --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a98be39c67e314b62da01fa5020a8536",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [14, 1]\n2025-09-30 15:35:36,559 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:35:36,560 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:35:36,560 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:35:37,587 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:35:37,587 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:35:37,587 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:35:37,587 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:35:37,587 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:35:37,587 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:35:38,596 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0018488639496508686\n2025-09-30 15:35:38,712 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:35:38,712 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:35:38,712 - __main__ - INFO - Regression completed in 2.15 seconds\nestimate variance between mujoco and model is :  0.2614195\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.87s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.87s/batch]\n",
    "execution_time": 14.050328016281128,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a98be39c67e314b62da01fa5020a8536 --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a98be39c67e314b62da01fa5020a8536",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [14, 1]\n2025-09-30 15:35:50,613 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:35:50,614 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:35:50,614 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:35:51,830 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:35:51,831 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:35:51,831 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:35:51,831 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:35:51,831 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:35:51,831 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:35:52,938 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0018482310641147403\n2025-09-30 15:35:53,055 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:35:53,055 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:35:53,056 - __main__ - INFO - Regression completed in 2.44 seconds\nestimate variance between mujoco and model is :  0.3032743\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.90s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.90s/batch]\n",
    "execution_time": 14.276656866073608,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a98be39c67e314b62da01fa5020a8536 --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a98be39c67e314b62da01fa5020a8536",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [14, 1]\n2025-09-30 15:36:04,551 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:36:04,551 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:36:04,551 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:36:05,559 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:36:05,559 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:36:05,559 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:36:05,559 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:36:05,559 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:36:05,559 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:36:06,734 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0018417865802170044\n2025-09-30 15:36:06,889 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:36:06,889 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:36:06,889 - __main__ - INFO - Regression completed in 2.34 seconds\nestimate variance between mujoco and model is :  1.6996278\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.89s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.89s/batch]\n",
    "execution_time": 13.741850852966309,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a98be39c67e314b62da01fa5020a8536 --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a98be39c67e314b62da01fa5020a8536",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [14, 1]\n2025-09-30 15:36:18,473 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:36:18,473 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:36:18,473 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:36:19,506 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:36:19,506 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:36:19,506 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:36:19,506 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:36:19,507 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:36:19,507 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:36:20,511 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.0018488014124990431\n2025-09-30 15:36:20,624 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:36:20,624 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:36:20,624 - __main__ - INFO - Regression completed in 2.15 seconds\nestimate variance between mujoco and model is :  0.25717652\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 85.0% \n |******************************************************************************************----------| 90.0% \n |***********************************************************************************************-----| 95.0% \n |****************************************************************************************************| 100.0% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.94s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/batch]\n",
    "execution_time": 14.419668674468994,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/a98be39c67e314b62da01fa5020a8536 --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "a98be39c67e314b62da01fa5020a8536",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [33, 1]\n2025-09-30 15:36:33,171 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:36:33,171 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:36:43,061 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.7086676485905556\n2025-09-30 15:36:43,184 - __main__ - INFO - Regression completed in 10.01 seconds\nestimate variance between mujoco and model is :  2.3265412\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 84.9% \n |******************************************************************************************----------| 89.8% \n |***********************************************************************************************-----| 94.8% \n |****************************************************************************************************| 99.8% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.569e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.107e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.366e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.983e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.388e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.529e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.034e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.498e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.036e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.860e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.713e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.763e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.616e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.489e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.166e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.753e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.594e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.334e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.134e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.662e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.881e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.035e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.876e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.700e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.856e+01, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.430e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.565e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.584e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.476e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.243e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.900e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.463e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.936e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.326e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.888e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.970e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.847e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.716e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.577e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.433e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.286e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.137e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.987e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.893e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.281e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.682e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.653e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.812e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.107e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.813e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.794e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.571e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.388e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.843e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.648e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.991e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.892e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.688e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.060e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.082e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.822e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.533e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.264e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.966e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.654e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.375e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.100e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.827e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.599e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.727e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.554e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.269e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.870e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.376e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.796e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.133e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.394e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.587e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.721e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.803e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.839e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.839e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.804e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.741e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.654e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.548e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.426e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.292e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.148e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.998e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.844e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.687e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.529e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.372e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.216e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.119e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.372e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.113e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.644e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.191e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.359e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.490e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.560e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.559e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.608e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.304e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.983e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.859e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.870e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.784e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.508e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.728e+01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.379e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.008e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.491e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.786e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.869e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.779e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.615e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.340e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.071e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.810e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.556e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.311e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.074e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.847e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.780e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.068e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.843e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.562e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.324e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.877e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.221e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.824e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.481e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.820e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.505e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.201e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.908e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.627e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.358e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.101e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.423e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.596e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.936e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.837e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.595e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.165e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.408e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.913e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.258e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.644e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.355e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.077e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.812e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.559e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.7s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e+03, tolerance: 1.007e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e+03, tolerance: 1.007e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.48s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.48s/batch]\n",
    "execution_time": 23.474533081054688,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/44a3a141cd611f0ccf2aea45a0d6db8c --algorithm mixed --regression-type explicit --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "44a3a141cd611f0ccf2aea45a0d6db8c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [33, 1]\n2025-09-30 15:36:56,322 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:36:56,322 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:37:01,009 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 1328.0592263848907\n2025-09-30 15:37:01,011 - __main__ - INFO - Regression completed in 4.69 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.6s finished\n",
    "execution_time": 8.554630756378174,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/44a3a141cd611f0ccf2aea45a0d6db8c --algorithm mixed --regression-type explicit --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "44a3a141cd611f0ccf2aea45a0d6db8c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [33, 1]\n2025-09-30 15:37:04,622 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:37:04,622 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:37:05,801 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 1174.1489902662697\n2025-09-30 15:37:05,802 - __main__ - INFO - Regression completed in 1.18 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
    "execution_time": 4.685640335083008,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/44a3a141cd611f0ccf2aea45a0d6db8c --algorithm mixed --regression-type explicit --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "44a3a141cd611f0ccf2aea45a0d6db8c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [33, 1]\n2025-09-30 15:37:09,485 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:37:09,486 - __main__ - INFO - Starting explicit regression\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:37:19,391 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 1.7705728156475773\n2025-09-30 15:37:19,529 - __main__ - INFO - Regression completed in 10.04 seconds\nestimate variance between mujoco and model is :  3.309342\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 39.9% \n |*********************************************-------------------------------------------------------| 44.9% \n |**************************************************--------------------------------------------------| 49.9% \n |*******************************************************---------------------------------------------| 54.9% \n |************************************************************----------------------------------------| 59.9% \n |*****************************************************************-----------------------------------| 64.9% \n |**********************************************************************------------------------------| 69.9% \n |***************************************************************************-------------------------| 74.9% \n |********************************************************************************--------------------| 79.9% \n |*************************************************************************************---------------| 84.9% \n |******************************************************************************************----------| 89.9% \n |***********************************************************************************************-----| 94.9% \n |****************************************************************************************************| 99.9% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.880e-01, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.691e-01, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.333e-01, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.502e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.300e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.138e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.984e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.730e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.328e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.824e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.229e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.559e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.812e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.071e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.319e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.472e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.627e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.766e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.891e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.019e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.108e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.210e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.292e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.356e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.406e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.443e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.471e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.492e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.505e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.515e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.520e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.491e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.451e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.411e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.391e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.770e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.909e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.649e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.737e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.800e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.249e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.721e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.444e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.470e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.850e+01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.675e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.537e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.333e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.011e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.598e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.094e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.517e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.172e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.368e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.576e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.741e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.908e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.053e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.168e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.272e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.362e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.438e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.505e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.575e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.635e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.704e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.807e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.899e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.986e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.063e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.132e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.193e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.868e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.132e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.174e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.624e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.379e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.591e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.608e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.784e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.641e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.436e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.260e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.795e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.366e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.884e+01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.590e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.873e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.961e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.907e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.662e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.282e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.748e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.124e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.433e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.697e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.922e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.808e-01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.260e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.512e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.107e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.434e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.529e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.597e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.805e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.514e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.734e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.562e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.211e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.751e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.196e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.503e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.838e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.104e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.306e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.457e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.673e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.736e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.764e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.784e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.773e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.732e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.722e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.699e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.811e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.915e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.739e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.001e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.977e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.312e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.962e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.359e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.516e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.552e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.392e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.203e+01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.255e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.576e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.729e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.660e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.515e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.236e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.814e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.268e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.621e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.7s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.757e+03, tolerance: 1.007e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.757e+03, tolerance: 1.007e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.29s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.29s/batch]\n",
    "execution_time": 21.66725993156433,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/44a3a141cd611f0ccf2aea45a0d6db8c --algorithm mixed --regression-type explicit --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "44a3a141cd611f0ccf2aea45a0d6db8c",
    "algorithm": "mixed",
    "regression_type": "explicit",
    "noise_level": 0.001,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [33, 1]\n2025-09-30 15:37:31,096 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:37:31,096 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:37:31,096 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:37:32,165 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:37:32,165 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:37:32,166 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:37:32,166 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:37:32,166 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:37:32,166 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:37:39,678 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 0.7086676485905559\n2025-09-30 15:37:39,796 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:37:39,796 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:37:39,796 - __main__ - INFO - Regression completed in 8.70 seconds\nestimate variance between mujoco and model is :  2.3265412\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 40.0% \n |*********************************************-------------------------------------------------------| 45.0% \n |**************************************************--------------------------------------------------| 50.0% \n |*******************************************************---------------------------------------------| 55.0% \n |************************************************************----------------------------------------| 60.0% \n |*****************************************************************-----------------------------------| 65.0% \n |**********************************************************************------------------------------| 70.0% \n |***************************************************************************-------------------------| 75.0% \n |********************************************************************************--------------------| 80.0% \n |*************************************************************************************---------------| 84.9% \n |******************************************************************************************----------| 89.8% \n |***********************************************************************************************-----| 94.8% \n |****************************************************************************************************| 99.8% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.569e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.107e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.366e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.983e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.388e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.529e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.034e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.498e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.036e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.860e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.713e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.763e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.616e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.489e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.166e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.753e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.594e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.334e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.134e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.662e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.881e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.035e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.876e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.700e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.856e+01, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.430e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.565e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.584e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.476e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.243e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.900e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.463e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.936e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.326e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.888e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+03, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.970e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.847e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.716e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.577e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.433e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.286e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.137e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.987e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.893e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.281e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.682e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.653e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.812e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.107e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.813e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.794e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.571e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.388e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.843e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.648e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.991e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.892e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.688e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.060e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.082e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.822e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.533e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.264e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.966e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.654e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.375e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.100e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.827e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.599e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.727e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.554e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.269e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.870e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.376e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.796e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.133e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.394e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.587e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.721e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.803e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.839e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.839e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.804e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.741e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.654e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.548e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.426e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.292e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.148e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.998e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.844e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.687e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.529e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.372e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.216e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.119e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.372e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.113e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.644e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.191e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.359e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.490e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.560e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.559e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.608e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.304e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.983e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.859e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.870e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.784e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.508e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.728e+01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.379e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.008e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.491e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.786e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.869e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.779e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.615e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.340e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.071e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.810e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.556e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.311e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.074e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.847e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.780e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.068e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.843e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.562e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.324e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.877e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.221e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.824e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.481e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.820e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.505e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.201e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.908e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.627e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.358e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.101e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.423e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.596e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+00, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.936e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.837e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.595e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.165e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.408e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.913e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.258e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.644e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.355e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.077e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.812e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.559e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.4s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e+03, tolerance: 1.007e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e+03, tolerance: 1.007e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.36s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.36s/batch]\n",
    "execution_time": 20.734192848205566,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/44a3a141cd611f0ccf2aea45a0d6db8c --algorithm mixed --regression-type mixed --noise-level 0.0 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "44a3a141cd611f0ccf2aea45a0d6db8c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.0,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [33, 1]\n2025-09-30 15:37:52,640 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:37:52,640 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:37:52,641 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:37:53,757 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:37:53,758 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:37:53,758 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:37:53,758 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:37:53,758 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:37:53,758 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:37:56,927 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 1328.0592263848912\n2025-09-30 15:37:56,928 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:37:56,928 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:37:56,928 - __main__ - INFO - Regression completed in 4.29 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.2s finished\n",
    "execution_time": 8.8625328540802,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/44a3a141cd611f0ccf2aea45a0d6db8c --algorithm mixed --regression-type mixed --noise-level 0.01 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "44a3a141cd611f0ccf2aea45a0d6db8c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.01,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [33, 1]\n2025-09-30 15:38:00,741 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:38:00,742 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:38:00,742 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:38:01,842 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:38:01,843 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:38:01,843 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:38:01,843 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:38:01,843 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:38:01,843 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:38:01,987 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 1174.1489902662693\n2025-09-30 15:38:01,988 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:38:01,988 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:38:01,988 - __main__ - INFO - Regression completed in 1.25 seconds\nSkipped model verification, retrieval failed\nprint model ...\n",
    "stderr": "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
    "execution_time": 5.116139650344849,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/44a3a141cd611f0ccf2aea45a0d6db8c --algorithm mixed --regression-type mixed --noise-level 0.1 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "44a3a141cd611f0ccf2aea45a0d6db8c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.1,
    "force_type": "non_zero"
  },
  {
    "success": true,
    "returncode": 0,
    "stdout": "random seed is : [33, 1]\n2025-09-30 15:38:05,957 - __main__ - INFO - Sampled 188 points uniformly from 3000 total samples\n2025-09-30 15:38:05,957 - __main__ - INFO - Starting mixed regression\n2025-09-30 15:38:05,957 - xlsindy.simulation - INFO - Starting mixed regression process...\n2025-09-30 15:38:07,056 - xlsindy.simulation - INFO - activated_function : (1, 94)\n2025-09-30 15:38:07,056 - xlsindy.simulation - INFO - activated_coordinate : (2, 1)\n2025-09-30 15:38:07,056 - xlsindy.simulation - INFO - external_forces : (188, 2)\n2025-09-30 15:38:07,056 - xlsindy.simulation - INFO - acceleration_values : (188, 2)\n2025-09-30 15:38:07,056 - xlsindy.simulation - INFO -  2 coordinates activated by the external forces and function interlink : \n [1 1]\n2025-09-30 15:38:07,056 - xlsindy.simulation - INFO - Performing explicit regression on the activated coordinates...\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\nPath: 000 out of 100\nPath: 001 out of 100\nPath: 002 out of 100\nPath: 003 out of 100\nPath: 004 out of 100\nPath: 005 out of 100\nPath: 006 out of 100\nPath: 007 out of 100\nPath: 008 out of 100\nPath: 009 out of 100\nPath: 010 out of 100\nPath: 011 out of 100\nPath: 012 out of 100\nPath: 013 out of 100\nPath: 014 out of 100\nPath: 015 out of 100\nPath: 016 out of 100\nPath: 017 out of 100\nPath: 018 out of 100\nPath: 019 out of 100\nPath: 020 out of 100\nPath: 021 out of 100\nPath: 022 out of 100\nPath: 023 out of 100\nPath: 024 out of 100\nPath: 025 out of 100\nPath: 026 out of 100\nPath: 027 out of 100\nPath: 028 out of 100\nPath: 029 out of 100\nPath: 030 out of 100\nPath: 031 out of 100\nPath: 032 out of 100\nPath: 033 out of 100\nPath: 034 out of 100\nPath: 035 out of 100\nPath: 036 out of 100\nPath: 037 out of 100\nPath: 038 out of 100\nPath: 039 out of 100\nPath: 040 out of 100\nPath: 041 out of 100\nPath: 042 out of 100\nPath: 043 out of 100\nPath: 044 out of 100\nPath: 045 out of 100\nPath: 046 out of 100\nPath: 047 out of 100\nPath: 048 out of 100\nPath: 049 out of 100\nPath: 050 out of 100\nPath: 051 out of 100\nPath: 052 out of 100\nPath: 053 out of 100\nPath: 054 out of 100\nPath: 055 out of 100\nPath: 056 out of 100\nPath: 057 out of 100\nPath: 058 out of 100\nPath: 059 out of 100\nPath: 060 out of 100\nPath: 061 out of 100\nPath: 062 out of 100\nPath: 063 out of 100\nPath: 064 out of 100\nPath: 065 out of 100\nPath: 066 out of 100\nPath: 067 out of 100\nPath: 068 out of 100\nPath: 069 out of 100\nPath: 070 out of 100\nPath: 071 out of 100\nPath: 072 out of 100\nPath: 073 out of 100\nPath: 074 out of 100\nPath: 075 out of 100\nPath: 076 out of 100\nPath: 077 out of 100\nPath: 078 out of 100\nPath: 079 out of 100\nPath: 080 out of 100\nPath: 081 out of 100\nPath: 082 out of 100\nPath: 083 out of 100\nPath: 084 out of 100\nPath: 085 out of 100\nPath: 086 out of 100\nPath: 087 out of 100\nPath: 088 out of 100\nPath: 089 out of 100\nPath: 090 out of 100\nPath: 091 out of 100\nPath: 092 out of 100\nPath: 093 out of 100\nPath: 094 out of 100\nPath: 095 out of 100\nPath: 096 out of 100\nPath: 097 out of 100\nPath: 098 out of 100\nPath: 099 out of 100\n2025-09-30 15:38:14,533 - xlsindy.optimization - INFO - LassoCV complete. Best alpha found: 1.7705728156475773\n2025-09-30 15:38:14,665 - xlsindy.simulation - INFO -  2 coordinates activated by the explicit regression this is a 0 change from the first detection : \n [1 1]\n2025-09-30 15:38:14,665 - xlsindy.simulation - INFO - Mixed regression process completed successfully.\n2025-09-30 15:38:14,666 - __main__ - INFO - Regression completed in 8.71 seconds\nestimate variance between mujoco and model is :  3.309342\n\n |*****-----------------------------------------------------------------------------------------------| 5.0% \n |**********------------------------------------------------------------------------------------------| 10.0% \n |***************-------------------------------------------------------------------------------------| 15.0% \n |********************--------------------------------------------------------------------------------| 20.0% \n |*************************---------------------------------------------------------------------------| 25.0% \n |******************************----------------------------------------------------------------------| 30.0% \n |***********************************-----------------------------------------------------------------| 35.0% \n |****************************************------------------------------------------------------------| 39.9% \n |*********************************************-------------------------------------------------------| 44.9% \n |**************************************************--------------------------------------------------| 49.9% \n |*******************************************************---------------------------------------------| 54.9% \n |************************************************************----------------------------------------| 59.9% \n |*****************************************************************-----------------------------------| 64.9% \n |**********************************************************************------------------------------| 69.9% \n |***************************************************************************-------------------------| 74.9% \n |********************************************************************************--------------------| 79.9% \n |*************************************************************************************---------------| 84.9% \n |******************************************************************************************----------| 89.9% \n |***********************************************************************************************-----| 94.9% \n |****************************************************************************************************| 99.9% \n |****************************************************************************************************| 100.0% \nprint model ...\n",
    "stderr": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.880e-01, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.691e-01, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.333e-01, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.502e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.300e+00, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.138e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.984e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.730e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.328e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.824e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.229e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.559e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.812e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.071e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.319e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.472e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.627e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.766e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.891e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.019e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.108e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.210e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.292e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.356e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.406e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.443e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.471e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.492e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.505e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.515e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.520e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.491e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.451e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.411e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.391e+02, tolerance: 8.175e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.770e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.909e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.649e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.737e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.800e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.249e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.721e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.444e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.470e-01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e+00, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.850e+01, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.675e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.537e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.333e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.011e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.598e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.094e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.517e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.172e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.368e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.576e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.741e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.908e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.053e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.168e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.272e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.362e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.438e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.505e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.575e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.635e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.704e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.807e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.899e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.986e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.063e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.132e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.193e+02, tolerance: 7.649e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.868e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.132e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.174e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.624e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.379e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.591e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.608e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.784e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.641e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.436e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.260e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.795e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.366e-01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+00, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.884e+01, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.590e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.873e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.961e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.907e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.662e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.282e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.748e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.124e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.433e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.697e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.922e+02, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+03, tolerance: 8.043e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.808e-01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.260e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.512e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.107e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.434e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.529e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.597e+00, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.805e+01, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.514e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.734e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.562e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.211e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.751e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.196e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.503e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.838e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.104e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.306e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.457e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.673e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.736e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.764e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.784e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.773e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.732e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.722e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.699e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.811e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.915e+02, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+03, tolerance: 8.063e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.739e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.001e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.977e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.312e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.962e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.359e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.516e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.552e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.392e-01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.203e+01, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.255e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.576e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.729e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.660e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.515e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.236e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.814e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.268e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.621e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+02, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+03, tolerance: 8.335e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.4s finished\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.757e+03, tolerance: 1.007e-01\n  model = cd_fast.enet_coordinate_descent(\n/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.757e+03, tolerance: 1.007e-01\n  model = cd_fast.enet_coordinate_descent(\n\nGenerating batches:   0%|          | 0/1 [00:00<?, ?batch/s]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.47s/batch]\nGenerating batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.47s/batch]\n",
    "execution_time": 21.789739847183228,
    "command": "/mnt/ssd1/eymeric/py-xl-sindy-data-visualisation/data_generation/.venv/bin/python -m data_generation.script.align_data --experiment-file results/44a3a141cd611f0ccf2aea45a0d6db8c --algorithm mixed --regression-type mixed --noise-level 0.001 --optimization-function lasso_regression --data-ratio 2.0 --random-seed 1 --skip-already-done",
    "experiment_id": "44a3a141cd611f0ccf2aea45a0d6db8c",
    "algorithm": "mixed",
    "regression_type": "mixed",
    "noise_level": 0.001,
    "force_type": "non_zero"
  }
]