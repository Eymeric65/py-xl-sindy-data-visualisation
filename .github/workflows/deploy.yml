name: Deploy to GitHub Pages

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  # Allow manual trigger
  workflow_dispatch:

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  # Build job
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '24'
          cache: 'yarn'
          cache-dependency-path: site/yarn.lock
          
      - name: Setup Pages
        uses: actions/configure-pages@v4
        with:
          static_site_generator: vite
          
      - name: Install dependencies
        working-directory: ./site
        run: yarn install --frozen-lockfile
          
      - name: Download latest result data from releases
        working-directory: ./site
        run: |
          # Get the latest data release
          echo "ðŸ” Fetching latest data release..."
          
          # Create public/results directory
          mkdir -p public/results
          
          # Get releases and find the latest one with data
          echo "ðŸ“¡ Querying GitHub API for data releases..."
          RELEASES_JSON=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/releases/latest")
          
          echo "ðŸ” Looking for data releases..."
          echo "$RELEASES_JSON" | jq -r '.[] | select(.tag_name | contains("data")) | .tag_name' | head -5
          
          # Get the latest data release assets
          LATEST_DATA_RELEASE=$(echo "$RELEASES_JSON" | jq -r '
            .[] | 
            select(.tag_name | contains("data")) | 
            select(.assets | length > 0) | 
            .assets[] | 
            select(.name | test("results.*\\.(tar\\.gz|zip|json)$")) | 
            "\(.browser_download_url)||||\(.name)"
          ' | head -10)
          
          if [ -n "$LATEST_DATA_RELEASE" ]; then
            echo "ðŸ“¦ Found data release assets:"
            echo "$LATEST_DATA_RELEASE" | sed 's/||||/ -> /'
            
            # Process each asset
            echo "$LATEST_DATA_RELEASE" | while IFS='||||' read -r url filename; do
              if [ -n "$url" ] && [ -n "$filename" ]; then
                echo "â¬‡ï¸  Downloading: $filename"
                if curl -L -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" "$url" -o "public/results/$filename"; then
                  echo "âœ… Downloaded: $filename"
                  
                  # Extract archives
                  if [[ "$filename" == *.tar.gz ]]; then
                    echo "ðŸ“‚ Extracting tar.gz: $filename"
                    cd public/results
                    if tar -xzf "$filename"; then
                      echo "âœ… Extracted: $filename"
                      rm "$filename"  # Remove archive after extraction
                      echo "ðŸ“‹ Contents after extraction:"
                      ls -la
                    else
                      echo "âŒ Failed to extract: $filename"
                    fi
                    cd ../..
                  elif [[ "$filename" == *.zip ]]; then
                    echo "ðŸ“‚ Extracting zip: $filename"
                    cd public/results
                    if unzip -q "$filename"; then
                      echo "âœ… Extracted: $filename"
                      rm "$filename"  # Remove archive after extraction
                      echo "ðŸ“‹ Contents after extraction:"
                      ls -la
                    else
                      echo "âŒ Failed to extract: $filename"
                    fi
                    cd ../..
                  else
                    echo "ðŸ“„ Direct file (no extraction needed): $filename"
                  fi
                else
                  echo "âŒ Failed to download: $filename"
                fi
              fi
            done
            
            # Wait a moment for file operations to complete
            sleep 1
            
          else
            echo "âš ï¸  No data releases found, using fallback"
            # Fallback: try to use local data if available
            if [ -d "../results" ]; then
              echo "ðŸ“‚ Using local results directory"
              cp -r ../results/* public/results/ 2>/dev/null || true
            fi
            if [ -d "../results_data" ]; then
              echo "ðŸ“‚ Using local results_data directory"
              cp ../results_data/* public/results/ 2>/dev/null || true
            fi
          fi
          
          # Final check
          echo "ðŸ“‹ Final contents of public/results:"
          ls -la public/results/
          
          
      - name: Build site
        working-directory: ./site
        run: |
          yarn build
          
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./site/dist

  # Deployment job
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4